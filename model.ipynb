{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a6b34d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import acquire\n",
    "import prepare\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pydataset import data\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb3caa6",
   "metadata": {},
   "source": [
    "## Model Exercises\n",
    "\n",
    "## <u>Decision Tree exercises</u>\n",
    "### Exercise 1) <br> Using the titanic data, in your classification-exercises repository, create a notebook, model.ipynb where you will do the following:\n",
    "\n",
    "- What is your baseline prediction? \n",
    "- What is your baseline accuracy? remember: your baseline prediction for a classification problem is predicting the most prevelant class in the training dataset (the mode). \n",
    "- When you make those predictions, what is your accuracy? This is your baseline accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ed2c360",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read titanic data from acquire\n",
    "titanic = acquire.new_titanic_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04cfbf08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "survived                    0\n",
       "pclass                      0\n",
       "sex                         0\n",
       "age                         0\n",
       "sibsp                       0\n",
       "parch                       0\n",
       "fare                        0\n",
       "embark_town                 0\n",
       "alone                       0\n",
       "pclass                      0\n",
       "sibsp                       0\n",
       "parch                       0\n",
       "alone                       0\n",
       "sex_male                    0\n",
       "embark_town_Queenstown      0\n",
       "embark_town_Southampton     0\n",
       "embark_town_Southhampton    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from prepare.py take in the titanic dataset and us the clean_titanic_data on this fresh data set\n",
    "#had originally found NaN within age...\n",
    "train, validate, test =prepare.prepare_titanic_data(titanic)\n",
    "train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "384389ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alone</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>alone</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>embark_town_Queenstown</th>\n",
       "      <th>embark_town_Southampton</th>\n",
       "      <th>embark_town_Southhampton</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40.1250</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>20.5250</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>39.6875</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>female</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>110.8833</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     survived  pclass     sex        age  sibsp  parch      fare  embark_town  \\\n",
       "583         0       1    male  36.000000      0      0   40.1250    Cherbourg   \n",
       "165         1       3    male   9.000000      0      2   20.5250  Southampton   \n",
       "50          0       3    male   7.000000      4      1   39.6875  Southampton   \n",
       "259         1       2  female  50.000000      0      1   26.0000  Southampton   \n",
       "306         1       1  female  29.699118      0      0  110.8833    Cherbourg   \n",
       "\n",
       "     alone  pclass  sibsp  parch  alone  sex_male  embark_town_Queenstown  \\\n",
       "583      1       1      0      0      1         1                       0   \n",
       "165      0       3      0      2      0         1                       0   \n",
       "50       0       3      4      1      0         1                       0   \n",
       "259      0       2      0      1      0         0                       0   \n",
       "306      1       1      0      0      1         0                       0   \n",
       "\n",
       "     embark_town_Southampton  embark_town_Southhampton  \n",
       "583                        0                         0  \n",
       "165                        1                         0  \n",
       "50                         1                         0  \n",
       "259                        1                         0  \n",
       "306                        0                         0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a531cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#removed the columns from each df (train, validate, test)not needed (duplicated info)\n",
    "train = train.drop(columns=['sex', 'embark_town'])\n",
    "validate = validate.drop(columns=['sex', 'embark_town'])\n",
    "test = test.drop(columns=['sex', 'embark_town'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82530455",
   "metadata": {},
   "source": [
    "Setting up our train_validate_test..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5fb155d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's do our train/validate/test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def train_validate_test_split(df, target, seed=123):\n",
    "    '''\n",
    "    This function takes in a dataframe, the name of the target variable\n",
    "    (for stratification purposes), and an integer for a setting a seed\n",
    "    and splits the data into train, validate and test. \n",
    "    Test is 20% of the original dataset, validate is .30*.80= 24% of the \n",
    "    original dataset, and train is .70*.80= 56% of the original dataset. \n",
    "    The function returns, in this order, train, validate and test dataframes. \n",
    "    '''\n",
    "    train_validate, test = train_test_split(df, test_size=0.2, \n",
    "                                            random_state=seed, \n",
    "                                            stratify=df[target])\n",
    "    train, validate = train_test_split(train_validate, test_size=0.3, \n",
    "                                       random_state=seed,\n",
    "                                       stratify=train_validate[target])\n",
    "    return train, validate, test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377cc4ed",
   "metadata": {},
   "source": [
    "Splitting data into train, validate and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9325ba3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create X & y version of train, where y is a series with just the target variable and X are all the features. \n",
    "\n",
    "X_train = train.drop(columns=['survived'])\n",
    "y_train = train.survived\n",
    "\n",
    "X_validate = validate.drop(columns=['survived'])\n",
    "y_validate = validate.survived\n",
    "\n",
    "X_test = test.drop(columns=['survived'])\n",
    "y_test = test.survived"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be9527a",
   "metadata": {},
   "source": [
    "*Q: WHAT IS YOUR BASELINE PREDICTION?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a58a38ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    307\n",
       "1    191\n",
       "Name: survived, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#finding baseline\n",
    "train.survived.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63016eea",
   "metadata": {},
   "source": [
    " -  <b> Baseline variable == Not Survived </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "871c0119",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6164658634538153"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['baseline_prediction'] = 0\n",
    "baseline_accuracy = (train.baseline_prediction == train.survived).mean()\n",
    "baseline_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21409730",
   "metadata": {},
   "source": [
    "### Exercise 2) <br> Fit the decision tree classifier to your training sample and transform (i.e. make predictions on the training sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1827a641",
   "metadata": {},
   "source": [
    "- Creating the decision tree object :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f31bfe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating that decision tree!\n",
    "\n",
    "clf = DecisionTreeClassifier(max_depth=2, random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd40ad54",
   "metadata": {},
   "source": [
    "- Fit the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "01b8306a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit(X, y)\n",
    "clf = clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e38c3cad",
   "metadata": {},
   "source": [
    "- Visualize a decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e8f8ac56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(390.6, 317.09999999999997, 'sex_male <= 0.5\\ngini = 0.473\\nsamples = 498\\nvalue = [307, 191]\\nclass = 0'),\n",
       " Text(195.3, 190.26, 'pclass <= 2.5\\ngini = 0.365\\nsamples = 175\\nvalue = [42, 133]\\nclass = 1'),\n",
       " Text(97.65, 63.420000000000016, 'gini = 0.081\\nsamples = 94\\nvalue = [4, 90]\\nclass = 1'),\n",
       " Text(292.95000000000005, 63.420000000000016, 'gini = 0.498\\nsamples = 81\\nvalue = [38, 43]\\nclass = 1'),\n",
       " Text(585.9000000000001, 190.26, 'fare <= 18.275\\ngini = 0.295\\nsamples = 323\\nvalue = [265, 58]\\nclass = 0'),\n",
       " Text(488.25, 63.420000000000016, 'gini = 0.184\\nsamples = 205\\nvalue = [184, 21]\\nclass = 0'),\n",
       " Text(683.5500000000001, 63.420000000000016, 'gini = 0.43\\nsamples = 118\\nvalue = [81, 37]\\nclass = 0')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAxsAAAGKCAYAAABke1wGAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAADUGUlEQVR4nOzdd1RUx9sH8O+lS0eKgmVRrC9iRRARAQvYRcWCFVGjxhIUY2KJYO+JxprEAIoBg4oIIopRFkSqDStW0AhYQIpKh3n/8MfGdRdYEFzQ53POnMjM3LnP3QDD3Dszl2OMgRBCCCGEEEJqm4y0AyCEEEIIIYR8mWiwQQghhBBCCKkTNNgghBBCCCGE1AkabBBCCCGEEELqBA02CCGEEEIIIXWCBhuEEEIIIYSQOkGDDUIIIYQQQkidkJN2AIQQUhMcxzXjOG60mppad1lZWU2O46QdEiG1jjFWUlBQkJ6fnx8G4BxjrFDaMRFCSHVw9FI/QkhDwnGcioaGxoni4uK+I0eOLLW0tFRWU1MDDTbIl6i4uBgvXrxgx44de3P79m250tLSBcXFxZ7SjosQQiRFgw1CSIPBcZySmpoaf9iwYV28vLyUFBUVpR0SIZ/N3bt3YWVllZ+TkzOfBhyEkIaCBhuEkAaD47ipvXr12hsVFaUiKysr7XAI+ezu3r2Lbt265RUWFjamKVWEkIaAFogTQhoMLS2t6fPnz6eBBvlqdezYEf/3f/9XAmCAtGMhhBBJ0GCDENJgvH37tveQIUOkHQYhUuXo6KjWqFEje2nHQQghkqDdqAghDQLHcQoyMjJympqa0g6FEKlq2rQpp6Sk1FTacRBCiCToyQYhpKGQk5WVLaNdp8jXTl5eHhzHyUs7DkIIkQQNNgghhBBCCCF1ggYbhBBCBPh8PjiOg4eHh7RDIYQQ8gWgwQYhhBDyPwkJCRgyZAi0tLSgoqICMzMz+Pr6VquN8gFbRSk2NraOoieEkPqHFogTQggheD9IsLe3h4KCAiZMmAANDQ0EBARg0qRJSElJwfLly6vVnrW1NWxsbETymzdvXksRE0JI/UeDDUIIIfVSfn4+7ty5gx49etT5uUpKSjBz5kxwHIfIyEh069YNAODu7g4LCwu4u7tj7NixaNu2rcRt2tjY0HQ0QshXj6ZREUK+Gv7+/ujbty/09PSgpKQEAwMDDBw4ECdOnBCpe+PGDUyYMAH6+vpQUFAAj8fDggULkJmZKajz6tUr6OvrQ0NDA48fPxY6/uXLl2jSpAk0NTXx5MmTasWZkpICjuPg7OyMu3fvYtiwYdDU1ISWlhacnJyQkZEBAIiOjkb//v2hrq4OLS0tzJw5E+/evRNqq6ioCLt27YK9vT1atGgBRUVF6OnpYdSoUbh69Wq14nr58iUWLVqENm3aQFFRETo6OhgzZgxu3bpVrXYqwxgDn8+Hi4sLmjRpgrVr19Za25U5f/48Hj16hIkTJwoGGgCgpqaGVatWoaSkBF5eXp8lFkII+ZLQkw1CyFdh9+7dWLBgAfT19TFq1Choa2sjPT0d8fHxOHnyJEaNGiWoGxQUhHHjxkFOTg4jRoxA8+bNcefOHezevRtnz55FXFwctLS0oKuri0OHDsHe3h4TJ05EVFQU5OTkwBiDs7MzXr58CT8/P/B4vBrFnJycjN69e8PU1BQzZ87E5cuXceTIETx9+hSbNm2CnZ0d7Ozs8M0334DP5+PPP/9EWVkZPD09BW28fv0arq6usLKyEqxFePz4MYKCghAaGoqIiAiYm5tXGcujR49gY2OD1NRUDBo0CKNGjcKLFy9w/PhxnD17FufPn5eonYrcu3cPPj4+OHz4MJ48eQKO42BlZYXp06fXuM3qiIiIAADY24u+K8/Ozk6ojqQePHiAX3/9FXl5eeDxeBgwYAB0dXU/PVhCCGlIGGOUKFGiVO8TAGV5efliVkPdunVjCgoK7MWLFyJlGRkZQv9WV1dnLVu2ZM+ePROq5+vrywCwefPmCeUvWbKEAWDLly9njDG2Y8cOBoBNmzatRrEmJyczAAwA27FjhyC/rKyMDRkyhAFgGhoaLDAwUFBWVFTEOnfuzOTk5Njz588F+QUFBSLXwRhjt27dYqqqqqx///5C+eHh4QwAc3d3F8rv3bs3k5OTY+fPnxfKv3fvHlNTU2OdOnWq9nVmZGSw3bt3MzMzM8H1Ghsbsw0bNrAnT56IPSY5OZm5u7tLnH755ReJYnF0dGQA2OXLl8WW6+joMF1dXYnaKv8MP05KSkps48aNErVRmUOHDrHGjRufYPXg55ISJUqUqkpSD4ASJUqUJEmfOtjo3r07U1FRYVlZWZXW+/nnnxkA5uPjU2E72trarKysTJBXWFjIunfvzmRkZNivv/7KFBUVmZGREcvNza1RrOWDDSMjI6HzMPb+D00AzNbWVuS4NWvWMADswoULEp1n+PDhTEFBgRUVFQnyxA02rl69ygCwGTNmiG1n8eLFDAC7ceNGlecsLCxkAQEBzMHBgcnLyzMArFmzZszNzY1du3atyuMr+kO+osTj8apskzHGBg4cyACwBw8eiC1v3bo1U1BQkKitW7dusa1bt7K7d++yd+/esdTUVHb48GHWrFkzBoDt2bNHonYqQoMNSpQoNaRE06gIIV8FJycnfP/99+jUqROcnJxgY2MDS0tLaGpqCtUr35Y0NjYWDx8+FGmnoKAAmZmZyMzMhI6ODgBAQUEBfn5+6N69OxYuXAg5OTn4+vpCTU3tk2Lu3LkzPn5jur6+PgCga9euIvXLy9LS0oTyr1+/ji1btiAqKgrPnz9HcXGxUHlGRobgWHHKP5Pnz5+LXfCclJQE4P1UKBMTk0qvaePGjfDw8ADHcZg0aRKcnZ1ha2sLGRnJlhDa2NiAMSZRXWkxNjaGsbGx4GtlZWVMmjQJnTt3hqmpKVavXo05c+ZIfM2EENKQ0WCDEPJVWLJkCRo3box9+/Zh+/bt2LZtG+Tk5DBkyBDs2LEDrVq1AvB+jQMA7Nmzp9L23r17JxhsAEDbtm1hYmKC2NhYmJmZwczM7JNjVldXF8mTk5OrsuzDwUR0dDT69esH4P3ag7Zt20JVVRUcxyEwMBCJiYkoLCysNI7yzyQkJAQhISEV1vt4cbo4rVu3hrKyMvLy8hAWFgYtLS2oqqp+0nqP2qChoQEAyMnJEVuem5srqFNTJiYmMDc3x8WLF/Hw4UO0a9fuk9ojhJCGgAYbhJCvhouLC1xcXJCZmYmLFy/Cz88P/v7+ePjwIW7cuAFZWVnBH/E3b95Ep06dJG5769atiI2Nhba2NqKjo/HHH39g1qxZdXUpElu/fj0KCwsRFRUFS0tLobLY2FgkJiZW2Ub5Z7Jr1y7Mnz//k+KZMmUKRo0ahePHj+PQoUPYs2cPdu3ahbZt22LSpEmYNGkS2rRpU+HxKSkp8Pb2lvh8mpqacHV1rbJe+Za2Dx48ENlqNysrCxkZGejdu7fE561I+QA1Ly/vk9sihJCGgAYbhJCvjra2NhwcHODg4ICMjAxcuHABDx8+RPv27WFubo6AgADExMRIPNi4cuUKVq5ciY4dO+L8+fOwsLCAq6sr+vbti/bt29fx1VTu0aNH0NbWFhlo5OXlSbz1bflTh5iYmE8ebACAqqoqpk2bhmnTpuHZs2c4fPgwfHx84OHhAQ8PD5ibm2Py5MkYP368yO5NKSkpWL16tcTn4vF4Eg02rK2tsXHjRoSFhWHChAlCZWFhYYI6n6K0tBTXrl0Dx3Fo2bLlJ7VFCCENBU0YJYR8Fc6ePYuSkhKhvOLiYsEUISUlJQDA9OnToaamhhUrVuD27dsi7eTl5QnWMADvpw5NnDgRHMfB19cX+vr6OHz4MAoLCzFx4kQUFRXV4VVVjcfj4fXr10LXUlpaiiVLluDVq1cStWFmZgZzc3P4+fnh77//FikvKyur9raw5Zo3b44ff/wRt2/fxuXLl7Fw4UIkJydjwYIFMDAwEHlrd/maDUlTSkqKRHH0798frVu3hq+vL65fvy7If/PmDdauXQs5OTk4OzsLHZORkYGkpCTBe0/KxcTEiKwrKS0txQ8//ICUlBTY29ujcePGEn9GhBDSkNGTDULIV2H8+PFQVlZGnz59wOPxUFxcjHPnzuHOnTsYN26c4F0Yurq68PPzw9ixY9GlSxcMHjwY7du3R0FBAZ48eYKIiAj07t0bZ86cAQAsXLgQ9+/fx88//yxYtN2nTx8sX74ca9euxfLly7Ft2zZpXTYWLFiAsLAw9OnTB+PGjYOSkhL4fD5SU1NhY2MDPp8vUTt+fn6wtbXFhAkTsGPHDvTo0QNKSkp4+vQpYmJi8OrVKxQUFHxSrD169ECPHj2wfft2nDlzBj4+PkhOTv6kNiUlJyeHAwcOwN7eHlZWVnBycoK6ujoCAgKQnJyMdevWiayx2L17N1avXg13d3ehhfNOTk7gOA69e/dGs2bNkJOTg8jISCQlJaFly5bYv3//Z7kmQgipD2iwQQj5KmzcuBFnzpxBfHw8goODoaKigjZt2uC3336Di4uLUN2hQ4fi2rVr2Lp1K/755x+EhYVBRUUFzZs3x/Tp0zF58mQAwLFjx+Dp6YmBAweKTNVZtWoVzp07h59//hn29vYYOHDg57pUIcOGDcOxY8ewYcMGHD58GMrKyujXrx9OnDiBNWvWSNxOq1atcO3aNfz8888IDAyEp6cnZGVloa+vj759+8LR0bHWYpaTk8OwYcMwbNgwlJaW1lq7VbG1tUVUVBTc3d3h7++PoqIiGBsbY+3atZg0aZLE7cydOxdnzpwBn89HRkYG5OTk0KZNG6xYsQJubm7Q0tKqw6sghJD6havvWwgSQggAcBynLC8vn1NUVEQ3SchXzcfHB66uroGZmZmjqq5NCCHSRWs2CCGEEEIIIXWCBhuEEEIIIYSQOkHTEQgh5DPYsWMHsrOzq6zn7OwMQ0PDOo+HEEII+RxosEEIIZ/Bjh078OTJkyrr2djY0GCDEELIF4MGG4QQ8hlI+r4HQggh5EtCazYIIYQQQgghdYIGG4QQQgghhJA6QYMNQgiREhsbG3Ac98ntcBwHGxubTw+IEEIIqWU02CCEEFJrEhISMGTIEGhpaUFFRQVmZmbw9fX9pDaLi4vRtWtXcByHDh06iJR7e3uD47hKU//+/YWO8fPzw+jRo2FkZAQ1NTWoqqrC2NgYixYtQmpq6ifFSwgh5D+0QJwQQqTk0KFDyMvL++R27t69C2Vl5VqI6NPw+XzY29tDQUEBEyZMgIaGBgICAjBp0iSkpKRg+fLlNWp37dq1ePjwYYXlXbt2hbu7u9iyY8eO4fbt27C3txfK9/f3x927d9GrVy/o6+uDMYbr169j586d8Pb2xsWLF9GpU6caxUsIIeQ/HGNM2jEQQkiVOI5TlpeXzykqKqKbJPVQSUkJOnTogGfPniEmJgbdunUDALx58wYWFha4d+8e7ty5g7Zt21ar3atXr8Lc3Bw///wzFi5ciPbt2yMpKUmiY4uKimBgYICcnBw8e/YMTZo0EZQVFBRASUlJ5Jg///wTM2fOxJgxY3Ds2LFqxfq5+Pj4wNXVNTAzM3OUtGMhhJCq0DQqQgipJSUlJdi4cSOMjIygpKSENm3aYOPGjXj8+DE4joOzs7NQfXFrNsqnBHl7eyMsLAy9e/eGsrIytLW1MXXqVGRkZIictz6s2Th//jwePXqEiRMnCgYaAKCmpoZVq1ahpKQEXl5e1WqzqKgIzs7O6NWrF+bPn1/tmE6cOIHMzEwMGzZMaKABQOxAAwDGjh0LAHj8+HG1z0cIIUQU3SEkhJBa4uLiAh8fHxgZGWHevHkoLCzEL7/8gpiYmGq3FRQUhJCQEAwfPhy9e/dGZGQkfHx88ODBA0RHR9fKwvLaFBERAQAi05UAwM7OTqiOpDw8PPDgwQMkJibW6Hr//PNPAMDMmTMlPiYkJAQAYGJiUu3zEUIIEUWDDUIIqQXnz5+Hj48PTE1NERkZiUaNGgEAVq5cKXSnX1LBwcHg8/mwtLQEAJSWlmLAgAHg8/mIjY2FhYVFjeJMSUmBt7e3xPU1NTXh6upaZb0HDx4AANq0aSO2DR0dHUEdSSQkJGDLli3YsGED2rVrJ/Fx5Z48eYLz58+jWbNmGDRoUIX1/P39cefOHeTl5eH27ds4e/YsjIyMsGbNmmqfkxBCiCgabBBCSC04fPgwAOCnn34SDDQAoGnTpvjuu++wbNmyarU3ceJEwUADAGRlZTFt2jTw+Xxcvnz5kwYbq1evlrg+j8eTaLCRk5MDANDQ0BBbrq6ujmfPnkl0zsLCQjg7O6Nbt25wc3OTONYPeXl5oaysDNOnT4esrGyF9fz9/XH8+HHB16ampvj777/B4/FqdF5CCCHCaM0GIYTUgsTERABA7969RcrE5VWlR48eInnNmzcHAGRnZ1e7vXI2NjZgjEmcUlJSanyumvrpp5/w4MEDeHp6VjpQqEhZWRm8vLzAcRxcXFwqrXvs2DEwxpCVlYULFy5AXl4e3bt3x4ULF2oaPiGEkA/QYIMQQmpBbm4uZGRkoK2tLVL28eJkSairq4vkycm9fxhdWlpa/QDrWPkTjfInHB/Lzc2t8KnHh65evYqff/4ZK1asqPG6iXPnzuHp06fo168fWrVqJdExmpqasLW1xZkzZ6CsrIypU6eiuLi4RucnhBDyH5pGRQghtUBdXR1lZWXIzMyEjo6OUNmLFy+kFJWoulqzUb6l7YMHD0SeymRlZSEjI0OiJzw3btxAaWkpPDw84OHhIVJ+7949cBwHDQ2NCp/w1GRheDl1dXWYm5sjMDAQDx8+RMeOHavdBiGEkP/QYIMQQmpBly5dcO3aNURHR2PEiBFCZdHR0VKKSlRdrdmwtrbGxo0bERYWhgkTJgiVhYWFCepUpV27dpgxY4bYsj///BMaGhpwdHSs8CWGmZmZOHnyJBo3boxRo2r2Goq0tDQAgLy8fI2OJ4QQ8h8abBBCSC2YNGkSvL29sXbtWtjZ2Qne4/D8+XPs3LlTytH9p3zNRm3r378/WrduDV9fXyxcuBBdu3YF8P6lfmvXroWcnJzIe0YyMjKQkZEBHR0dwdOg3r17V/gE5M8//0TTpk1x4MCBCuPw8fFBUVERJk+eDEVFRbF13rx5gwcPHqB79+4iZV5eXoiPj0fbtm3F7qxFCCGkemiwQQghtWDAgAGYNGkS/vrrL5iYmGDkyJEoLCyEv78/zM3NERwcDBmZL3eZnJycHA4cOAB7e3tYWVnByckJ6urqCAgIQHJyMtatWyeyhe3u3buxevVquLu7i50yVROSTKHKzMxEjx490LVrV5iYmKBZs2bIyspCQkICrl69CnV1dRw8eLBW4iGEkK8dDTYIIaSWeHt7o0OHDvD09MSuXbvQvHlzuLq6on///ggODpZogXRDZmtri6ioKLi7u8Pf3x9FRUUwNjbG2rVrMWnSpDo/f3x8PG7dugUzM7NKF5fr6upi1apV4PP5OHfuHDIzM6GgoABDQ0MsWrQIixcvFuz8RQgh5NNwdfE4nRBCahvHccry8vI5RUVFDe4myYEDBzBr1izs27cPc+bMkXY4pIHz8fGBq6trYGZmZs0WpRBCyGf05T7TJ4SQz+z58+ci6yFSU1Oxbt06yMnJYfjw4VKKjBBCCJGOBneHkBBC6qtNmzYhJCQEVlZW0NPTw9OnT3Hq1CnBIulmzZpJO0RCCCHks6LBBiGE1JJBgwbh3r17OHPmDDIzM6GoqIguXbpg3rx5ItvBEkIIIV8DGmwQQkgtGTRoEAYNGiTtMAghhJB6g9ZsEEIIIYQQQuoEDTYIIYQQQgghdYIGG4QQ8pUwNDSEoaGhtMMghBDyFaHBBiGEkC9SbGwsZGVlwXEcNm3aJLbOs2fPMHv2bLRs2RIKCgowMDDA9OnT8e+//4qtzxjDsWPHYGNjA319fSgrK6N9+/aYPXs2Hj9+XJeXQwghDRINNgghhHxx8vPz4ezsjEaNGlVY5+HDh+jRowd+//13dOjQAd999x3MzMxw8OBBmJqa4tGjRyLHuLq6YuzYsbh//z4cHBywYMECtGrVCn/88Qe6du2KGzdu1OVlEUJIg0ODDUIIIV+cFStWID09HT/++GOFdVxdXfHy5Uvs3LkTYWFh2Lp1KwIDA/H333/j5cuXmDdvnlD99PR07Nq1CzweD3fv3sW+ffuwefNmnDlzBtu3b8ebN2/wyy+/1PWlEUJIg0KDDUIIEcPf3x99+/aFnp4elJSUYGBggIEDB+LEiRNC9Tw9PTFy5EgYGhpCSUkJjRs3hp2dHc6fPy/SJp/PB8dx8PDwQHR0NGxtbaGmpgZdXV18++23yM/PBwCEhITAwsICKioqaNKkCZYuXYqSkhKhtry9vcFxHLy9vREQEICePXtCWVkZTZs2xdy5c5GVlSXxtTLG4OnpCUtLS6irq0NZWRmmpqbw9PQUqZufn48tW7agc+fO0NDQgIqKCgwNDTF+/HjcvHlT4nPWpUuXLmHnzp3Ytm0bmjdvLrZOQUEBzp49iyZNmmDBggVCZWPHjkXXrl1x9uxZoalRT58+BWMMlpaW0NDQEDpm2LBhAIBXr17V8tUQQkjDRoMNQgj5yO7duzF+/Hg8fPgQo0aNwuLFi2Fvb4+0tDScPHlSqO68efPw4sULDBgwAIsWLcKwYcMQGxsLOzs7kYFJubi4OPTv3x8aGhqC9QL79u3DzJkzceTIETg6OoLH42H27NnQ1NTE1q1bsWHDBrFtHT16FE5OTmjfvj2+++47tG7dGvv374etra1g8FIZxhgmT56MGTNmIDMzE5MmTcLMmTPx7t07zJgxA0uWLBGqP2XKFPzwww/gOA7Tp0/H/PnzYWFhgYiICFy5ckXCT7ju5OXlwdnZGTY2Npg1a1aF9TIzM1FSUgIejweO40TKW7VqBQAIDw8X5LVp0wYKCgq4dOkScnNzheqfOnUKANCvX7/auAxCCPli0Ev9CCHkI56enlBQUMD169ehp6cnVJaZmSn09Z07dwR/mJZLT0+Hqakpli5dilGjRom0f+bMGQQGBmLkyJEAgOLiYpiamsLPzw9nz55FZGQkevbsCQBYvXo12rRpg507d2LZsmWQl5cXauv06dP4559/0L9/f0Gei4sLvLy8sG3bNvz000+VXuuBAwfg6+uLb775Bnv37oWsrCwAoKioCI6Ojti+fTsmTJgAU1NT5OTkICAgAD169EBcXJygLgCUlpbizZs3lZ6rnIeHh0T1yrm6ukJTU1Oiuj/++CPS09MRFhZWaT0tLS3IysriyZMnYIyJDDiSk5MBAPfv3xfkaWtrY9OmTXBzc0OHDh0wcuRIqKurIzExERcuXMDs2bNFnpIQQshXjzFGiRIlSvU+AVCWl5cvZp9B9+7dmYqKCsvKyqpxGwsWLGAAWEpKiiAvPDycAWC2trYi9desWcMAsOnTp4uUubi4MADs8ePHgjwvLy8GgA0cOFCkfmpqKpOXl2dGRkZC+Twej/F4PKG8zp07M1VVVZafny/Szo0bNxgAtnjxYsYYYzk5OQwAs7S0rPziqwCgWik5OVmidvl8PuM4ju3cuVOQV/45bdy4UaS+ra0tA8B2794tlH/8+HHBub/55huR4/z8/JiqqqpQjL1792aRkZHV+yBq6NChQ6xx48YnWD34uaREiRKlqhI92SCEkI84OTnh+++/R6dOneDk5AQbGxtYWlqKvbv++PFjbNy4ERcuXEBqaioKCwuFytPS0sDj8YTyunbtKtKOvr5+lWVpaWkiT1GsrKxE6hsYGMDIyAhJSUl48+YN1NTUxF5nXl4ebt68CQMDA7FbwxYXFwMA7t27BwBQV1fH0KFDERISgh49emDMmDGwsrKCubk5FBQUxJ5DHMaYxHUl9e7dO7i4uMDCwgLz58+X6JhffvkFffr0wfz58xEcHIzOnTvj4cOHOHnyJDp37owbN24IPb0BgDVr1mDdunXw8PDA1KlToaWlhevXr2Px4sWwtbWFv78/Ro8eXevXRwghDRUNNggh5CNLlixB48aNsW/fPmzfvh3btm2DnJwchgwZgh07dgj+4H/48CHMzMyQm5sLW1tbDB8+HOrq6pCRkQGfz0dERITI4AN4/0f7x+Tk5KosK//j/0MfT/Mq16RJEyQlJSE3N7fCwUZWVhYYY0hNTcXq1asr+DTe/yFfzt/fHxs2bICvry9WrFgBAFBTU4OLiws2bNgAZWXlCtupSytWrEBaWhpOnz4NGRnJliN26dIFCQkJcHd3R3h4OMLDw9GmTRv89ttvyM7Oxvfffw9dXV1B/fPnz8Pd3R2LFi3C8uXLBfmWlpY4deoUWrduDVdXVxpsEELIB2iwQQghYri4uMDFxQWZmZm4ePEi/Pz84O/vj4cPHwrueP/yyy/IysrC4cOHMWnSJKHj58yZg4iIiDqP8+XLl2LzX7x4AUD84KVceVmPHj1w+fJlic6nrKyMdevWYd26dUhOTkZ4eDj279+PnTt3Ij8/H7/99luVbdTFmo3r16+joKAAHTp0EFu+bNkyLFu2DN999x127NghyO/QoQP+/vtvkfrOzs4AAFNTU0He6dOnAQC2trYi9XV1dWFiYoKYmBhkZGRAR0eniqsihJCvAw02CCGkEtra2nBwcICDgwMyMjJw4cIFPHz4EO3btxe89K18oXe5srIyXLp06bPEd/HiRZG8tLQ0PHr0CEZGRhU+1QDeP5Ho2LEj7t69i+zsbIkXYZdr1aoVWrVqBScnJ+jp6SEoKEiiwUZlT1HEcXZ2rjK2oUOHok2bNiL5Dx48ECy479y5MywsLKo835s3bxAcHIzGjRtj4MCBgvyioiIAFW9vW56vqKhY5TkIIeRrQVvfEkLIR86ePSvyXovi4mK8fv0aAKCkpAQAgrUYkZGRQnU3b96MW7dufYZIgXPnzom802PlypUoLi7GtGnTqjx+4cKFyMvLw6xZs5CXlydSnpycjJSUFADv/5iOj48XqZOVlYXCwkLB51KV6i4uNDQ0rLLN77//HgcOHBBJ06dPBwCMHj0aBw4cwPjx4wXH5Ofni/x/LiwsxIwZM/D69Wu4u7sLXZOlpSUA4Oeff0ZOTo7Qcd7e3oI3klc2wCOEkK8NPdkghJCPjB8/HsrKyujTpw94PB6Ki4tx7tw53LlzB+PGjRMMMubMmQMvLy+MGTMG48ePh7a2NmJjY3H16lXBQuq6NnToUAwZMgRjx45FixYtEBERgZiYGHTp0kXkHRnizJ49G7GxsTh48CCio6PRv39/GBgY4MWLF0hKSkJcXBx8fX1haGiI1NRUmJubw9jYGN27d0ezZs2QmZmJkydPori4GN9//32dX29tunLlCkaPHo2BAweiRYsWyM3NRUhICJ4+fYpZs2aJfdnfb7/9Bj6fj7Zt22LEiBHQ0tJCYmIizp07B0VFRaEpWoQQQmiwQQghIjZu3IgzZ84gPj4ewcHBUFFRESwcdnFxEdTr1q0bwsLCsHLlSgQEBEBWVha9e/fGpUuXEBQU9FkGG46OjpgxYwbWr1+P48ePQ11dHbNnz8aGDRvQqFGjKo8vfwv5kCFD8Mcff+DUqVN4+/Yt9PT00LZtW2zbtg0DBgwAABgaGsLDwwMXLlzAP//8g8zMTOjo6KB79+5YtGgR7Ozs6vpya1XLli1hY2ODixcv4sWLF1BWVkb37t3x888/Y8yYMSL1ZWVlcebMGezcuRN///03/Pz8UFRUBD09PTg5OWHZsmUwMTGRwpUQQkj9xdXFFoSEEFLbOI5TlpeXzykqKqKbJHg/bWf69Onw8vISLGYmXwcfHx+4uroGZmZmir4xkhBC6hlas0EIIYQQQgipEzTYIIQQQgghhNQJGmwQQgghhBBC6gTNfSaEkAbI2dmZ1moQQgip9+jJBiGEEEIIIaRO0GCDEEIIIYQQUidosEEIIRKwsbEBx3HSDqPOGRoaguM4QUpKSpJ2SF+FyZMnC33u3t7e0g6JEEJqBQ02CCGECNHQ0IC7uzvc3d2ho6MjyC8sLISbmxv69u0LAwMDKCkpoWnTprC0tISXlxeKi4vFtpebm4vFixeDx+NBUVERPB4PixcvRm5urkhdZ2dnoT+6xaW1a9d+0vVdv34dy5cvh729PXR1dcFxHGxsbCo9JisrC0uWLEGbNm2gqKgIXV1dODo64vbt22LrBwcHY8GCBbC0tISKigo4joOHh0eF7Y8ePRru7u4YOXLkJ1wZIYTUP7RAnBBCiBBNTU2xfxjn5+dj7969MDMzw9ChQ6Grq4usrCyEhobCxcUFR44cQWhoKGRk/ruP9e7dO1hbW+P69esYOHAgnJyckJiYiF9++QXh4eGIioqCioqKoL6DgwMMDQ3FxrVt2za8e/cO9vb2n3R9gYGB2LhxIxQUFNCuXTtkZGRUWj8zMxMWFhZ48OABLCwsMHLkSKSnp+P48eMIDQ3FhQsXYG5uLnTM9u3bERERAXV1dRgYGODhw4eVnmP06NEYPXo0vL29cfLkyU+6PkIIqVcYY5QoUaJU7xMAZXl5+WImJdbW1uz9r8wvG4/HYzweT2xZWVkZKywsFMkvLi5mNjY2DAALDg4WKlu1ahUDwJYuXSo2f9WqVRLFdfnyZQaAmZiYSHYhlbh16xa7cuUKKyoqYunp6QwAs7a2rrD+vHnzGAC2ePFiofzo6GgmKyvL/u///o+VlpYKlUVGRrL79++zsrIy5ufnxwAwd3f3KmPz8vJiAJiXl1eFdQ4dOsQaN258gtWDn0tKlChRqirRNCpCSIMXGRkJjuMwY8YMseXPnj2DrKys0FSZK1euYP78+ejUqRM0NDTQqFEjdOrUCRs2bKhwOtDHPDw8wHEc+Hy+SJm3t3eFc+9v3LiBCRMmQF9fHwoKCuDxeFiwYAEyMzMlOq+0cBwHBQUFkXw5OTmMGjUKAPD48WNBPmMMBw4cgKqqKlatWiV0zLJly6ClpYUDBw6AMVbluQ8cOAAAFf4/rg5jY2N0794d8vLyEtUPDAyEjIwMVq9eLZRvYWGB4cOH486dOyLfA1ZWVmjbtu1Xsc6HEEIqQ4MNQkiDZ2VlBUNDQxw/fhwFBQUi5X/99RfKysowZcoUQd4ff/yBEydOwMTEBLNnzxb8EbtixQqMGzeuzmINCgqCmZkZTp06BVtbW7i6usLExAS7d++GhYUFsrKy6uzcdaWsrAxnzpwBAJiYmAjyHzx4gLS0NPTp00doqhQAKCkpoW/fvkhLS6tyilF+fj78/PygqKgo9P/wc3nx4gV0dHSgqqoqUtaqVSsAQHh4+OcOixBCGgRas0EIafA4jsOkSZOwfv16BAcHY+zYsULlf/31F5SUlODo6CjIW7ZsGfbs2QNZWVlBHmMMM2fOhKenJ6KiotCnT59ajTMzMxNTpkxBkyZNEB0djWbNmgnK/Pz8MHHiRPz000/YvXt3lW15e3sjJSVF4nM7ODiga9euNYhaVFFRETZs2ADGGDIzM3H+/HkkJSVh5syZsLW1FdR78OABAKBNmzZi22nbtq2gXvm/xTl27BhycnIwYcIENG7cuFauoTp0dHTw8uVLvH37VmTAkZycDAC4f//+Z4+LEEIaAhpsEEK+CFOmTMH69etx+PBhocFGYmIibt68iXHjxkFDQ0OQz+PxRNrgOA7z5s2Dp6cnzp8/X+uDjUOHDiE3Nxd79uwRGmgAgJOTE7Zt24YjR45g165dVU6/8fb2RkREhMTnNjQ0rNXBxodTijiOw9KlS7F+/Xqhejk5OQAg9Ll/SF1dXaheRf78808AwMyZM2sc86cYPHgwvLy8sHr1amzdulWQHx8fj1OnTgEAsrOzpRIbIYTUdzTYIIR8Edq3bw9TU1OEhobi9evXgjvgPj4+ACAy/aaoqAi7d+/GkSNHkJSUhLdv3wqtHUhLS6v1GGNjYwX/FTd1qKCgAJmZmcjMzBTaclYccetEPhdVVVUwxlBWVoa0tDQEBwdj+fLluHTpEk6fPi0YRNSGhw8fIjIyEq1atUK/fv1qrd3qWLNmDc6cOYNt27YhJiYGvXr1Qnp6Oo4dO4b/+7//w40bN4SekBFCCPkPDTYIIV+MKVOm4PLly/D398ecOXNQVlYGPz8/6OrqYtCgQUJ1HR0dERwcjHbt2mH8+PHQ09ODvLw8srOzsXPnThQWFtZ6fK9fvwYA7Nmzp9J67969q3KwUR/IyMigefPmmDt3LnR0dDBu3DisX78emzdvBvDfE42KnlyUv2ejoicfwPunGowxuLi4SG2xdfPmzZGQkAB3d3eEhoYiPj4eLVq0wJo1a2BoaIgJEyZAV1dXKrERQkh9R4MNQsgXY8KECXBzc8Phw4cxZ84cXLhwAWlpaViwYAHk5P77dZeQkIDg4GDY29sjJCRE6K50bGwsdu7cKdH5yt8nUVJSIlIm7g/s8jv+N2/eRKdOnap1bR+T5poNcezs7AAIP3H5cE2GOOX5Fa3XKC0txcGDByErK4vp06fXYrTV16xZM8GOWB8qfx+JqanpZ46IEEIaBhpsEEK+GHp6erCzs0NoaCiSk5Nx+PBhAKJTqB49egQAGDZsmMj0l4sXL0p8Pi0tLQBAamqqSNm1a9dE8szNzREQEICYmJhaGWxIa82GOOXTzj7cTrZt27YwMDDApUuX8O7dO6EdqQoKChAZGQkDA4MKF5CfPn0a6enpGDp0qMgal/qgtLQUR44cgZycHMaMGSPtcAghpF6irW8JIV+UKVOmCN7vEBAQgPbt26Nnz55CdcoXh0dGRgrl3759Gxs3bpT4XOV3sw8dOoSysjJBfkxMDP766y+R+tOnT4eamhpWrFiB27dvi5Tn5eUJ1nVUhc/nV+ulSs7OzhJfV0Vu3bol9l0geXl5WLx4MQBgyJAhgnyO4zBz5ky8ffsWa9asETpm48aNyMrKwsyZMyucHlW+MLyqd2s4OztX+E6T2lBcXIz8/HyhvLKyMixZsgT37t3DggULYGBgUCfnJoSQho6ebBBCvigjR46Euro6tm7diuLiYrHvZTAzM4OZmRmOHj2Kvn37olevXnj69CmCgoIwdOhQHDt2TKJzWVhYwNLSEhcuXICFhQX69u2LJ0+eICgoCMOHD8eJEyeE6uvq6sLPzw9jx45Fly5dMHjwYLRv3x4FBQV48uQJIiIi0Lt3b8E7K+qbY8eOYfPmzbCxsUGrVq2grq6O1NRUhIaGIjMzE1ZWVli0aJHQMUuXLkVQUBC2bNmCa9euoUePHkhMTERoaCi6du2KpUuXij3XixcvEBISgiZNmmD48OGVxlU+0PtwqlxlkpKSsGnTJgAQDCKSkpIEAzIdHR1s27ZNKBZjY2PY2dmhVatWKCoqwtmzZ5GUlIShQ4eKHaAGBgYiMDAQwH/b4wYGBgqmvvXp00dqu2sRQshnJe1XmFOiRImSJAmAsry8fDGTwPTp0xkAxnEcS05OFlvn5cuXzMXFhRkYGDAlJSVmYmLC9uzZwx4/fswAsGnTpgnVt7a2Zu9/ZQrLyMhgU6dOZY0bN2aNGjVivXr1YmfPnmVeXl4MAPPy8hI5Jikpic2YMYPxeDymoKDAtLS0mImJCVu4cCGLj4+X5BLrDI/HYzweT2xZQkICmzVrFjM2NmaamppMTk6OaWtrM1tbW/bbb7+x4mLx/3uys7PZokWLWIsWLZi8vDxr0aIFW7RoEcvOzq4wjs2bNzMAbOnSpVXG3K1bN6ampsZev34t0TWGh4czABWmj68/NzeXTZkyhbVu3ZopKSkxNTU1ZmFhwf744w9WWloq9hzu7u6VnuPj769ylX3flDt06BBr3LjxCVYPfi4pUaJEqarEMcZACCH1HcdxyvLy8jlFRUX0RLYOGRoaAkC1Fp9LU25uLrS0tODm5oYtW7ZIO5xP5u3tjenTp8PLy6vCqW8+Pj5wdXUNzMzMHPV5oyOEkOqjNRuEEEKEPHnyBBzHgeM4JCUlSTucSl26dAny8vKCNSMN1eTJk8FxnNR33SKEkNpGdwgJIYQIuLq6Cr0Nu76/72Pw4MEoKCiQdhifbPTo0UK7ctXlzmGEEPI50WCDEEKIgKurq7RD+CqNHj0ao0ePlnYYhBBS62gaFSGEEEIIIaRO0GCDEEIIIYQQUidosEEIIYQQQgipEzTYIISQBsTb27tO35ZNCCGE1CYabBBCCGmwfH19YWZmBhUVFWhpaWHIkCG4fPmytMMihBDyPzTYIIQQ0iBt2LABkyZNwosXLzBnzhyMGzcOly5dgqWlJfh8vrTDI4QQAtr6lhBCSAN0//59uLu7o127doiPj4eGhgYAYOHChTAzM8PMmTORlJQEOTnq5gghRJroyQYhhNQTkZGRcHBwQJMmTaCoqIgWLVpg9OjRiIqKqvLYEydOwMnJCW3atIGysjI0NDRgZWWFo0ePiq1/7tw52Nvbw8DAAIqKimjSpAmsrKxw4MABoXoJCQkYM2YMWrRoAUVFRejq6qJnz57YuHFjrVxzTXl5eaGkpAQrVqwQDDQAwNjYGNOmTcOjR49w4cIFKUZICCEEoMEGIYTUCzt37oSNjQ3OnTuHgQMHws3NDf369UNiYiKOHTtW5fHLli3D7du30adPH3z33XcYO3Ys7t27h3HjxmHnzp1CdYODg2Fvb4+EhATY29vDzc0NI0aMQEFBAf766y9BvatXr6JPnz44c+YMrKyssHjxYjg6OqJRo0Yig5LPLSIiAgBgb28vUmZnZydUhxBCiPTQ82VCCJGyxMRELF68GPr6+rh06RIMDQ0FZYwxpKenV9nG6dOn0bp1a6G8t2/fonfv3li1ahVmzZoFZWVlAO+fCjDGEB4eji5duggdk5mZKfj34cOHUVRUBH9/f4wcObLCepXh8/nVWj/RtWtXODg4VFnvwYMHUFVVRZMmTUTK2rZtK6hDCCFEumiwQQghUvbbb7+hrKwM69atExpoAADHcTAwMKiyjY8HGgCgqqoKZ2dnuLm5ISEhAdbW1oI2AQgGHx/S1tYWOrck9SrD5/OxevVqieoCwLRp0yQabOTk5EBPT09smbq6uqAOIYQQ6aJpVIQQImXx8fEA/pv+UxMvX77E4sWL0bFjRygrK4PjOHAcBzc3NwBAWlqaoK6TkxMAoFevXpg/fz6OHz+Oly9firQ5btw4yMjIYNSoUXBxcYGvry+ePn1arbg8PDzAGJM40ftDCCHky0KDDUIIkbKcnBxwHAd9ff0aHf/69Wv07NkTv/zyC7S1tTFjxgysXLkS7u7ugulPhYWFgvqOjo4IDAxEp06dsH//fjg6OqJp06bo168frl+/Lqhnbm4OPp8PKysr+Pr6YtKkSeDxeDA1NUV4ePgnXfOn0tDQqPDJRW5urqAOIYQQ6aJpVIQQImWampqCtRnNmjWr9vF//vknnj59inXr1mHFihVCZZs2bcLJkydFjhk5ciRGjhyJ3NxcREdHIyAgAH/++ScGDRqEpKQkaGpqAgCsrKwQGhqK/Px8xMXFITg4GHv37sXQoUNx69YtsdO3PlRXazbatm2LmJgYPH/+HE2bNhUqK1+rUb52gxBCiPTQYIMQQqTMzMwMly9fRlhYGKZPn17t4x89egQAIou4AeDixYuVHquuro5BgwZh0KBBKC0thaenJ+Li4kR2eWrUqBFsbGxgY2MDTU1NrFq1CufOncPs2bMrbb+u1mxYW1sjJiYGYWFhmDp1qlDZ2bNnBXUIIYRIF02jIoQQKZszZw5kZWWxcuVKPHnyRKhMkt2oeDwegPfv6fiQr68vTp8+LVL//PnzKCgoEMkvX7ehpKQE4P1ApXxK0odevHghVK8ydbVmY/r06ZCTk8P69euFplPdvn0bhw4dgpGREfr16ydRW4QQQuoOPdkghBApMzExwY4dO7Bw4UIYGxvDwcEBPB4Pz58/R2RkJIYOHYodO3ZUePyUKVOwefNmLFy4EHw+HzweDzdu3MA///yD0aNHIyAgQKi+m5sbnj59ChsbGxgaGoLjOERFRSE+Ph4WFhbo06cPAGD79u04d+4cbG1t0bp1aygpKeHq1as4f/48jIyMMHr06Lr8WCrVrl07eHh4YOXKlejcuTMcHR3x7t07+Pn5obi4GH/88Qe9PZwQQuoB+k1MCCH1wPz589GpUyds374doaGhePv2LfT09GBubo5x48ZVemzz5s0RERGBpUuX4p9//kFJSQm6d++OsLAw/PvvvyKDjWXLliEgIABXrlzB2bNnIS8vj1atWmHLli349ttvISsrCwCYO3cuNDQ0EBcXh8jISDDG0LJlS6xcuRKurq5QU1Ors89DEitWrIChoSF27NiBffv2QUFBAb1798aaNWvQs2dPqcZGCCHkPY4xJu0YCCGkShzHKcvLy+cUFRXRTRLyVfPx8YGrq2tgZmbmKGnHQgghVaE1G4QQQgghhJA6QYMNQkiDQU9iCYFgMT0hhDQENNgghDQU+aWlpTLFxcXSjoMQqcrNzUVpaelracdBCCGSoMEGIaRBYIwxNTW1Z5cvX5Z2KIRIVVRUVN6bN2+uSzsOQgiRBA02CCENRkFBwaG//vqrSNpxECIthYWFCA4OlmWMHZd2LIQQIgkabBBCGoyioiJvLy+vorCwMGmHQshnV1paCmdn5wJ5eflIxliatOMhhBBJ0GCDEFLvcRynxnHcAMbYo7y8vMGjRo16O3/+/KLo6GjQGg7yJWOM4fXr1zh8+DD69OnzLiQkJDEnJ8eB47hGHMfZSzs+QgipCr1ngxBS73Ec9zMAJcbYt//72kheXn5ao0aN5rx9+1ZXRkaGcRxXKuUwCaltXGlpqaysrGyZiopKbHZ29n4ARxljBRzHqQN4CMCWMXZbynESQkiF6OVYhJB6jeO4/wMwBYDxB9lviouL2xUXF+cAGFtWVpYgnegIqXMyZWVlS7Kzs+cBUAJQCACMsVyO49YA+PV/T/3oziEhpF6iJxuEkHqL4zgOwDkAwYyxnf/7ehKA7QAOAvBgjOVJM0ZCPgeO40wAeAJ4A2AWY+wRx3FyAK4CWE0Lxgkh9RWt2SCE1GcOAJoC2MtxXAsApwAsBTCUMbaUBhrka8EYuwnAAkAIgDiO4xYDYAAWAtjOcZyyNOMjhJCK0GCDEFIvcRzXCMDPAL4DMBPv7+DGAjBljNHLNshXhzFWwhjbDqAXgOEAogFkAIjD+0E4IYTUOzSNihBSL3Ectwrv7+QqA1AAMIMxdke6URFSP3AcJ4P3g/D1AHwATAPQgzGWIs24CCHkYzTYIITUOxzHtQZwG0ARgMMArgBoDqDFB6mUMdZZakES8hlxHDcQ79cpPQPw7wfpHYDJADoCSGSM9ZNakIQQIgYNNr4gHMfxALQGoCLtWAiR0DsAjxljTz7M5DguBMAgAE8BJEP4j6vyP7ZSGGO5nzdcQqTjf5sjNIPwgPvD1BaAJoCOjLGkD46TA9AFgC5oB0rSMJQByAZwndblfRlosNHAcRzHycnJfauqqrqwtLS0Zbt27QpVVVXxvl8ipP5ijOHt27e4f/++oqys7NO3b9/+WlJSspcxxv73hxVoO09CJMdxnAxjrOx//zZQU1PbUFJSMlpPTw8GBgZlioqK0g6RkCoVFxcjMzOTS05OVmzUqNE/2dnZPzHGrkk7LlJzNNhowDiO41RUVHa1bNly+q5du5Stra0hJ0c3rkjDUlJSgoiICCxYsCDv6dOnnu/evVtIgwxCao7juGYqKipx33zzTZP58+fLtW7dWtohEVJtGRkZ8PPzw48//vg2Ly9vAGMsTtoxkZqhwUYDxnGcU5s2bf6Ij49X0dLSknY4hHySrKwsmJmZvXv48OEsxpiftOMhpKHS1NRMWLx4cddVq1bR3SfS4IWEhMDR0TG3oKBAjzFWKO14SPXR1rcNmJaW1jfu7u400CBfBC0tLaxatUpFS0trlrRjIaSh4jiuWXFxscmPP/5IAw3yRRg6dCg6duwIAAOkHQupGRpsNFAcxzV6+/Zt7+HDh0s7FEJqzYgRI/Du3TvL/71jgxBSfcOHDRtWoqCgIO04CKk1U6ZMUVNXV3eSdhykZmiw0XDpqqqqlmhoaEg7DkJqjYaGBlRUVEoA6Eg7FkIaIllZ2RadOnWiHQnJF6V9+/acvLw8LT5qoGiw0XApKSkplUo7CEJq2/++r+nJBiE1oKioqNaoEf34kC/L/76n6Ru7gaLBBpEajuNgY2Mj7TAIIeSLUhtbnxcXF8Pd3R1t2rSBgoICOI4Dn8//9OAIqYH/fU/Tnv4NFA02CGnAiouLcfz4cTg7O6Njx45QUVGBmpoazM3NsXfvXpSWVu/hl6GhITiOE5vmzJlTR1dBCKlvtm/fjjVr1qBFixZYunQp3N3dYWhoKO2wGqTg4GAsWLAAlpaWUFFRAcdx8PDwqPSYZ8+eYcGCBYLf602aNEGfPn3g4+Mj8e/1zMxM/P777xgxYgRat24NRUVF6OjoYPDgwTh79qzYYyrrA8rTxYsXhY6prO6mTZskipV82Wi3CkIasEePHsHR0RGqqqro378/RowYgZycHAQHB2PevHkIDQ1FUFBQte50amhowNXVVSTf1NS0FiMnhNRnp06dgqqqKsLCwiAvLy/tcBq07du3IyIiAurq6jAwMMDDhw8rrf/o0SOYmZkhKysL9vb2GDFiBHJzcxEYGIipU6fi/Pnz8Pb2rvK8R48exdy5c2FgYID+/fujWbNmePbsGY4fP44zZ85gy5Yt+P7774WOcXV1RXZ2tkhbGRkZ2LNnD7S0tNCzZ0+Rch6PB2dnZ5H8Pn36VBkn+Qowxig1wASgnb6+fi5rwAAwa2traYdRJ2JjY1lhYWGdn+fZs2dsz5497O3bt0L5b9++ZaampgwA+/vvvyVuj8fjMR6PV8tRVo++vn4ugHasHvycUaLU0JKysvKv27ZtY5+qVatWUv9dUFeKiopYTEzMZztfZGQku3//PisrK2N+fn4MAHN3d6+w/pw5cxgAtmPHDqH8rKws1rJlSwaApaSkVHne8+fPs6CgIFZaWiqUn5SUxDQ0NJicnBx79uyZRNewbds2BoAtWLBApOxz9OXh4eFMW1v7OqsHP2OUqp9oGhWpEJ/PFzzujYiIgLW1NVRVVdG4cWNMnDgRz549E3vcy5cv4ebmhvbt20NJSQmNGzdGr169sH379irPef/+fSxduhTdu3eHtrY2lJSU0K5dOyxduhRv3rwRqZ+amooFCxagbdu2aNSoETQ1NdGxY0fMnTsXubm5gnpZWVlYsWKF4JG0uro62rRpA2dnZ/z77781/5A+8OTJE6xfvx4dOnRAr169kJeXVyvtVqZZs2b49ttvoaIivPmMiooKFi9eDACIjIys8zgIIV8GDw8PcByH5ORkPHnyRDAdpnx9XU5ODjZv3gxra2sYGBhAQUEBBgYGmDJlitg79uXt8fl8HDx4ED169ICysrLQer03b97A3d0dxsbGgt/jgwYNQlRUVK1e2+XLl7Fw4UIYGBh81mmhVlZWaNu2rcRPmFNSUgAAQ4YMEcrX1NQUPCl49epVle3069cPw4cPh4yM8J967du3x/jx41FSUoKYmBiJYvrzzz8BADNmzJCoPiEfomlUpEoxMTHYuHEjhg4dioULF+Lq1avw8/NDVFQUEhIS0KRJE0Hde/fuwdbWFunp6ejTpw8cHBzw7t073Lp1C+vXr4ebm1ul5woICMCff/4JW1tb2NjYoKysDLGxsdi6dSv4fD4uXbokeKT/7t07WFpa4unTp7Czs8OoUaNQVFSEx48f4+DBg/jhhx+grq4Oxhjs7e2RkJAAS0tLDB48GDIyMkhJSUFgYCCcnZ3RokWLGn02b968wbFjx3Do0CFERESAMYaWLVvihx9+EBkAfG7ln5OcXPV+zAsLC3Hw4EGkpqZCS0sLFhYW6Nq1ax1ESAipb8oHATt27AAAwZTK8vUad+/exapVq2Bra4tRo0ZBRUUFSUlJ8PPzQ0hICK5cuYJWrVqJtLt161aEh4djxIgR6N+/v+D30uvXr9G3b1/cvn0bffv2hb29PXJycnDy5EnY2tri6NGjcHBwqPH1/Pvvvzh8+DB8fHxw9+5dAED37t0xb968GrdZ14yNjXHmzBmcPn0a3333nSA/Ozsbly5dQpMmTWBsbPxJ56hO/xAdHY27d+/C1NQUXbp0EVsnOzsbBw4cwMuXL6Grqwtra2u0a9fuk2IkXw4abJAqhYWF4cCBA0J3NNasWQN3d3csX75ccMcDACZPnoz09HT8/vvvmDVL+EXQFT0J+dCUKVOwePFifPxCqvLz/f3335g8eTIA4Pz583jy5AlcXV3xyy+/CNV/8+YNFBUVAQA3b95EQkICHBwccOLECaF6hYWFKC4uluBT+E9paSnOnTuHQ4cOITAwEPn5+dDU1MSMGTMwefJk9O3bV+wdrB07doidC1sRZ2fnT1qQ6enpCQCws7Or1nHPnz8XmXtrZ2cHHx8f6Onp1TgeQkj9Z2NjAxsbG8GagI8XMnfs2BHp6elo3LixUH54eDgGDBiA9evX48CBAyLtRkREIC4uDiYmJkL5CxYswO3bt3Ho0CFMmTJFkL9hwwb07NkT33zzDezt7VGd7Xzfvn2L48eP49ChQ+Dz+SgrK0OrVq2wYsUKTJ48GR06dBA5Jjs7WzDAklRVi7xr6vvvv0dwcDAWLVqEM2fOoHPnzoI1G0pKSggICKjW5/Gx8ptkSkpKsLKyqrJ+eR8/c+bMCuskJiYK9fkcx8HJyQm///671G+8kXpA2vO4KNUs4TOs2QgPD2cAWPv27VlZWZlQWV5eHtPV1WWNGjUSrE2Ii4tjAFjfvn0lah/VmOeZmZnJADBnZ2dBXlBQEAPAli9fXumxN27cYADYxIkTJTpXRRITE5mbmxvT19dnAJiioiIbNWoUO3bsGCsoKKjyeB6PxwBInMLDw2sc62+//cYAsH79+lXruNWrVzM+n89evXrFcnNzWWxsLBs8eDADwMzNzUXm/tYFWrNBiVLNU22t2ajJ+i0TExNmaGgolOfu7s4AMFdXV5H6r169YrKysqx///5i2/v1118ZABYUFFTluUtLS9nZs2fZ5MmTmbKyMgPAtLW12Zw5c9jFixdF+rCPJScnV+v38/s/n6pPkjUbjDGWkZHB7O3thc6npKTEVq1axd69e1ejc5ebOHEiA8DWrFlTZd03b94wVVVVpqyszHJycsTWWbJkCYuLi2OvX79mWVlZ7MKFC6xXr14MABs7duwnxVqO1mw07ERPNkiVLC0tRe7UN2rUCD169MCZM2dw//59dOrUCfHx8QCqfyf9Q4wxeHl5wdvbG7du3UJOTg7KysoE5WlpaYJ/9+3bFwYGBti4cSMSExMxZMgQ9OnTByYmJkLxduzYEV26dIGvry9SU1MxcuRI9OnTB927d4esrKxEcT158kTw+Lhz587w8PDAuHHjoKmpKfG1lc/DrWunTp3C/PnzYWhoiMOHD1fr2FWrVgl9bW5ujlOnTsHa2hpRUVEIDQ3F0KFDazNcQkgDw+fzsWPHDsTFxSEjIwMlJSWCso+fSpczMzMTyUtISEBpaSkKCgrEPiV48OABgPfTc4cPH15pTD4+PoInssOGDcPMmTMxZMgQiXfSMjQ0BGNMorp17eHDhxg+fDhUVVURGRmJbt26ITs7G76+vlixYgXOnDmDqKioGu0StmzZMvj6+mLIkCFYvnx5lfX//vtvvH37FtOmTYO6urrYOlu3bhX62tbWFufPn0eXLl1w9OhR3Lp1C506dap2rOTLQYMNUqWKps6Ur9XIyckR+m+zZs1qfK6FCxdi9+7daNGiBUaMGAF9fX3BdKjVq1ejsLBQUFdDQwMxMTFYtWoVgoODERISAgBo3rw5li1bhm+//RbA+zmp58+fh4eHB44fPy5YOK2jo4MFCxZgxYoVVQ46lJWV0bp1azx+/Bh37tzByZMnoaamhpEjR0JZWbnG11vbTp8+DUdHR+jr6yM8PBz6+vqf3KaMjAymT5+OqKgoXLp0iQYbhHzFjh49ivHjx0NVVRX29vYwNDSEsrIyOI6Dt7c3njx5Iva4pk2biuS9fv0aAHDp0iVcunSpwnO+e/euyriaNWsGTU1NZGdnIzIyErq6ulBTU4ONjY3IAun6ztnZGU+ePMHjx48Fn5uqqiqWLl2K169fY/PmzTh8+DCmT59erXZ/+uknbNq0CQMHDsTx48clutlWPiWusilU4igrK8PJyQlr165FdHQ0DTa+cjTYIFV6+fKl2PwXL14AeP9HPwDBXf7U1NQan2fPnj3o3LkzYmJihP6If/78OVavXi1yTMuWLeHt7Y3S0lLcvHkTYWFh+PXXXzFv3jxoaWnByckJAKCtrY1du3bh119/RVJSEi5cuIBdu3bB3d0d8vLyWLZsWaWx6erq4uHDh7h06RIOHTqEo0eP4vTp01BVVcWoUaMwefJk9O/fv9Jf3nW9ZuP06dMYPXo0dHR0cOHChVp9AZeOjg4AfJYdtggh9ZeHhweUlJRw5coVtG3bVqjsyJEjFR4nbh1b+Z1yNzc3bNu27ZPiGjBgAJ4/f47g4GD4+Pjg8OHD8PLyQrNmzeDk5ITJkydXuLgZqD9rNt68eYNLly6he/fuYgdo/fr1w+bNm3HlypVqDTZ++uknrFu3Dv369cPJkyehpKRU5TF37txBbGwsOnToUKP3ZVC/QQSkPY+LUs0S6uGajfj4+E9asxETE8MAMDc3N5G6/v7+Eq/xiIyMZADYhAkTKq339OlTBoD16tVLong/VFBQwPz9/dnw4cOZvLw8A8CaNm3KFi1axC5fviz2mLpcsxESEsIUFRWZgYEBu3//frWvpyorV65kANgvv/xS621/jNZsUKJU81TXazYUFRVZjx49RPJTU1OZnJycyFqG8jUb4n6fpaenM47jWO/evT853o+9evWK7dq1i/Xs2VPwO7VTp05s06ZN7OnTpyL168uajYyMDAaAtWzZUmz54cOHGQC2ePFiic9Z/vvb2tq6Wus9Fi9ezACwrVu3SnzMhyZPnswAsBMnTtTo+A/Rmo2GnRrWs0UiFffu3RPsbFRu69atePXqFZycnARzdHv27AkzMzNERkbijz/+EGmnqicePB4PwPtH6h+u03j27Bl+/PFHkfq3bt0S+8i+/IlL+Z2b5ORk3Llzp8p61aGoqIixY8ciKCgIqamp2LlzJ5o3b45ffvkFpqam6Nixo8jdnJSUlGr9cH64D31lQkNDMXr0aGhpaeHChQsidxs/VlxcjKSkJDx69Ego/86dO2KfvMTExGD79u1QVFTE6NGjJYqJEPJl4vF4uH//vuD3JwAUFBRg7ty5Qms3JNG0aVOMGzcO0dHR2LZtGxgTXTMRFxdXozvjOjo6mD9/PuLj45GUlITly5fjzZs3+PHHH8Hj8YR2vgL+W7NRnVQXtLW10b59ezx9+lRkV6/c3Fxs3rwZwPt1ER9KSkpCUlKSSHurVq3CunXrYGVlhZCQEImn/RYXF8PHxwfy8vKYOnVqhfWuXbsm9v/PiRMn4OvrCx0dHQwYMECic5IvF02jIlWys7PDt99+i5CQEHTo0AFXr17F2bNn0aJFC2zYsEGo7uHDh2FjY4NvvvkGPj4+sLCwQEFBAW7fvo1r164hMzOzwvPo6+tjzJgxOH78OExNTdG/f3+8ePECp06dQr9+/fD48WOh+v/88w/c3NxgaWmJDh06QFtbG48fP0ZQUBAaNWqE+fPnA3i/Jd+oUaPQs2dPdOrUCU2bNkVqaioCAwMhKytb5bs/qqKrq4uFCxdi4cKFuHv3Lnx8fPDXX3+hqKioztdzJCUlYdSoUSgsLISNjQ38/PxE6hgaGgptZZuamoqOHTuCx+MJLVr39/fHli1b0L9/fxgaGkJRURG3b9/G2bNnISMjg/3796Nly5Z1ej2EkPptwYIFWLBgAbp16wZHR0eUlJTg3LlzYIyhS5cuSExMrFZ7e/fuxb179/D999/Dx8cHvXr1goaGBv79919cuXIFDx48QHp6+if9Lm3fvj3Wr1+PdevWISIiAocOHRK52VKXAgMDERgYCOD9za/yvPLfv3369BFaE7Fjxw4MHz4cs2bNgp+fH7p3747s7GwEBwfjxYsXGDZsmMjauY4dOwKA0CDI29sba9euhZycHMzMzEQWcgP/bXX8saCgILx69QqjR4+udMvznTt3IjAwEP3790fLli3BGMO1a9cQGRkJJSUlHDx4EKqqqhJ9TuQLJu1HK5RqlvAZp1G5u7uziIgIZmVlxZSVlZmmpiabMGGC2EfRjDH2/Plz9t1337HWrVszBQUF1rhxY2Zubs5+/vlnoXoQMy3qzZs3zM3NjRkaGjJFRUXWtm1btnbtWlZUVCRS/86dO+y7775j3bp1Y9ra2kxRUZG1bt2aOTs7szt37gjq/fvvv+zHH39kvXr1Ynp6ekxBQYG1bNmSOTo6stjY2Fr7vD5UVlZW5VaLtaH8/1Fl6ePPuHy6wMdTJPh8Phs3bhxr06YNU1NTY/Ly8qx58+ZswoQJLC4urs6vpRxNo6JEqeaprqdRlZWVsf379zNjY2OmpKTEmjZtymbMmMFevHjBrK2tqzWNqlxeXh7bsmUL69GjB1NRUWGNGjVirVq1Yg4ODuzQoUOsuLj4k6/nYyUlJbXeZkXKP4OK0rRp00SOuXz5Mhs3bhzT19dncnJyTEVFhZmamrJffvlF7OdR3lZ1zlvev4tTvuX56dOnK722gIAANnLkSGZoaMiUlZWZgoICa9WqFZsxYwa7e/euxJ9RVWgaVcNOHGP1Y6s3Uj0cx7XT19e/nJaWplZX5+Dz+bC1tYW7u3udvbyIkI8ZGBi8SU9PN2WM3Zd2LIQ0NCoqKr+uWbNmwac+sSWkPuHz+XB0dEzMyMjoKu1YSPXRmg1CCCGEEEJInaDBBiGEEEIIIaRO0GCDEEIIIYQQUidoNypSIRsbG9CaHkIIIYQQUlP0ZIMQQgghhBBSJ2iwQQghhBBCCKkTNNggn52NjQ04jvvkdjiOk/gt24QQQuov6hcI+XLRYIOQWpCQkIAhQ4ZAS0sLKioqMDMzg6+vb7XaiI+Px7Rp09CpUyc0btwYSkpKaNOmDcaPH4/Lly9XeuyJEycwcOBAaGtro1GjRmjVqhWcnJzw77//CtXz8PAAx3Fik5KSUrWvmxBCiHi10S9ERUXBzc0NPXr0gLa2NpSUlNChQwf88MMPyM7OFntMWVkZdu/eje7du0NZWRnq6uqwtrZGUFCQ2PrUL5C6RgvEyWd36NAh5OXlfXI7d+/ehbKyci1E9Gn4fD7s7e2hoKCACRMmQENDAwEBAZg0aRJSUlKwfPlyidqJjo5GWFgYevXqhX79+kFZWRmPHz9GUFAQjh49ioMHD2LKlClCxzDGMGfOHPz+++8wMjLChAkToKamhrS0NERERODJkydo0aKFyLmmTZsGQ0NDoTw5Ofp1QAiRDuoXxHN0dERGRgb69OmDqVOnguM48Pl8bNmyBceOHUN0dDSaNGkiqM8Yw7hx43D8+HEYGRlhxowZKCwsxMmTJzFy5Ejs2rUL8+fPF3su6hdInZH2K8wp1SwBaKevr5/LiFQVFxczIyMjpqioyK5evSrIz83NZcbGxkxOTo7dv39forby8/PF5t+8eZMpKSkxXV1dVlZWJlS2Y8cOBoB9++23rKSkRGx8H3J3d2cAWHh4uEQxSYO+vn4ugHasHvycUaLU0JKysvKv27ZtY0R6arNf2LRpE0tNTRXKKysrY3PnzmUA2Ny5c4XKjh49ygAwS0tLlpeXJ8h/9eoV4/F4TFFRkSUnJwsd0xD6hfDwcKatrX2d1YOfMUrVTzSNinyykpISbNy4EUZGRoKpPxs3bsTjx4/BcRycnZ2F6oubm+vt7Q2O4+Dt7Y2wsDD07t0bysrK0NbWxtSpU5GRkSFy3vowN/f8+fN49OgRJk6ciG7dugny1dTUsGrVKpSUlMDLy0uitip6XN2pUyd07NgRr169wps3bwT5+fn5WL16NVq1aoWdO3dCVlZW5Fi6K0UIkQbqF2qnX/jhhx9gYGAglMdxHH766ScAQGRkpFBZYGAgAGD58uVo1KiRIF9HRweLFi1CYWEhPD09a3JZhNQY/SVCPpmLiwt8fHxgZGSEefPmobCwEL/88gtiYmKq3VZQUBBCQkIwfPhw9O7dG5GRkfDx8cGDBw8QHR1dKwsIa1NERAQAwN7eXqTMzs5OqE5NPXr0CPfu3UPLli2hrq4uyA8LC0NWVhamT5+O0tJSBAUF4f79+9DU1MSAAQPQpk2bCtu8ePEi4uPjISsri/bt22PAgAE0N5cQUmuoX6jbfkFeXh6A6A2lFy9eAABatWolckx5Xnh4uNg2qV8gdYUGG+STnD9/Hj4+PjA1NUVkZKTgTsrKlSuF7uhIKjg4GHw+H5aWlgCA0tJSDBgwAHw+H7GxsbCwsKhRnCkpKfD29pa4vqamJlxdXaus9+DBAwAQ+4e9pqYmdHR0BHUkFR8fj9OnT6O4uBhPnjxBUFAQOI7D77//LlTvypUrAN53Nl26dMG9e/cEZTIyMli0aBG2bdsm9hyrVq0S+rpp06bw8vLCoEGDqhUrIYR8jPqF2u8XPlb+dKJ88FJOR0cHAJCcnIyOHTsKlSUnJwMA7t+/L7ZN6hdInZH2PC5KNUuoJ2s2nJ2dGQB28uRJkbKNGzcyAGzatGlC+dbW1uz9t95/vLy8GAA2depUkXbKy3799VehfADM2tpaojjDw8MZAIkTj8eTqN2BAwcyAOzBgwdiy1u3bs0UFBQkaqvcrl27hGJp0qQJO3funEi92bNnMwBMVlaW9ezZk8XHx7M3b96wyMhI1qFDBwaA7d27V+iYEydOsIMHD7KUlBSWn5/PHjx4wNauXcsaNWokMr9YWmjNBiVKNU/1Yc0G9Qu13y986Nq1a0xZWZnp6emxV69eCZUdPHiQAWBWVlZC6wAzMjKYoaEhAyBy7obQL9CajYadaM0G+SSJiYkAgN69e4uUicurSo8ePUTymjdvDgAVbvMnCRsbm2r9YKSkpNT4XJ9q/vz5YIwhLy8PiYmJGDRoEOzt7UWeUpSVlQEAFBQUEBgYiJ49e0JVVRVWVlY4duwYZGRksH37dqFjHBwcMHXqVPB4PME86pUrV2LHjh0oLCzEhg0bPtt1EkK+TNQv1J3Hjx9j6NChKC0txZEjRwRPMspNnDgRtra2uHjxIkxMTLBgwQLMmTMHxsbGgmm4H6/vo36B1DUabJBPkpubCxkZGWhra4uUfbgdn6Q+XJNQrnxOamlpafUDrGMaGhoAgJycHLHlubm5gjrV1ahRI3Tu3Bne3t4YPHgwfvjhB9y6dUvk3KampiILCI2NjdG6dWs8evRIos7Y2dkZcnJyuHTpUo1iJYSQctQv1E2/kJycDFtbW2RmZuLEiROwtbUVqSMnJ4fQ0FB4eHhARkYGv//+OwICAjBy5EgcO3YMAKCrqyvR+ahfILWF1myQT6Kuro6ysjJkZmaK3GEpX6hWH9TV3Ny2bdsCeD9H9+O7b1lZWcjIyKjRnbyPDRw4ECEhIbh48SI6deoEAGjfvr0gVnHK8/Pz8yusU05BQQHq6uq1ss89IeTrRv1C7fcLjx8/hq2tLdLT0xEQEIDBgwdXWFdRURHu7u5wd3cXyufz+QDe36CSBPULpLbQYIN8ki5duuDatWuIjo7GiBEjhMqio6OlFJWolJQUrF69WuL6PB5Pok7F2toaGzduRFhYGCZMmCBUFhYWJqjzqdLS0gD8twMJAMFdrbt374rULy4uxsOHD6GsrCzRXaxHjx7h9evX6NKlyyfHSgj5ulG/ULv9QvkTjfT0dPj7+2PYsGESH/uhv/76CwBEYqoI9QukttA0KvJJJk2aBABYu3YtCgoKBPnPnz/Hzp07pRWWiLqam9u/f3+0bt0avr6+uH79uiD/zZs3WLt2LeTk5ET2k8/IyEBSUpLIHvEXL14UrMP40PXr17F//37Iy8tjwIABgnwjIyPY2dnh4cOHOHDggNAxmzZtQnZ2NkaNGiWYbvDmzRvcuHFDpP3s7GzMnDkTAODk5CTRdRNCSEWoX6i9fiE5ORk2NjZIS0vDkSNH4ODgUOX5c3NzRfKOHTsGT09P9OzZE6NHjxaKifoFUtfoyQb5JAMGDMCkSZPw119/wcTEBCNHjkRhYSH8/f1hbm6O4OBgyMh8uWNaOTk5HDhwAPb29rCysoKTkxPU1dUREBCA5ORkrFu3Du3atRM6Zvfu3Vi9ejXc3d3h4eEhyJ8yZQrKyspgYWGBli1boqioCPfu3cO5c+fAGMPOnTthaGgo1NbevXvRu3dvzJo1C4GBgejQoQOuXbuGCxcuoEWLFti6daugbmZmJrp06QJTU1OYmJhAT08PaWlpCA0NRUZGBgYOHIhFixbV5cdFCPkKUL9Qe/2Cra0tnj59il69euHGjRtiBwYf1gcAc3NztGjRAh07doSSkhLi4+PB5/PRunVrHD16VGiBOPUL5HOgwQb5ZN7e3ujQoQM8PT2xa9cuNG/eHK6urujfvz+Cg4NrvEC6obC1tUVUVBTc3d3h7++PoqIiGBsbY+3atYI7fJJYvnw5Tp06hdjYWAQFBYExBn19fUycOBHz58+Hubm5yDFGRka4fPkyVq1ahTNnziAsLAxNmjTB3Llz4e7uLrQYs3Hjxpg3bx5iY2MRHByM7OxsqKiowMTEBJMnT8bMmTPFvoWcEEKqi/qF2ukXnjx5AgCIjY1FbGys2DofDzbGjx+PgIAAxMbGori4GK1atcLKlSvx/fffiyy2p36BfA4cY0zaMZAa4Diunb6+/uW0tDQ1acdSkQMHDmDWrFnYt28f5syZI+1wSANhYGDwJj093ZQxJv7NU4SQCqmoqPy6Zs2aBW5ubtIORSzqF0hN8Pl8ODo6JmZkZHSVdiyk+r7c55jks3n+/Dk+HrSmpqZi3bp1kJOTw/Dhw6UUGSGEEGmgfoEQUo6mUZFPtmnTJoSEhMDKygp6enp4+vQpTp06JVgM16xZM2mHSAgh5DOifoEQUo4GG+STDRo0CPfu3cOZM2eQmZkJRUVFdOnSBfPmzZN4iz1CCCFfDuoXCCHlaLBBPtmgQYMwaNAgaYdBCCGknqB+gRBSjtZsEEIIIYQQQuoEDTYIIYQQQgghdYIGG+SLZmhoKPIiPEIIIV836hsI+XxosEFIAxYZGYklS5bA1tYWGhoa4DgOzs7OFda3sbEBx3GVJh8fH6FjDA0NK6xL++QTQkj9s3v3bgwdOhSGhoZQUVGBpqYmunTpAg8PD7x+/VqkflRUFNzc3NCjRw9oa2tDSUkJHTp0wA8//IDs7GyR+oWFhXBzc0Pfvn1hYGAAJSUlNG3aFJaWlvDy8kJxcfFnuErSUNACcUIaME9PTxw8eBDKyspo2bIlcnNzK63v7OwMGxsbkfzi4mJs3LgRMjIy6N+/v0i5hoYGXF1dRfJNTU1rGjohhJA64uXlhZKSElhbW6Np06YoKChAXFwcVq9eDU9PT8TFxUFfX19Q39HRERkZGejTpw+mTp0KjuPA5/OxZcsWHDt2DNHR0WjSpImgfn5+Pvbu3QszMzMMHToUurq6yMrKQmhoKFxcXHDkyBGEhoZCRobuaRMabBDSoM2fPx/ff/89OnTogISEBFhYWFRav6KnHsePHwdjDEOGDIGBgYFIuaamJjw8PGohYkIIIXXt0qVLUFJSEsn/6aefsG7dOmzfvh3btm0T5C9atAhTpkwR+v3PGMO8efOwb98+rF69Gnv37hWUaWhoICcnBwoKCkLtl5SUYODAgQgLC8Pp06cxbNiwOrg60tDQkJMI+Pv7o2/fvtDT04OSkhIMDAwwcOBAnDhxQqiep6cnRo4cCUNDQygpKaFx48aws7PD+fPnRdrk8/ngOA4eHh6Ijo6Gra0t1NTUoKuri2+//Rb5+fkAgJCQEFhYWEBFRQVNmjTB0qVLUVJSItSWt7c3OI6Dt7c3AgIC0LNnTygrK6Np06aYO3cusrKyJL5Wxhg8PT1haWkJdXV1KCsrw9TUFJ6eniJ18/PzsWXLFnTu3BkaGhpQUVGBoaEhxo8fj5s3b0p8zrpgamoKY2NjyMrKflI7Bw4cAADMmDGjNsIihHxBqG9oeH2DuIEGAIwdOxYA8PjxY6H8H374QeRGE8dx+OmnnwC8n7L7cdnHAw0AkJOTw6hRo8Seg3y9aLBBALyf3zl+/Hg8fPgQo0aNwuLFi2Fvb4+0tDScPHlSqO68efPw4sULDBgwAIsWLcKwYcMQGxsLOzs7kc6nXFxcHPr37w8NDQ3Mnj0bLVu2xL59+zBz5kwcOXIEjo6O4PF4mD17NjQ1NbF161Zs2LBBbFtHjx6Fk5MT2rdvj++++w6tW7fG/v37YWtrK+igKsMYw+TJkzFjxgxkZmZi0qRJmDlzJt69e4cZM2ZgyZIlQvWnTJmCH374ARzHYfr06Zg/fz4sLCwQERGBK1euSPgJ11/Pnj1DWFgYmjZtiqFDh4qtU1hYiIMHD2LDhg3Yt28frl+//nmDJIRIBfUNX1bfEBISAgAwMTGRqL68vDyA94MISZSVleHMmTPVOgf58tE0KgLg/R0pBQUFXL9+HXp6ekJlmZmZQl/fuXMHrVq1EspLT0+Hqakpli5dKrir8aEzZ84gMDAQI0eOBPB+jYCpqSn8/Pxw9uxZREZGomfPngCA1atXo02bNti5cyeWLVsm+GVX7vTp0/jnn3+E1ha4uLjAy8sL27ZtE9yJqciBAwfg6+uLb775Bnv37hU8FSgqKoKjoyO2b9+OCRMmwNTUFDk5OQgICECPHj0QFxcn9AShtLQUb968qfRc5ao7BcnV1RWamprVOqamvLy8UFZWBmdn5wo7lOfPn4tMwbKzs4OPj4/I9wsh5MtBfUPD7ht+//13pKWl4c2bN7h69Sr4fD5MTU2xaNEiiY4vf6JjZ2cntryoqAgbNmwAYwyZmZk4f/48kpKSMHPmTNja2kocJ/nCMcYoNcAEoJ2+vn4uqyXdu3dnKioqLCsrq8ZtLFiwgAFgKSkpgrzw8HAGgNna2orUX7NmDQPApk+fLlLm4uLCALDHjx8L8ry8vBgANnDgQJH6qampTF5enhkZGQnl83g8xuPxhPI6d+7MVFVVWX5+vkg7N27cYADY4sWLGWOM5eTkMADM0tKy8ouvAoBqpeTk5GqfIyYmhgFg06ZNk/iYsrIy1qpVKwaAPXjwQGyd1atXMz6fz169esVyc3NZbGwsGzx4MAPAzM3NWWlpabVjrYy+vn4ugHasHvycUaLU0JKysvKv27ZtY7WF+ob3Gmrf0KNHD6HjBw0axF6+fCnRsdeuXWPKyspMT0+PvXr1SmydN2/eCLXPcRxbunQpKy4urlacVQkPD2fa2trXWT34GaNU/URPNggAwMnJCd9//z06deoEJycn2NjYwNLSUuwdlMePH2Pjxo24cOECUlNTUVhYKFSelpYGHo8nlNe1a1eRdsp3wqisLC0tTeROmZWVlUh9AwMDGBkZISkpCW/evIGamprY68zLy8PNmzdhYGCATZs2iZSXb9d37949AIC6ujqGDh2KkJAQ9OjRA2PGjIGVlRXMzc3FzletCGNM4rqf04ULF5CcnAxra2u0adNGbJ1Vq1YJfW1ubo5Tp07B2toaUVFRCA0NrXD6FSGkYaO+4b2G2jdcvnwZAJCRkYGYmBj8+OOP6NatG06fPo3OnTtXeNzjx48xdOhQlJaW4siRI9DR0RFbT1VVFYwxlJWVIS0tDcHBwVi+fDkuXbqE06dPQ11dvU6uizQsNNggAIAlS5agcePG2Ldvn2CXCjk5OQwZMgQ7duwQ/FJ/+PAhzMzMkJubC1tbWwwfPhzq6uqQkZEBn89HRESESAcDQOwvnPIpO5WViduru6JpO02aNEFSUhJyc3Mr7FCysrLAGENqaipWr15dwacBvHv3TvBvf39/bNiwAb6+vlixYgUAQE1NDS4uLtiwYQOUlZUrbKe+K18YPnPmzGodJyMjg+nTpyMqKgqXLl2iwQYhXyjqG4Q11L5BR0cHw4cPR7du3dCmTRvMmjULcXFxYusmJyfD1tYWmZmZOHHihETToWRkZNC8eXPMnTsXOjo6GDduHNavX4/NmzfX9qWQBogGG0TAxcUFLi4uyMzMxMWLF+Hn5wd/f388fPgQN27cgKysLH755RdkZWXh8OHDmDRpktDxc+bMQURERJ3H+fLlS7H5L168ACC+gypXXtajRw/BHZ+qKCsrY926dVi3bh2Sk5MRHh6O/fv3Y+fOncjPz8dvv/1WZRv1cc1GVlYWTpw4AU1NTYwZM6bax5ff6crLy6vt0Agh9Qj1DeI1xL6hefPm6NixIxISEpCXlycyIHr8+DFsbW2Rnp6OgIAADB48uNrnKF/fwefzaxwn+bLQYIOI0NbWhoODAxwcHJCRkYELFy7g4cOHaN++PR49egQAgsV85crKynDp0qXPEt/FixdF8tLS0vDo0SMYGRlVeOcKeH/XqWPHjrh79y6ys7Or/Uu7VatWaNWqFZycnKCnp4egoCCJOpTK7pSJ4+zsXOeDjcOHD6OwsBAzZ85Eo0aNqn18QkICgPdvGCeEfPmob6hYQ+ob0tPTwXGcyJbp5U800tPT4e/vX+N3ZKSlpQGAyAJ+8vWirW8JAODs2bMie5cXFxfj9evXAP7bs7t8vu3He25v3rwZt27d+gyRAufOnRPZt33lypUoLi7GtGnTqjx+4cKFyMvLw6xZs8TelU9OTkZKSgoA4NWrV4iPjxepk5WVhcLCwgr3Mv9YdRdTfY4/4P/8808Alb9b486dO8jOzhbJj4mJwfbt26GoqIjRo0fXVYiEECmjvuE/DaVvSE9Px/3798Wey8PDAy9evED//v2hqKgodG02NjZIS0vDkSNH4ODgUOk5bt26JbIbGfD+SffixYsBAEOGDKkyVvJ1oCcbBAAwfvx4KCsro0+fPuDxeCguLsa5c+dw584djBs3TtCRzJkzB15eXhgzZgzGjx8PbW1txMbG4urVq4LFcnVt6NChGDJkCMaOHYsWLVogIiICMTEx6NKli8g+6OLMnj0bsbGxOHjwIKKjo9G/f38YGBjgxYsXSEpKQlxcHHx9fWFoaIjU1FSYm5vD2NgY3bt3R7NmzZCZmYmTJ0+iuLgY33//fZ1fb2WioqIE6y5evXolyCvfprZDhw748ccfRY67cuUKEhMT0b17d3Tr1q3C9v39/bFlyxb0798fhoaGUFRUxO3bt3H27FnIyMhg//79aNmyZe1fGCGkXqC+oeH1Dffu3UO/fv3Qq1cvdOjQAU2aNEFGRgYuXryIe/fuwcDAAHv27BE6xtbWFk+fPkWvXr1w48YN3LhxQ6TdD6d8HTt2DJs3b4aNjQ1atWoFdXV1pKamIjQ0FJmZmbCyspJ4e13yFZD2dliUapZQy1vf7t27l40YMYLxeDympKTEtLW1mbm5Ofvtt99EtrALDw9nlpaWTE1NjWlqarIhQ4awK1euMHd3dwaAhYeHC9UFwNzd3UXOWb5doZeXl0iZuLY+rB8QEMB69OjBlJSUmJ6eHps9ezbLzMwUaUfc9obl/v77bzZgwACmpaXF5OXlWbNmzZiNjQ3bvn27YJu/rKws5uHhwfr27cv09fWZgoICMzAwYIMGDWJnz56t8nOta+WfSUXJ2tpa7HFz585lANjevXsrbZ/P57Nx48axNm3aMDU1NSYvL8+aN2/OJkyYwOLi4urgimjrW0qUPiXV9ta31Dc0vL4hPT2dLV26lJmbmzNdXV0mJyfH1NTUWPfu3dlPP/0k9vOorB8pTx9KSEhgs2bNYsbGxkxTU5PJyckxbW1tZmtrK/Z741PR1rcNO3GM1c8tOUnlOI5rp6+vfzktLa3iSahfGG9vb0yfPh1eXl4iL5gjXw4DA4M36enppowx0XkAhJBKqaio/LpmzZoFbm5u0g7ls6G+4cvH5/Ph6OiYmJGR0VXasZDqozUbhBBCCCGEkDpBgw1CCCGEEEJInaDBBiGEEEIIIaRO0G5UpMFwdnam+biEEEKEUN9ASP1GTzYIIYQQQgghdYIGG4QQQgghhJA6QYMNUiM2NjbgOE7aYdQ5Q0NDcBwnSElJSdIOqcEpKSkR+gy/hu8bQr5W1DcQSVHf8PWgwQYhVdDQ0IC7uzvc3d2ho6NTad0tW7YIfmnGxsYKlRUXF+P48eNwdnZGx44doaKiAjU1NZibm2Pv3r0oLS2tlXgPHz6M2bNnw9TUFIqKiuA4Dt7e3hXW9/Pzw+jRo2FkZAQ1NTWoqqrC2NgYixYtQmpqqkj9Bw8e4JtvvkH37t2hq6sLRUVFGBoaYtiwYTh//rxIfRkZGcHnV/62YUIIaegq6htSU1OxY8cO2NnZoWXLllBQUEDTpk0xZswYxMXFVdpmcnIyZs2aBR6PB0VFRTRp0gS2trY4evSoUL2UlBSRP9Q/TEeOHPnk6/Pw8KiwfSUlJbHH5OXlYdu2bejevTu0tLSgqamJLl26YP369cjJyRGqS33D14MWiBNSBU1NTXh4eFRZ7+7du1i1ahVUVFTw7t07kfJHjx7B0dERqqqq6N+/P0aMGIGcnBwEBwdj3rx5CA0NRVBQ0Cff3Vm5ciWePHkCHR0d6Ovr48mTJ5XW9/f3x927d9GrVy/o6+uDMYbr169j586d8Pb2xsWLF9GpUydB/du3b+P48eOwsLCAhYUF1NXVkZqaipMnTyIkJATr1q3DihUrBPVlZGQEnx+fz68yHkIIaQgq6ht27dqFzZs3w8jICAMHDoSenh4ePHiAwMBABAYGwtfXF+PHjxc57ty5c3BwcAAADB8+HK1bt0ZWVhZu3LiBf/75B2PHjhU5pkuXLoJjPvTh7+xPNW3aNBgaGgrlycmJ/vlYVFQEGxsbJCQkoGvXrpg2bRo4jkN4eDhWrlwJX19fxMfHQ0VFBQD1DV8Vab/CnFLNEoB2+vr6uUxKrK2t2ftvny8bj8djPB6vynolJSWsZ8+ezMzMjE2ePJkBYDExMUJ1nj17xvbs2cPevn0rlP/27VtmamrKALC///77k2M+d+4cS0lJYYwxtnHjRgaAeXl5VVg/Pz9fbP6BAwcYADZmzBih/IKCAlZWViZSPzU1lenp6TF5eXn2+vVrsW1K8n2jr6+fC6Adqwc/Z5QoNbSkrKz867Zt25i0UN/A2PHjxxmfzxfJj4yMZPLy8kxLS4sVFBQIlT19+pSpq6uztm3bsidPnogcW1xcLPR1cnIyA8CmTZtW42uoiru7OwPAwsPDJap/5MgRBoCNGjVKpGzkyJEMAPP29hZ7bFXfN+Hh4UxbW/s6qwc/Y5Sqn2ga1RcoMjISHMdhxowZYsufPXsGWVlZ2NjYCPKuXLmC+fPno1OnTtDQ0ECjRo3QqVMnbNiwAcXFxRKdt/yRK5/PFynz9vaucDrPjRs3MGHCBOjr60NBQQE8Hg8LFixAZmamROetDzZv3ozExER4enpCVlZWbJ1mzZrh22+/FdzVKaeiooLFixcDeP//7lMNGDCgWo+kK3ocXn4X7fHjx0L55VOzPmZgYABLS0sUFxfj33//rUbEhJDPgfqGz2P06NGwtrYWybeysoKtrS2ysrJw8+ZNobL169cjNzcX+/fvR8uWLUWOFfckob5JSUkBAAwePFikbOjQoQCAV69efc6QSD1R/797SbVZWVnB0NAQx48fx549e0T+mPzrr79QVlaGKVOmCPL++OMPBAcHo2/fvhgyZAjy8vLA5/OxYsUKJCQk4MSJE3USa1BQEMaNGwc5OTmMGDECzZs3x507d7B7926cPXsWcXFx0NLSqpNz15Zbt25h9erVWLlyJYyNjWvUhry8PID61aGEhIQAAExMTCSqn5mZibi4OKioqKB169Z1GRohpAaob5A+cb/rGWM4evQoGjdujH79+uHKlSuIiIhAWVkZunbtin79+kFGRvy94bS0NOzbtw/Z2dnQ19dH//790aJFi1qN+eLFi4iPj4esrCzat2+PAQMGiL1JVd7/hYaGYtasWUJlISEh4DgOtra2tRobaRjqz182pNZwHIdJkyZh/fr1CA4OFpnn+ddff0FJSQmOjo6CvGXLlmHPnj1Cd+UZY5g5cyY8PT0RFRWFPn361GqcmZmZmDJlCpo0aYLo6Gg0a9ZMUObn54eJEyfip59+wu7du6tsy9vbW3BXRRIODg7o2rVrDaIWVlJSIljw/eOPP9a4HU9PTwCAnZ3dJ8dUU/7+/rhz5w7y8vJw+/ZtnD17FkZGRlizZo3Y+vfv34evry9KS0uRlpaGoKAgZGdn448//oCqqupnjp4QUhXqG6pWW32DOE+fPsU///wDfX19oZs4ycnJeP36NXr27Im5c+di//79Qsd169YNQUFBaN68uUib586dw7lz5wRfy8rKYv78+di+fXuFT9mra9WqVUJfN23aFF5eXhg0aJBQ/tChQ+Hg4IATJ06gW7dusLW1BWMM4eHhePz4Mfbt24cePXrUSkykgZH2PC5KNUuoYs1GUlISA8BGjBghlH/9+nUGgI0bN66iQ4VcuXKFAWAeHh5C+eLmV1Y2v9PLy0tk7cDPP//MADAfHx+x5+7evTvT1tYWuz7gY+XxSJoqW8PwoarWbKxevZrJycmxK1euCPKmTZsmds1GRX777TcGgPXr10+i+tUhyZqNcmPGjBH6jExNTdmjR48qrB8cHCxUX01Njf3111+VnoPWbFCiVLepqjUb1Dd8nr7hY0VFRaxv374MADt06JBQWUxMDAPAZGVlmaqqKvPy8mKvX79mycnJbNasWQwAMzc3FzrmxYsXzN3dnV2/fp3l5uayly9fsqCgINaxY0cGgH3//fcSx1aREydOsIMHD7KUlBSWn5/PHjx4wNauXcsaNWrEFBUV2dWrV0WOKS0tZUuXLmUcxwl9rlOmTGHJyckVnovWbHzZiZ5sfKHat28PU1NThIaG4vXr12jcuDEAwMfHBwCEHpMD73eR2L17N44cOYKkpCS8ffsWjDFBeVpaWq3HWL41bGxsLB4+fChSXlBQgMzMTGRmZla55ay4ucB1LTExEevWrcOSJUvQvXv3GrVx6tQpzJ8/H4aGhjh8+HAtR1g9x44dAwBkZ2fj2rVrWLFiBbp3746AgAD069dPpP6wYcPAGENRURFSUlLwxx9/YPLkyYiNjcWvv/76ucMnhEiA+obPr6ysDM7OzoiMjMQ333wj8hmXlZUBAEpLS7F27Vo4OzsDALS0tPD777/jxo0biIuLE3qKpKenJ7QTlpqaGoYPH46ePXvC2NgYO3bswLJlyz5pqtnHu1y1adMGK1euhJ6eHmbPno0NGzYIbcmbl5eHCRMmID4+Hr6+vhg4cCA4jsP58+excOFChIaGIjY2FkZGRjWOiTRMNNj4gk2ZMgWXL1+Gv78/5syZg7KyMvj5+UFXV1fk8aejoyOCg4PRrl07jB8/Hnp6epCXl0d2djZ27tyJwsLCWo/v9evXAIA9e/ZUWu/du3dVdijSMG3aNBgZGUm0La44p0+fhqOjI/T19REeHg59ff3aDbCGNDU1YWtrizNnzqBDhw6YOnUqkpOTBXONP6agoIB27dph69atyMvLw65duzB48GCxiwQJIdJHfcPnU1ZWBhcXF/j6+mLatGnYt2+fSB0NDQ3Bv0eMGCFSPnz4cMTFxeHy5ctVTllr2rQphg4dCh8fHyQkJNTJ1FxnZ2fMmzcPly5dEsrfsGEDgoODcfLkSaHrGDt2LNTU1DB48GCsWbMGBw8erPWYSP1Gg40v2IQJE+Dm5obDhw9jzpw5uHDhAtLS0rBgwQKhxWkJCQkIDg6Gvb09QkJChOZ5xsbGYufOnRKdr3wBW0lJiUjZxy/zAQB1dXUAwM2bNz95T3BpzMtNTEwEUPFuThYWFgCAEydOiNwhOn36NEaPHg0dHR1cuHBBZA/z+kBdXR3m5uYIDAzEw4cP0bFjxyqPsbOzw969e8Hn82mwQUg9RX1DxWpzzUZZWRmmT5+OQ4cOYdKkSfD09BS70LtNmzaQlZVFaWkpNDU1RcrL8/Lz8yU6b/kALC8vr8axV0ZBQQHq6uoi7YeGhgKA2EXgtra24DgOV65cqZOYSP1Gg40vmJ6eHuzs7BAaGork5GTBNJ2PH+E+evQIwPtpMR8vKLt48aLE5yt/XCvurdPXrl0TyTM3N0dAQABiYmJqpUOJiIiQuL6hoeEndygVbR8ZGRmJBw8eYMSIEdDV1RUZSJQPNLS1tREeHl6vHymXT5Go6KnGp9YnhHx+1DdUrDb6BkB4oDFhwgQcPHiwwh2lFBUV0bt3b1y8eBF37twReXpx584dQWySSEhIqFb96nr06BFev36NLl26COUXFRUBeL+9rZqamlBZRkYGGGNQVFSsk5hIPSftRSOUapYg4Uv9/Pz8GAC2fPlypqamxtq3by9SJzo6mgFgY8eOFcq/desW09LSEvviIHGLucrb6devHystLRXKl5OTE1l89/LlS6ampsZ0dXXZrVu3ROJ69+6dxIus60p1FwEyVvkC8dOnTzNFRUXWtGlTlpSUJFF7+N8Cu5qoaoF4bm6u0OL2D3l6ejIArG3btkL50dHRrLCwUKR+SkoKa9GiBQPAoqKixLZJC8QpUarbJOlL/ahv+DSV9Q2lpaWCfmDs2LGspKSkyvZ8fX0ZANa/f3+hF/7dvXuXKSsrMzU1NaGXpcbFxbGioiKRdnbs2MEAsP/7v/8TWUBfHpMki+Bzc3NZYmKiSH5WVhazsbFhANimTZuEymbPns0AsKlTpwpdc2lpKXNxcWEAmJubm9jz0QLxLzvRk40v3MiRI6Guro6tW7eiuLhY5M4VAJiZmcHMzAxHjx5F37590atXLzx9+hRBQUEYOnSoYOFwVSwsLGBpaYkLFy7AwsICffv2xZMnTxAUFIThw4eL7Meuq6sLPz8/jB07Fl26dMHgwYPRvn17FBQU4MmTJ4iIiEDv3r1x5syZWvkspC0pKQmjRo1CYWEhbGxs4OfnJ1LH0NBQsDgQeH8zAEC1tjA8cOAAoqKiAEDw4qgDBw4IFko6ODgIpnVlZmaiR48e6Nq1K0xMTNCsWTNkZWUhISEBV69ehbq6usj82mXLluHOnTuwsrJCy5YtISMjg0ePHiE0NBRFRUVYsmQJLC0tJY6XEPL5Ud9Qd8rXJaiqqqJdu3ZYu3atSJ2Pp2tNmDABAQEBOHbsGLp06QJ7e3vk5OTg+PHjKCgogJeXl9Bi76VLlyIpKQnW1tZo0aIFCgoKEBsbiytXrkBLSws+Pj4iL18tX4guyfucMjMz0aVLF5iamsLExAR6enpIS0tDaGgoMjIyMHDgQCxatEjomBUrViAoKAiHDh3ClStX0K9fP3Ach/DwcNy8eROGhob44YcfqvNRki+FtEc7lGqWIOGTDcYYmz59OgPAOI6rcOu5ly9fMhcXF2ZgYMCUlJSYiYkJ27NnD3v8+LHEd68YYywjI4NNnTqVNW7cmDVq1Ij16tWLnT17Vuz2huWSkpLYjBkzGI/HYwoKCkxLS4uZmJiwhQsXsvj4eEkusc7U5pON8PDwKrddtLa2FjomMTGRAWCTJk2q9vkrSu7u7oK6b9++ZatWrWJ9+/ZlTZs2ZfLy8kxFRYUZGxuzRYsWsX///Vek/aNHj7KxY8ey1q1bMxUVFSYvL8+aNWvGRo8ezc6cOVNpbPRkgxKluk2SPtlgjPqGT1FZ31DV7+CKrre4uJj9/PPPzNjYmCkqKjJ1dXU2cOBAdv78eZG6f/zxBxs0aBBr3rw5U1JSYkpKSqx9+/bsu+++E/t7mzHGunXrJvKEpCI5OTls3rx5rEePHkxHR4fJyckxDQ0N1qdPH7Z///4Kn9akp6ezBQsWsDZt2jAFBQWmqKjI2rVrxxYvXswyMjIqPB892fiyE8fYf1vYkYaD47h2+vr6l9PS0tSqrk1qqnzOa3UWGNam3bt3Y+HChbh582aN305en9jY2CAiIgKV/d4xMDB4k56ebsoYu/8ZQyPki6CiovLrmjVrFri5uUk7lC+atPuG6srNzYWWlhbc3NywZcsWaYcjoqq+gc/nw9HRMTEjI6Pr542M1AaaRkVIFZ48eSJ4HH337l106NDhs5374sWLGDFiRIMeaJSUlNCCcULIF0eafUN1Xbp0CfLy8li8eLG0QxGgvuHrQYMNQirh6uqK7Oxswdefe0/3v//++7Oery7IyMjA3d1d2mEQQkitkXbfUF2DBw9GQUGBtMMQQn3D14MGG4RUwtXVVdohNHgyMjI1fvEhIYTUR9Q3fDrqG74e4jd9JoQQQgghhJBPRIMNQgghhBBCSJ2gwQYhhBBCCCGkTtBggzQI3t7e4DgO3t7e0g6FEEJIPUF9AyH1Hw02CGlA8vLysH37dkycOBEdOnSAjIwMOI5rMHu9E0IIqTu+vr4wMzODiooKtLS0MGTIEFy+fFnaYZGvHA02CGlAXr58iSVLlsDPzw8FBQXQ0tKSdkiEEELqgQ0bNmDSpEl48eIF5syZg3HjxuHSpUuwtLQEn8+XdnjkK0aDDUIaEB0dHYSFhSEzMxMpKSno2bOntEMihBAiZffv34e7uzvatWuHGzduYPv27fjtt98QHR0NOTk5zJw5EyUlJdIOk3ylaLBBpC4yMhIODg5o0qQJFBUV0aJFC4wePRpRUVFVHnvixAk4OTmhTZs2UFZWhoaGBqysrHD06FGx9c+dOwd7e3sYGBhAUVERTZo0gZWVFQ4cOCBULyEhAWPGjEGLFi2gqKgIXV1d9OzZExs3bqyVa64pVVVVDBw4EI0bN5ZqHIQQUteob5Ccl5cXSkpKsGLFCmhoaAjyjY2NMW3aNDx69AgXLlyQYoTka0Yv9SNStXPnTixatAiNGjXCqFGj0LJlS6SmpiIqKgrHjh1Dnz59Kj1+2bJlUFBQQJ8+faCvr49Xr14hKCgI48aNw44dO/Ddd98J6gYHB2PkyJHQ1NTEyJEjBfWvX7+Ov/76CzNnzgQAXL16FX369IGcnBxGjhwJHo+H7Oxs3L59GwcOHMCyZcvq9DMhhJCvHfUN1RMREQEAsLe3Fymzs7PDvn37EBERATs7u88dGiE02CDSk5iYiMWLF0NfXx+XLl2CoaGhoIwxhvT09CrbOH36NFq3bi2U9/btW/Tu3RurVq3CrFmzoKysDOD9nR/GGMLDw9GlSxehYzIzMwX/Pnz4MIqKiuDv74+RI0dWWK8yfD6/WnNku3btCgcHB4nrE0LIl4r6hv9I2jc8ePAAqqqqaNKkiUhZ27ZtBXUIkQYabBCp+e2331BWVoZ169YJdSYAwHEcDAwMqmzj484EeD/VyNnZGW5ubkhISIC1tbWgTQCCDuZD2traQueWpF5l+Hw+Vq9eLVFdAJg2bRoNNgghBNQ3fEjSviEnJwd6enpiy9TV1QV1CJEGWrNBpCY+Ph4APumx7suXL7F48WJ07NgRysrK4DgOHMfBzc0NAJCWliao6+TkBADo1asX5s+fj+PHj+Ply5cibY4bNw4yMjIYNWoUXFxc4Ovri6dPn1YrLg8PDzDGJE60RzwhhLxHfQP1DeTLQoMNIjU5OTngOA76+vo1Ov7169fo2bMnfvnlF2hra2PGjBlYuXIl3N3dBY+4CwsLBfUdHR0RGBiITp06Yf/+/XB0dETTpk3Rr18/XL9+XVDP3NwcfD4fVlZW8PX1xaRJk8Dj8WBqaorw8PBPumZCCCGVo76h+jQ0NCp8cpGbmyuoQ4g00DQqIjWampqC+bfNmjWr9vF//vknnj59inXr1mHFihVCZZs2bcLJkydFjhk5ciRGjhyJ3NxcREdHIyAgAH/++ScGDRqEpKQkaGpqAgCsrKwQGhqK/Px8xMXFITg4GHv37sXQoUNx69YtsY/oP0RrNgghpGaob/iPpH1D27ZtERMTg+fPn6Np06ZCZeVrNcrXbhDyudFgg0iNmZkZLl++jLCwMEyfPr3axz969AgARBbqAcDFixcrPVZdXR2DBg3CoEGDUFpaCk9PT8TFxYns5NGoUSPY2NjAxsYGmpqaWLVqFc6dO4fZs2dX2j6t2SCEkJqhvuE/kvYN1tbWiImJQVhYGKZOnSpUdvbsWUEdQqSBplERqZkzZw5kZWWxcuVKPHnyRKhMkh1HeDwegPd7sX/I19cXp0+fFql//vx5FBQUiOSXz81VUlIC8L4zKn/s/KEXL14I1asMzcslhJCaob6h+n3D9OnTIScnh/Xr1wtNp7p9+zYOHToEIyMj9OvXT6K2CKlt9GSDSI2JiQl27NiBhQsXwtjYGA4ODuDxeHj+/DkiIyMxdOhQ7Nixo8Ljp0yZgs2bN2PhwoXg8/ng8Xi4ceMG/vnnH4wePRoBAQFC9d3c3PD06VPY2NjA0NAQHMchKioK8fHxsLCwEOzbvn37dpw7dw62trZo3bo1lJSUcPXqVZw/fx5GRkYYPXp0XX4sVVqyZAkyMjIAADdv3hTkqaqqAgB+/PFHdOjQQWrxEULIp6C+ofratWsHDw8PrFy5Ep07d4ajoyPevXsHPz8/FBcX448//oCcHP3JR6SDvvOIVM2fPx+dOnXC9u3bERoairdv30JPTw/m5uYYN25cpcc2b94cERERWLp0Kf755x+UlJSge/fuCAsLw7///ivSoSxbtgwBAQG4cuUKzp49C3l5ebRq1QpbtmzBt99+C1lZWQDA3LlzoaGhgbi4OERGRoIxhpYtW2LlypVwdXWFmppanX0ekjh27JjI3b7jx48L/u3s7EyDDUJIg0Z9Q/WtWLEChoaG2LFjB/bt2wcFBQX07t0ba9asQc+ePaUaG/m6cYwxacdAaoDjuHb6+vqX09LSpPvbjZBaZmBg8CY9Pd2UMXZf2rEQ0tCoqKj8umbNmgXlW7wS8iXg8/lwdHRMzMjI6CrtWEj10ZoNQgghhBBCSJ2gwQYhhBBCCCGkTtBgo+EqKioqov9/5ItTWFgoA6CwyoqEEBFFRUV54nZWIqQhy8/PBwD6xm6g6I/VhuvVmzdvFN69eyftOAipNe/evcPbt28VALySdiyENEQlJSXP7t27ly/tOAipTcnJySgpKXlSdU1SH9Fgo4FijL1TUVG5Im7PcEIaqpCQEKioqFxmjOVJOxZCGqiQwMBArqSkRNpxEFJrfHx8cnNycv6WdhykZmiw0YBlZWX9sW7dujx6ukG+BO/evcP69evzsrKyDkg7FkIaKsZYMsdxj/bv318m7VgIqQ1RUVG4du2aHIBQacdCaoYGGw3bweTk5OABAwbkJSYmgrYxJg0RYwyJiYkYMGBAXnJycjCAg9KOiZCGLDc3d9SPP/6YtWnTprLXr19LOxxCaiQ/Px9HjhzBoEGD8goLCx0YYzQ9sIGi92w0cBzHySorK6/mOG62pqamUufOncvU1dVlZWTq5ziytLRUgTEmIysrW8BxnLTD+WIxxlBaWqrEcVyZrKxskbTjEaesrAy5ubmlN27ckMnOzi5gjP2Wl5fnzhgrlXZs/9/encdFVb1/AP8ctmFfFFRwGRBRDDFD1BRlcS9N3HMpRaXgW2buppmgkWalqVlm4vbTJE3R3HeQFLdcUCsMFdTEDUKRfXt+f+CMjDPsMwzL83695lWee+655w7nmTtn7jnnMlbTCSFaWFparszMzPR2dXXNatq0qY6hoWG1vDAQEfLy8ox1dXVzdHR0ePyXBhUUFOgUFBQYPr8GV8u7X7m5ufTo0aP8c+fOGRoZGV1NSUmZQUSR2q4XqzjubNQSovCbuxuA5gBMtVyd4rwK4F0A8wE803Jd6gIzAEEANgGI0XJdipMG4BaAi8QfRoypnRDCFEBXANYA9LVcHVUEgIkAkgFs0XJd6goPAP0ALED1XOEpH8ATAGeJ6KGW68LUgDsbrEoIIZoDOAPAl4hOa7s+dYUQoguAXQBeJ6JbWq4OY4wpEELMAjAQgBcRVcu7sLWREGINAHMAI/iHHqZp3NlgGieEMAQQDWADEa3Qdn3qGiHExwDGAPAgour4KxZjrA4SQngD+AVAByK6q93a1C3Pr8unAGzk6zLTNO5sMI3jX1C06/kQu18APCWi97VdH8YYE0LYArgAYCwRHdF2feoiIYQDCkccDOQRB0yTquVkMVZ7CCH8UDhe2J87Gtrx/H33B+AphBir7fowxuo2IYQ+gK0AfuSOhvYQUTyACQC2CiFstF0fVnvxnQ2mMUKIVwEcBeBNRH9quz51nRDCBUAkgB5EdEXL1WGM1VFCiK8BtAHQj4iq5YpIdYkQYiGADgD68mqATBP4zgbTCCGEBYDtAD7mjkb18PzvMBnAjud/H8YYq1JCiEEAhgF4hzsa1cY8ALooXL2QMbXjzgarNCHEh0KICUX+LQBsAHCYiHgpw2qEiH4GcATAOlHkQSdCiAlCiA+1VzPGWG0jhPhdCGFS5N9OAFYDGE5EydqrGSuKiPIAjAQwXgjxRtFtQojDPMSKVRZ3Npg69AKQWuTf0wDYAZiqneqwUkwB0BSKf59nAHpqpzqMsdpGCNEAhUOlMp7/2xiFd7uDieicNuvGlD1/nsUIAOuFENIim3QBuGunVqy24M4GU4fXAFwEACGEJ4DpKPzlKlurtWIqPf+7DAMwUwjR7XnyRRT+HRljTB1ew/OHdT6/i/oDgGsAVmm3Wqw4RHQSwFcAtgshJM+T+drAKo07G6xShBDWACwA3BJCNAIQBsCPiG5rt2asJM//Pn4Awp7/3W4BsBJC1NdqxRhjtYUbnv8IhcLV8DoAeJ9XJaz2vgVwG8Cy5/++iMK/JWMVxp0NVlmvAbiEwlutvwAIJaKDQOFt8+edEVZNCCGsnw9nABEdALAOhR1EHRT+HfkXLMaYOrgBuCiEcAOwEMAQIkoHACGEnRBCT6u1YwqEEE0B+VLp4wH0EEK8A+5sMDXgzgarLDcUfkn9AkA2gAVCCHMhxCwU/lrup8W6MWV+KLwLNUsIYQZgPoBcACEo/DvyRYUxpg5uAG6icJ7GB0QUK4RoK4TYCiAGQBOt1o7JCSF0ARwWQpwQQvRC4Ry+ISi8y2EAwEYIYaXNOrKajTsbrLJkX05HAPgAwFwUXmBeBdCTiL7RVsWYsud/j54o/PvcQuHf638ARgEgcGeDMVZJz7+YNgDwGYDdABKEEL8BOATgPAAHIkrQXg1ZUc+freEKYA2AFSh8qrg9ChcR2Y7CuTZ815tVGD/Uj1WKECIBhXM2fgPw1vP/fklE/2izXqx0QoiWAD4B4Atgz/P/PiEiB61WjDFWowkhfACsR+Ev5IkAXgGwGMBaIsrUZt1YyYQQOgAGo/CHKAB4BKA5Cp/2zj8esgrhOxuswp5PJpYCkKBwecP2RDSeOxo1AxH9Q0TjAbRH4d9PAsCeb5czxippCAqvDWYAfgXgSEQruaNR/RFRARFtR+GdjLko/DGxOQpHLzBWIXxng1XY8zH/GwB8RESJWq4OqyQhhB2A71C4mtgzbdeHMVYzPX/Iqx2ARc8fGMdqqOfLFo8E8CoRzdJ2fVjNxJ0NxhhjjDHGmEZoZek5IUQ9FD51uhEKVzpgrLLSAcQBiCSiXG1X5mVCCFMUtvkmAAy1XB1WN+UBSAYQQUR3NX0wIYQhgO4AHAAYa/p4jKlJGgqvJSeq4loihHAC0A2AFXhoO9OODAAJAI4RUZYmDlCldzaEEFJLS8v/y8zM7NS1a9ecli1bGhgaGnJwsUohIqSmpuadO3cu98aNG7oGBgabUlNTJ1WHTocQop6FhcX/ZWVl9XR3d892cXExMDEx0dV2vVjdk5OTQ/fu3cs5cuSInr6+/o0nT568T0Sn1X0cIYSRubn5T9nZ2UPatGmT+9prr+mbmprqFY7GYKz6IiI8ffo07+zZs7nx8fE6+vr6G1JTU6doYiiYEOINCwuL7wDY9erVq6BRo0b6+vr6HCSsShER0tLS8i9dupRz7do1fUNDw51Pnz59j4gy1HmcKutsCCGkJiYmZ2fPnm398ccf65qamlbJcVndcvfuXYwfPz7j7Nmzkc+ePRuozQ6HEKKemZnZ6TFjxtgvWLDAoF69etqqCmNyubm52LFjByZMmJCekZHRh4hOqatsIYSRmZnZ0d69e7/23XffGdna2qqraMaq1O3btzFmzJiMS5cuHXn27NlQdXY4hBADTE1Nf9m2bZtR7969oavLvz8x7Xvw4AEmTZqUdfDgwcvPnj3roc4OR5V1NqysrI5OmTLFe968eRxVTKOys7PRrVu3jPPnz08iorXaqoeZmdlPb7/99tg1a9YY8K+6rLrZu3cvRowY8Sg9Pb0RqelCoK+v/0n37t3n7d+/34i/QLGaLjMzE507d06PiYn5HxFtUkeZQggjiUSSHBUVZdSxY0d1FMmY2uTn5+Ott97KOnr06Bc5OTkh6iq3SoYwCSEsMjMzu3788cd89WEaJ5FIMGPGDGMrK6sJ2qqDEEI3Pz//7VmzZnFHg1VL/fr1g5WVlTGADuoq09TUdPysWbO4o8FqBSMjI0yfPt3EyspqvBqL7dO2bds87miw6khXVxezZs0yNDY29lNnuVU1X8KnQ4cO2RYWFlV0OFbXvfnmm0hLS3N/PklVG9o1aNBAODk5aenwjJVMCIGRI0ca6urq9ldTeQ1zcnKaeXp6qqM4xqqFAQMG4NmzZ12FEGpZUMfc3HzI6NGjzdRRFmOa0LVrV+Tl5TURQqhtHGxVdTYaOjo6amXlK1Y3mZiYwMjIKA+AtiZKNGratGmBlo7NWJlIpVI9Y2PjJmoqrqGNjU22nh5/1LPaw9zcHAYGBvkofLhdpenr6zdp1qyZOopiTCN0dXXRoEGDbAAN1VVmVXU2eNUpVuUMDAwKoL2llfUNDQ15/BSr1gwNDaGnp6euZWn1DQwM+MFNrNZ53tmQqKMsIYSBRKKWohjTGIlEQlDj96c61QHw9vaGOsbPCyHg7e1d+QoxpiUcC4y9wPHAWMk4Rlhl1KnORm10/vx5vPnmm7CysoKJiQk6duyILVu2lLucgoICrFy5Em3btoWRkRFsbGwwfPhwxMXFqcxPRNi+fTu8vb1ha2sLY2NjtGrVCgEBAbh165ZS/suXL2POnDno06cPbGxs+AOHqZ26YqGo3NxctGvXDkIIODs7q8wjix03NzcYGxvD3NwcXl5e2L17d7HlXr9+HX5+fnBycoKRkREaN26MXr16lbgPY+Whjnh49OgRFi1ahKFDh8LBwQFCiFK/cJb32vCy+Ph4mJqaQgiBwMDActWXsfLQxjUjOzsb06ZNg6enJ+zs7GBoaIhGjRrBw8MD69evR26u1h8PphlEpPEXgI8CAgIySctu375Nf//9d6XL+fvvv+n27dtqqFHlREREkIGBAZmampK/vz9NmzaNHBwcCAB98cUX5SrrvffeIwD0yiuv0IwZM2jMmDEkkUjIwsKC/vzzT6X8kyZNIgBka2tLgYGBNHPmTOrTpw8JIcjMzIxiYmIU8gcFBREAMjAwoDZt2hAA8vLyqszpl8ra2joNgD1VQRt/+QVgYM+ePZ9q9AQrgWOhbD777DMyMTEhANSqVSul7QUFBTRkyBACQI6OjjRx4kR67733qEGDBgSAvvvuO6V9oqOjydDQkPT09Gjw4ME0a9YsGjduHFlYWBAACgoKqnB9yys0NJSsrKx+IfW0+fZOTk5PqqzyasTxUHw5AEgIQS1btiRjY2Mq/NpQvPJeG4oqKCggLy8vecwFBASUua6aZGlpmQ7AjtQQJ9bW1qf27dtX5edQWRwjZVPaNSMlJYUMDQ3J09OT/P39afbs2RQYGEhSqZQAUO/evSk/P78yp6YWzs7OTwB0JHV9J1JXQSUepJp0NmqT3NxccnR0JIlEQhcvXpSnp6amkouLC+np6dE///xTprKOHz9OAKhbt26UlZUlTz969CgJIcjT01Mhf2JiIgkhSCqV0pMnit8tli5dSgDIz89PIf3atWt04cIFysnJofv373Nng6mNOmOhqAsXLpCenh6tWLGi2AvHr7/+SgDIw8ODMjIy5OmPHz8mqVRKEomE4uPjFfbp27cvAaBdu3YppCckJJCZmRkZGhpSZmbVfFxyZ6P2UWc8PHjwgE6cOEGpqalERNSqVasSOxsVuTYUtXz5ctLT05Pn5c4G0wRtXjMKCgooOztbZZ28vb0JAO3Zs6fcx1Y3dXc2avQwqry8PCxatAiOjo4wNDREixYtsGjRIty6dQtCCPj5+SnkVzXmcMOGDRBCYMOGDTh8+DC6dOkCY2Nj1K9fH2PGjEFSUpLScavDEKBjx47h5s2bGDVqFF577TV5upmZGebNm4e8vDysX7++TGX99NNPAICQkBAUnbjWo0cP9O3bF1FRUbh+/bo8/c6dOyAieHh44OXljPv3L1xF8/HjxwrpLi4ucHNzg76+fvlOlJUJx4J6YkEmJycHfn5+eP311zFx4sRi8+3atQsAMGfOHBgZGcnTra2tMWXKFGRnZ2PdunUK+yQkJEAIgTfeeEMhXSqVwtXVFVlZWUhLSytXfZkijgf1xEPDhg3h6ekJM7OyrdRakWuDzI0bNzB79mzMnDlTod5MMzhGtHPNEELAwEB53rWenh4GDRoEAGUabljT1Og1CsePH49NmzbB0dERH374IbKzs/Htt9/i9OnT5S5r9+7d2LdvH9566y106dIFUVFR2LRpE+Li4hAdHa2WiVHqdOLECQBAnz59lLb17t1bIU9ZyjIxMYGHh4fKsg4cOICoqCi0atUKANCiRQsYGBjg1KlTSE1Nhbm5uTz/3r17AQDdu3cv3wmxSuFYUE8syAQHByMuLg4xMTElnu/Dhw8BAA4ODkrbZGkREREK6S4uLoiNjcWBAwfg6+srT79z5w6uXr0KV1dXWFtbl6u+TBHHg3rjoawqem0oKCjAuHHjIJVKMW/evAr9nVj5cIxo55pRnIKCAhw8eBAA4OrqWu79q7sa29k4duwYNm3aBHd3d0RFRcl/VZw7d26FfhXZs2cPIiMj5V+48/Pz0bNnT0RGRuLMmTPo3LlzheqZkJCADRs2lDm/paUlJk+eXGo+2cTtFi1aqCzD2tq62MndRaWnp+P+/fto06YNVD31V/ZQuqJl1a9fH19++SWmTZsGZ2dn+Pr6wtzcHDExMTh+/DgCAgLw0UcflXpsph4cC+qJBZnz58/jq6++wsKFC9GyZcsS88o6BfHx8WjdurXCtvj4eADAP//8o5AeEhKCU6dOYejQoRgwYABatmyJR48eITw8HA4ODti6dWuZ68qUcTyoNx7Ko6LXhmXLliE6OhonT54ELwureRwj2rtmyOTk5GDhwoUgIiQnJ+PYsWOIjY2Fv78/fHx8ynzsGkNd47FKekEDczb8/PwIAP32229K2xYtWkQAaOzYsQrpXl5eSuNN169fTwBozJgxSuXItq1YsUIhHeWYbyCbYFfWl1QqLVO5vXr1IgAUFxencnvz5s3JwMCg1HLu3bsnH3OuSlRUFAGg999/X2lbWFgYmZqaKtS/S5cuFBUVVeIxec6GenEsqCcWiIiysrLolVdeIXd3d8rLy5Ono5jxtxs3bpTPdyo6zyIpKYns7e3liyK8LCEhgdzd3RXO18rKir799luF42pabZyzwfGgvnh4WWlzNmTKc224fv06GRkZ0ZQpU+RpsveG52xoBseI9q4ZMs+ePVOouxCCZs6cSbm5uWU6rqbxnI3nYmJiAABdunRR2qYqrTTt27dXSmvSpPDBuk+ePCl3eTLe3t7l+oMkJCRU+FhVacGCBRgzZgxmz56Nu3fvIi0tDSdPnkReXh58fHwQHh6u7SrWGRwL6vPZZ58hLi4O69atU3mn72WjRo2Cj48Pfv/9d7i6uuKjjz5CYGAgXFxc5ENIXi7n3Llz6Ny5M6ysrHDhwgWkp6fj1q1bmDBhAqZMmYJhw4Zp5NzqCo4H7SrPtaGgoAB+fn6ws7NDSEiIFmtdt3CMqE95rxkypqamICLk5+fj7t27+P777/HTTz/B29sbqampGqyxdtTYzkZqaip0dHRQv359pW0NG5b/CetFx5bK6OkVjjLLz88vfwU1TDb57unTpyq3p6amKk3Qq2g5RfMBhbdgg4KCMHHiRMyZMwdNmjSRz/nYu3cvjIyMynQrk6kHx4J6YuHixYtYunQpPv300zKPmdXT08OBAwcQHBwMHR0d/PTTTwgPD4evry+2b98OALCxsZHnz83NxYgRI6Cjo4Ndu3bJn83h4OCAr7/+Gm+//TZ27typNM+DlR3Hg3rioSLKe21YsWIFzpw5g9DQUBgbq+tB9qw0HCPau2a8TEdHB02aNMH//vc//PTTTzh16hS++OKLCpVVndXYORvm5uYoKChAcnKy0mRK2aTN6kBTYw6LzqV4+VeFlJQUJCUllekXChMTE9ja2iI+Ph75+flKPXPZuEXZ8QBg//79AKByXKGNjQ1cXV1x+vRpJCUl8UTXKsCxoJ5YuHLlCvLz8xEcHIzg4GCl7devX4cQAhYWFgq/1kkkEgQFBSEoKEghf2RkJADA3d1dnhYbG4v4+HgMHjxY5Zer7t27Y+vWrbhw4ULtHLdbBTge1BMPFVHea8Ply5dBRMW29dWrV2P16tXw9fWVr/zGKo9jRLvXjOLIJqfLrh21SY3tbLz66qu4dOkSoqOjMWDAAIVt0dHRWqqVsoSEBMyfP7/M+aVSaZmCxcvLC4sWLcLhw4cxYsQIhW2HDx+W5ykLLy8v/PLLLzh16hQ8PT0Vth06dEiprJycHADFL2EoS+eJflWDY0E9sdCyZUtMmDBB5ba1a9fCwsICQ4cOLfMvsD///DMAKNSJY0fzOB7Ud20or/K2by8vL/kv4EXdv38f+/fvh7OzMzw8PHgpXDXjGKme14zExEQAqJ2PCFDX5I+SXtDABPEjR44QAHJ3d1eYmHn//n1q1KhRuSc4rV+/XukYsslJLz/RF1Uwubk0ubm51Lx5c5JIJHTp0iV5etGH0ly/fl1hn8ePH9Pff/9Njx8/Vkgv+lC/og+bKe6hfmFhYQSAXFxclB7cJHs/27dvX2zdeYK4enEsqC8WioMSJvs9far8Z/71119JR0eHOnTooDBpMCsriywsLEhHR4cOHTqksM+9e/fI1taWANCVK1fKVK/Kqo0TxDkeNBcPpU0Qr+y1QYYniGsWx4j2rhlXr16lpKQkpfT09HT5A18r8wRzdVH3BPEae2ejZ8+eGD16NH7++We4urrC19cX2dnZ2LZtGzp16oQ9e/ZAR6fGTkkplZ6eHkJDQ9GnTx9069YNI0eOhLm5OcLDwxEfH4+QkBClJdhWrlyJ+fPnIygoSOGWn4+PD/z9/REaGorXXnsN/fr1w8OHD7F161aYm5tj1apVCuUMGzYMq1evRmRkJJycnDBgwABYWVkhJiYGR44cgUQiwbJlyxT2iY2NxZdffgkAyMzMlKfJHhxkbW2Nb775Rr1vUh3BsaC+WKiITp06oWnTpmjdujUMDQ1x7tw5REZGonnz5vj1118VhiZKJBIsWbIE/v7+eOONN9CvXz+0bt0aDx8+xM6dO5GamooPP/ywVq6zXlU4HtQbD0Uf7nb//n2ltG+++UY+FKci1wZW9ThGtHfN2L59OxYvXgxvb284ODjA3Nwc9+7dw4EDB5CcnIxu3bphypQplTzD6qfGdjaAwqdXOjs7Y926dfjuu+/QpEkTTJ48GT169MCePXs0NgmuuvDx8cHJkycRFBSEbdu2IScnBy4uLvj8888xevTocpW1evVqtG3bFqtXr8aKFStgamqKt956C1988YVS0Onq6uLgwYNYvnw5tm7dirCwMOTk5KBBgwYYOXIkZs+erfRl6cGDB9i4caNC2sOHD+VpUqmUOxuVwLGgvlgor7fffhvh4eE4c+YMcnNz4eDggLlz52LGjBkqJ05OmDAB9vb2WLZsGc6cOYP9+/fDxMQEbdu2hb+/P8aOHavR+tYFHA/qi4eXP7dfTgsODpZ3NipybWDawTGinWtG//79kZiYiOjoaJw5cwZpaWmwsLBA27ZtMWLECIwfP17l0MIaT123SEp6QQPDqEqyZs0aAkCrVq2qqkOyaqiuDKMqCccCK0ltHEZVEo4HVhG1bRhVSThGGBE/Z0PBgwcPZBc5uXv37iEkJAR6enp46623tFQzxqoWxwJjL3A8MFYyjhFWlWr0vZovv/wS+/btQ7du3dCgQQPcuXMHe/fuxbNnz/D555+jcePG2q4iY1WCY4GxFzgeGCsZxwirSjW6s9G3b19cv34dBw8eRHJyMiQSCV599VV8+OGHSsuZMVabcSww9gLHA2Ml4xhhVanGdzb69u2r7WowpnUcC4y9wPHAWMk4RlhVqtFzNhhjjDHGGGPVF3c2GGOMMcYYYxrBnQ0tsLe3h729vbarwZjWcSywuobbPGMvcDzUDdzZYBpx8OBB9OzZE5aWljAyMoKrqyuWLl2K/Pz8UvfNzc1Fu3btIISAs7NzFdSWMc05f/48hg4dCgcHBxgZGUEqlcLX1xdRUVFKeR89eoRFixbJ8wshIITQQq0ZK7/09HRs3rwZw4cPR8uWLWFkZARLS0t4eXkhLCys2P0KCgqwcuVKtG3bFkZGRrCxscHw4cMRFxenMr+9vb08Nl5+BQYGaur0GCu3qKgoTJ8+HT4+PrCwsIAQAn5+fsXmr8g1gIiwfft2eHt7w9bWFsbGxmjVqhUCAgJw69YtNZ9RxdToCeKselqxYgU+/vhjmJubY/DgwbC0tMTRo0cxbdo0nD59Gr/++muJ+3/++ee4ceNGFdWWMc3ZsWMHhg8fDolEgkGDBqFp06a4e/cudu7cid27d2PdunUYN26cPP9ff/2FOXPmQAgBJycnGBsbIyMjQ4tnwFjZ/f7773j33XdRv3599OjRA0OGDMGjR48QHh6OUaNG4eTJk/j++++V9gsMDMSaNWvwyiuv4KOPPsLDhw+xdetWHD58GNHR0XjllVeU9rGwsMDkyZOV0t3d3TVxaoxVyLp167Bx40YYGxujWbNmSE1NLTF/Ra4BkydPxooVK2Bra4uBAwfC3NwcMTExWLNmDcLCwnDy5Em0bdtWnadVfup6OmBJL1TxE8SrO6lUSlKpVNvV0Ih///2XDAwMyMrKihISEuTpubm55OvrSwAoLCys2P0vXLhAenp6tGLFCgJArVq1qnBd+Ani1V9tjgUiImdnZxJC0KVLlxTSL1y4QEIIsre3V0h/8OABnThxglJTU4mIqFWrVlT4Ma0Zde0J4tVBbW7zly5dok2bNlF2drZC+oMHD0gqlRIAOnv2rMK248ePEwDq1q0bZWVlydOPHj1KQgjy9PRUOk5Vv4d16QniVa02xwMR0fnz5+natWuUl5dHp0+fJgA0duzYYvOX9xqQmJhIQgiSSqX05Inix+/SpUsJAPn5+ZW73nXuCeLbtm2Dp6cnGjRoAENDQ9jZ2aFXr17YuXOnQr5169bB19cX9vb2MDQ0RL169dC7d28cO3ZMqczIyEgIIRAcHIzo6Gj4+PjAzMwMNjY2+OCDD5CZmQkA2LdvHzp37gwTExM0bNgQM2fORF5enkJZGzZsgBACGzZsQHh4ODp06ABjY2M0atQI//vf/5CSklLmcyUirFu3Dh4eHjA3N4exsTHc3d2xbt06pbyZmZn46quv0LZtW1hYWMDExAT29vZ4++23cfXq1TIfU90OHDiAnJwc+Pv7QyqVytP19PQwf/58AMAPP/ygct+cnBz4+fnh9ddfx8SJE6ukvjUJx0LNigUASEhIgK2tLdq1a6eQ7ubmBltbWzx+/FghvWHDhvD09ISZmVkV1rL64jZfs9p8u3bt8M4778DAwEAhvWHDhggICAAApeGDP/30EwAgJCQEEolEnt6jRw/07dsXUVFRuH79uoZrXjNwPNSseAAK77S5uLhAV1e3TPnLew24c+cOiAgeHh6wsLBQ2Na/f38AULrOaEO17mysXLkSb7/9Nm7cuIFBgwZh6tSp6NOnDxITE/Hbb78p5P3www/x8OFD9OzZE1OmTEH//v1x5swZ9O7dWykQZc6ePYsePXrAwsICAQEBaNasGVatWgV/f3/88ssvGDp0KKRSKQICAmBpaYmvv/4aCxcuVFnWr7/+ipEjR6JVq1b4+OOP0bx5c/z444/w8fGRB2tJiAjvvPMOJkyYgOTkZIwePRr+/v5IT0/HhAkTMH36dIX87777LmbNmgUhBMaNG4eJEyeic+fOOHHiBC5cuFDGd1j9Hj58CABwcHBQ2iZLO336NLKzs5W2BwcHIy4uDmvXruVx6i/hWKh5sQAALi4uuH//Pi5fvqyQfvHiRdy/fx/du3fXTsVqAG7zNbPNF0dfXx9A4Q9PRZ04cQImJibw8PBQ2qd3794AlDsoAJCdnY2NGzdi4cKFWLVqlVKM1TYcD7UrHtSlRYsWMDAwwKlTp5SGaO3duxcAqsd1Rl23SEp6oYLDqF577TUyMDCghw8fKm1LSkpS+PetW7eU8iQmJpKdnR21aNFCIT0iIoIAEADatWuXPD0nJ4fatm1LQgiqX78+nTt3Tr4tNTWVGjRoQPXq1aOcnBx5+vr16+VlHT16VOE448aNIwC0YMEChXRVtw1/+uknAkDvv/8+5eXlydOzs7PprbfeIgB0/vx5IiJ68uQJCSGoffv2CnmJiPLy8iglJUXpvVAlKCioXK+ylPvjjz8SAJoxY4bStsuXL8vfq7/++kth27lz50hXV5cWL14sTwMPo5LjWKh5sUBEFBUVRWZmZmRkZESjR4+mTz75hEaNGkVGRkbk5eVFiYmJJe5fl4dRcZuvmW1elby8PHJ1dSUhBF29elWenpaWRgCoTZs2Kvfbu3evyuuJbEjWy6/evXurbC+VVR2GUXE81Px4KMswqpeV5RqwdOlSEkKQra0tBQYG0syZM6lPnz6kr69PAQEBCn+jslL3MKpq3dlwc3MjExOTSn3IffTRRwRAYf6ALLh8fHyU8i9YsIAA0Lhx45S2jR8/ngAoBLIsuHr16qWU/969e6Svr0+Ojo4K6aqCq23btmRqakqZmcpv05UrVwgATZ06lYiInj59SgDIw8Oj5JMvhaoP65Je8fHxpZZ569Yt0tXVpXr16tGdO3fk6bm5uTRo0CB5WdHR0fJtWVlZ9Morr5C7u7vChwV3Nl7gWChUk2JB5vLly+To6Kiwf9OmTWn9+vWl7luXOxvc5gvVxDb/stmzZxMAGj9+vEL6vXv3SjyXqKgo+ZfOoubPn0+RkZH0+PFjSk1NpTNnztAbb7xBAKhTp06Un59f4bqqUh06GxwPhWpyPGiqs0FEFBYWRqampgp17NKlC0VFRZW7nkTq72xU69WoRo4ciRkzZqBNmzYYOXIkvL294eHhAUtLS6W8t27dwqJFi3D8+HHcu3dPaZhOYmKiwhwCAErjqAHA1ta21G2JiYlKw4S6deumlN/Ozg6Ojo6IjY3Fs2fPih2Dl5GRgatXr8LOzg5ffvml0vbc3FwAkI9bNTc3R79+/bBv3z60b98eQ4YMQbdu3dCpUyelsbIlocIvCGrl4OCAOXPm4PPPP4erqysGDx4MCwsLHDt2DHfu3EGzZs1w584dhfGLn332GeLi4nDhwoUyj2usazgWCtWkWAAKxzmPGjUK/fv3x549e2Bvb4/bt29j4cKFGDduHK5cuYKlS5dq5Ng1Hbf5QjWtzb/sxx9/xKJFi+Dm5obly5erpcx58+Yp/LtTp07Yu3cvvLy8cPLkSRw4cAD9+vVTy7GqC46HQjU9HjRhwYIFCAkJQXBwMMaMGQMrKytcvnwZU6dOhY+PD7Zt24bBgwdrtY7VurMxffp01KtXD6tWrcKSJUvwzTffQE9PD2+++SaWLVsmb+A3btxAx44dkZqaCh8fH7z11lswNzeHjo4OIiMjceLECZVzBMzNzZXSZONJS9oma+xFNWjQQOU5NGzYELGxsUhNTS02uFJSUkBEuHfvnnwStSrp6eny/9+2bRsWLlyILVu24NNPPwUAmJmZYfz48Vi4cCGMjY2LLUfTFixYgJYtW+K7777DL7/8Al1dXXTr1g1hYWEYMWIEAMDGxgZA4dj1pUuX4rPPPoOrq6vW6lzdcSwoqgmxIBtr7OTkhE2bNkFHp3CKnLOzMzZu3Ii4uDgsX74cH3zwAVq0aKGVOlZn3OYV1YQ2/7LQ0FB88MEHePXVV3HkyBGYmpoqbJdNaH369KnK/WVj0F+e+KqKjo4Oxo0bh5MnT+LUqVO1rrPB8aCoJsaDJhw7dgxBQUGYMmUK5syZI0/38PDA3r170bx5c0yePJk7G6UZP348xo8fj+TkZPz+++8ICwvDtm3bcOPGDVy5cgW6urr49ttvkZKSgs2bN2P06NEK+wcGBuLEiRMar+ejR49UpssmTKsKVhnZtvbt2+OPP/4o0/GMjY0REhKCkJAQxMfHIyIiAj/++COWL1+OzMxMrF69utQygoODy3QsmcmTJ6v8FUWVd955B++8845CWnZ2NuLi4lCvXj35B+OVK1eQn5+P4OBglfW5fv06hBCwsLDAkydPylXf2oZjQbXqGgvR0dF4+vQpvLy85B0NGSEEfHx8cObMGVy+fJk7G8XgNq9adW3zRa1ZswYBAQFo06YNjh49inr16inlMTExga2tLeLj45Gfn690Z1v2UD8nJ6cyHdPa2hoAau2zaTgeVKsJ8aAp+/fvBwD4+PgobbOxsYGrqytOnz6NpKQkeXxoQ7XvbMjUr18fAwcOxMCBA5GUlITjx4/jxo0baNWqFW7evAkA8PX1VdinoKAAp06dqpL6/f7770ppiYmJuHnzJhwdHUtcxszMzAytW7fG33//jSdPnpS7ATs4OMDBwQEjR45EgwYNsHv37jIFV0m/Gqji5+dXqeDavn07srOzMWHCBHlay5YtFf5d1Nq1a2FhYYGhQ4fW6l8myotjoXjVKRZycnIAFL/soCy96HKfTDVu88WrTm1eRtbReOWVV3Ds2LESv+R4eXnhl19+walTp+Dp6amw7dChQ/I8ZXH+/HkAhU8Yr804HopXHeNBk2rKdaZaL3176NAhpXWcc3Nz8d9//wEADA0NAUA+9vDl5fEWL16Ma9euVUFNgSNHjiitYT137lzk5uZi7Nixpe4/adIkZGRk4L333lP5q0x8fDwSEhIAFDaec+fOKeVJSUlBdna2/H0pTXkn+JT1A1zVEzL//vtvTJs2Debm5vjkk0/k6V26dEFoaKjKFwA0atQIoaGhWLFiRZmOXVtxLLxQU2Lh9ddfh66uLrZv344rV64obPvzzz8RFhYGiUSCzp07l6mOdQ23+RdqSpsHCodOBQQEwNnZGceOHZMPmS3O+++/D6Dw/ZJ9cQIKh4ccOnQInp6eaNmypTz9r7/+UnmX+/Tp01iyZAkkEonWh4xoAsfDCzUpHjRNtmT00qVLlYYjbtiwATdu3ED79u21/uyman1n4+2334axsTG6du0KqVSK3NxcHDlyBH/99ReGDx8uD6rAwECsX78eQ4YMwdtvv4369evjzJkzuHjxonzikKb169cPb775JoYNG4amTZvixIkTOH36NF599VWlNaFVCQgIwJkzZ7Bx40ZER0ejR48esLOzw8OHDxEbG4uzZ89iy5YtsLe3x71799CpUye4uLjAzc0NjRs3RnJyMn777Tfk5uZixowZGj/fkkybNg0XL15Ehw4dUK9ePcTFxWHPnj3Q0dHBrl270LRpU63WrybiWKh5sdC4cWPMnj0bISEh6NChAwYOHAh7e3vcuXMHO3fuRHZ2Nr7++mulX339/Pzk/3///n2ltG+++Uart8OrCrf5mtfmjx8/jvfffx9EBE9PT6xatUopT7t27TBw4ED5v318fODv74/Q0FC89tpr6NevHx4+fIitW7fC3NxcqYxt27bhq6++Qo8ePWBvbw+JRII///wThw4dgo6ODn788Uc0a9ZM06da5Tgeal48AMDJkyflP57K7jKcPHlS/pnu7Oys8AMsUL5rwLBhw7B69WpERkbCyckJAwYMgJWVFWJiYnDkyBFIJBIsW7ZMMydXHupa1qqkFyq49O0PP/xAAwYMIKlUSoaGhlS/fn3q1KkTrV69mnJzcxXyRkREkIeHB5mZmZGlpSW9+eabdOHCBQoKCiIAFBERoZAXAAUFBSkdU7Z0m6plKVWVVTR/eHg4tW/fngwNDalBgwYUEBBAycnJSuWoWupNZuvWrdSzZ0+ysrIifX19aty4MXl7e9OSJUvo8ePHRESUkpJCwcHB5OnpSba2tmRgYEB2dnbUt29fOnToUKnvq6Zt27aNunbtSvXq1SN9fX1q2rQpjR8/nm7cuFGucsBL38pxLNTMWCAqjIcePXqQlZWVfFnoXr160e7du1XmhwaXIH1ZdV76ltt8zWvzRZ+zUNxL1bKf+fn5tGLFCnJxcSGJREL169enoUOH0vXr15XyRkZG0vDhw6lFixZkZmZG+vr61KRJExoxYgSdPXtWI+dVHZa+5XioefFAVHpMeHl5Ke1T3mtAVlYWLV68mNzc3MjY2Jj09PTIzs6ORo4cSVeuXKlQvevUczZqgpKCkWlXbeps1AQcCzVPde5s1ATc5uuG6tDZqAk4HmoPdXc2qvWcDcYYY4wxxljNxZ0NxhhjjDHGmEZwZ4MxxhhjjDGmEdV6NaqawM/PT2GVAMbqKo4FVtdwm2fsBY4HVhy+s8EYY4wxxhjTCO5sMMYYY4wxxjSiTnQ2vL29IYTQdjU0zt7eHkII+Ss2NlbbVVK7rl27KpxjZGSktqtULXGbr7tCQ0MV3pO6MqyB2zwrq7y8PIX3sC60GxmOk7pLm9eGOtHZqEssLCwQFBSEoKCgUp8y/NVXX8kb3ZkzZ9Ry/H///RcBAQFo1qwZDAwMYGdnh3HjxuHu3bvF7nP+/Hm8+eabsLKygomJCTp27IgtW7aozDt+/HgEBQXBy8tLLfVlNV9xbT47OxvTpk2Dp6cn7OzsYGhoiEaNGsHDwwPr169Hbm6uyvKuX78OPz8/ODk5wcjICI0bN0avXr2we/dujdS/tDgMCwvD4MGD4ejoCDMzM5iamsLFxQVTpkzBvXv3lPK7ubkhKCgIH3/8sUbqy7SvpM/5zZs3IyAgAO7u7pBIJBBCYMOGDSWWV9k2369fPwghYGhoWNFTksvNzcWOHTvg5+eH1q1bw8TEBGZmZujUqRN++OEH5OfnK+2TkZGBJUuWYNSoUXB2doaOjg6EEEhISFB5DB0dHfn7J3vyNqt9SooTIsL27dvh7e0NW1tbGBsbo1WrVggICMCtW7eUyrp8+TLmzJmDPn36wMbGBkIIeHt7q62uFblevdxhVvUq+t1Lq9cGdT2wo6QXtPxQPy8vLyo81dqtpCdxvuyvv/4iiURCJiYmBIBOnz5d6ePHxcVRgwYNCAD16tWLpk+fTr6+viSEoAYNGqh8gnhERAQZGBiQqakp+fv707Rp08jBwYEA0BdffFHssVQ9vfRldfmhftzmC58sa2hoSJ6enuTv70+zZ8+mwMBAkkqlBIB69+5N+fn5CvtER0eToaEh6enp0eDBg2nWrFk0btw4srCwKPYpu5VRljgcOHAgtWrVikaNGkXTpk2jqVOnUvfu3UkIQZaWlnT16lWVZcfHxxf7xGaZ2vRQP27zL7YDIGtra/n/l/SQtcq2+bVr15KOjg4ZGhqSRCKp2EkV8ffffxMAMjU1JV9fX5o5cyYFBASQnZ0dAaD+/ftTQUGBwj6ytg6ApFIp1atXT+WTllUpS7upTQ/14zgpNGnSJAJAtra2FBgYSDNnzqQ+ffqQEILMzMwoJiZGIb/sO4eBgQG1adOm2Kd/V1RFrldBQUEqX6NHjyYA1Lp1a5XHKsu1gZ8gXgEcXIry8vKoQ4cO1LFjR3rnnXfU1tno168fAaDly5crpG/bto0AUJ8+fRTSc3NzydHRkSQSCV28eFGenpqaSi4uLqSnp0f//POPymNxZ6Nk3OaJCgoKKDs7Wyk9NzeXvL29CQDt2bNHYVvfvn0JAO3atUshPSEhgczMzMjQ0JAyM9XzUVbWOCzueKGhoQSAhgwZonI7dzZqp9I+548cOUIJCQlERLRo0aJSOxuVafN3794lCwsLmjp1KkmlUrV0Nv7991/6/vvvKS0tTSE9LS2N3N3dCQBt3bpVYduzZ8/o8OHDlJycTEREffr04c5GMThOiBITE0kIQVKplJ48UfzIWrp0KQEgPz8/hfRr167RhQsXKCcnh+7fv6/2zkZFrlfFmThxIgGgJUuWqNyujc6G1odRRUVFQQiBCRMmqNz+77//QldXV+F21YULFzBx4kS0adMGFhYWMDIyQps2bbBw4cJih0a8LDg4uNgx/xs2bCj21vOVK1cwYsQI2NrawsDAAFKpFB999BGSk5PLdNzqYPHixYiJicG6deugq6urljKzsrJw6NAhNGzYEB999JHCtmHDhqFdu3Y4dOiQwu3JY8eO4ebNmxg1ahRee+01ebqZmRnmzZuHvLw8rF+/Xi31q064zVcNIQQMDAyU0vX09DBo0CAAULpdnpCQACEE3njjDYV0qVQKV1dXZGVlIS0tTS31K2scFjc0ZdiwYQCUz6E64jZfdXr27FmuoUGVafMTJkyAjY0NQkJCKlXnoho3bowPPvgAJiYmCukmJiaYOnUqgML2VJSpqSl69eqFevXqqa0e2sBxUjXu3LkDIoKHhwcsLCwUtvXv3x8A8PjxY4V0FxcXuLm5QV9fXyN1qsj1SpWsrCz8/PPPMDAwwLvvvqv2elaU1jsb3bp1g729PXbs2IGsrCyl7T///DMKCgoU3rQ1a9Zg586dcHV1RUBAgDwwP/30UwwfPlxjdd29ezc6duyIvXv3wsfHB5MnT4arqytWrlyJzp07IyUlRWPHVpdr165h/vz5mDt3LlxcXNRWbnJyMvLy8iCVSlVOPnNwcAAAREREyNNOnDgBAOjTp49S/t69eyvkqU24zWtXQUEBDh48CABwdXVV2Obi4gIiwoEDBxTS79y5g6tXr8LV1bXUuVBloY443LdvHwDlc6iOuM1XXxVt8z/99BOOHDmC0NBQGBkZVUldZV/09PRq5yPCOE6qRosWLWBgYIBTp04hNTVVYdvevXsBAN27d9dG1ZSUdL1SJTw8HCkpKRgwYABsbGw0Xb0y03rECiEwevRofPHFF9izZ4/81zqZn3/+GYaGhhg6dKg8bfbs2fj+++8Vfg0kIvj7+2PdunU4efIkunbtqtZ6Jicn491330XDhg0RHR2Nxo0by7eFhYVh1KhR+Oyzz7By5cpSy9qwYUOxE9dUGThwINq1a1eBWivKy8uTT7r75JNPKl1eUVZWVtDV1cXt27dBREodjvj4eADAP//8I0+Li4sDUBj4L7O0tIS1tbU8T23Cbb506mrzAJCTk4OFCxeCiJCcnIxjx44hNjYW/v7+8PHxUcgbEhKCU6dOYejQoRgwYABatmyJR48eITw8HA4ODti6dWul61PRONy2bRv++usvZGRk4M8//8ShQ4fg6OiIBQsWVLpOmsZtvnTqbPPlUZE2f/v2bUyfPh2BgYFVuljHunXrALz4Maq24TgpnTripH79+vjyyy8xbdo0ODs7w9fXF+bm5oiJicHx48cREBCgNEKjqpTneqXK2rVrAQD+/v6armr5qGs8VkkvlDJnIzY2lgDQgAEDFNIvX75MAGj48OHFjisr6sKFCwSAgoODFdJVjVEsacz/+vXrlca5ysbxbdq0SeWx3dzcqH79+koT11SR1aesr5LG2xZV2lje+fPnk56eHl24cEGeNnbsWLXN2fDx8SEAtHLlSoX0HTt2yM/l/fffl6f36tWLAFBcXJzK8po3b04GBgYqt9X0ORvc5qumzRMVjucuWrYQgmbOnEm5ubkq8yckJMjHhsteVlZW9O2331JeXl6Z6lWSisbhkCFDFOrk7u5ON2/eLDZ/dZuzwW2+6tq8TFnmbBCVr80XFBRQjx49qFmzZpSamqpQL3XM2SjO6tWrCQB179691Lw1ec4Gx0nVxUlYWBiZmpoqlN+lSxeKiooqcT9NzNmQKe/1qqhbt26REIKaNWumNJm8KG3M2dD6nQ0AaNWqFdzd3XHgwAH8999/8nGXmzZtAgClcWc5OTlYuXIlfvnlF8TGxiItLU12sQMAJCYmqr2OsiUpz5w5gxs3bihtz8rKQnJyMpKTk0sdZqGNZ0PExMQgJCQE06dPh5ubm0aO8e2336Jr166YOHEi9uzZg7Zt2+LGjRv47bff0LZtW1y5ckVtc0RqOm7zVcfU1BREhIKCAiQmJmLPnj2YM2cOTp06hf3798Pc3Fye99y5cxg4cCDatGmDCxcuwNnZGQ8fPsQPP/yAKVOmICoqCuHh4RWuS2XicPv27QCAJ0+e4NKlS/j000/h5uaG8PDwanPLvyTc5qun8rb5VatW4dixYzhw4ADMzMyqpI579+7FxIkTYW9vj82bN1fJMbWF46RqLFiwACEhIQgODsaYMWNgZWWFy5cvY+rUqfDx8cG2bdswePDgKq9Xea5XL1u3bh2ICOPGjYOOjtZnSSioFp0NoDCA/vjjD2zbtg2BgYEoKChAWFgYbGxs0LdvX4W8Q4cOxZ49e9CyZUu8/fbbaNCgAfT19fHkyRMsX74c2dnZaq/ff//9BwD4/vvvS8yXnp6uljHd6jZ27Fg4OjoiODhYY8d49dVXcf78eQQFBSEiIgIRERFo0aIFVq9ejSdPnmDGjBkKYwhlE7OePn2qsrzU1FSlyVu1Cbf5qqWjo4MmTZrgf//7H6ytrTF8+HB88cUXWLx4MYDC9f1HjBgBHR0d7Nq1C8bGxgAK5xt9/fXXuHv3LrZu3YqIiIgy3c5WRR1xaGlpCR8fHxw8eBDOzs4YM2YM4uPjNTZxUZ24zVcv5W3z9+7dw6xZs+Dn56f099KU/fv3Y+jQobC1tUVERARsbW2r5LjaxHGiWceOHUNQUBCmTJmCOXPmyNM9PDywd+9eNG/eHJMnT9ZKZ0OmtOvVywoKCrBhwwbo6Ohg/PjxVVzb0lWbzsaIESMwbdo0bN68GYGBgTh+/DgSExPx0UcfKUwGO3/+PPbs2YM+ffpg3759Cr+UnzlzBsuXLy/T8WS9vry8PKVtqr78ynqTV69eRZs2bcp1bi/TxhjFmJgYAMWvbNO5c2cAwM6dOzFw4MAKH8fZ2VnlGF/Zkyrd3d3laU5OTgAK5260b99eIX9KSgqSkpLQpUuXCteluuM2XzxNj1+Xjfku+qtabGws4uPjMXjwYPmXrqK6d++OrVu34sKFCxXubKgzDs3NzdGpUyfs2rULN27cQOvWrStUp6rEbb542pizUd42HxcXh7S0NGzYsKHYBwXK5uulpKTA0tKyUvXbv38/Bg8eDGtraxw/fhz29vaVKq+m4DgpnjriZP/+/QCg8nPcxsYGrq6uOH36NJKSkqpFZ0nV9eplBw8exL///os+ffqgWbNmVVSzsqs2nY0GDRqgd+/eOHDgAOLj4+W3Sl++ZXjz5k0AhcuTvTwk5/fffy/z8aysrABA5RN4L126pJTWqVMnhIeH4/Tp02oJrvKssmRvb1/p4CpuKb2oqCjExcXJVy7QxIf5s2fPsGfPHtSrVw+9evWSp3t5eWHRokU4fPgwRowYobDP4cOH5XlqK27zxVNHmy+JbGhB0bsBOTk5AJSXPJSRpUskkgofV91xqOo8qjNu88XTdJtXpbxt3tbWttg2vHXrVmRmZsp/WKpMnAAvOhr169dHREQEHB0dK1VeTcJxUjx1xElVfNarU1k+56vtxHAZdU3+KOmFMj7ULywsjADQnDlzyMzMjFq1aqWUJzo6mgDQsGHDFNKvXbtGVlZWKie9qJoQJSune/fuChNpoqOjSU9PT2ki0qNHj8jMzIxsbGzo2rVrSvVKT09XyyTryijPxEGZkiamyiaGlTSJqKiMjAylSUxZWVk0bNgwApQf9pebm0vNmzcniURCly5dkqcXfajf9evXVR6rpk8Ql+E2XzkltfmrV69SUlKSUnp6err8QWZFn1KflZVFFhYWpKOjQ4cOHVLY5969e2Rra0sA6MqVKwrb8HwiX2UUF4epqakKE8mLWrduHQEgJycnldur2wRxGW7zlaPOCeIVbfPF1au4CeKy9l3Wyb379+8niURCjRo1otjY2DLtU1RNniAuw3FSOSXFiey9dXFxUXqon+x7T/v27Ystu6wTxMtzbSjv9aqoR48ekb6+PllbW6t8MODL6uwEcRnZ8mNff/01cnNzVT6QpGPHjujYsSN+/fVXeHp64vXXX8edO3ewe/du9OvXTz6JsjSdO3eGh4cHjh8/js6dO8PT0xO3b9/G7t278dZbb2Hnzp0K+W1sbBAWFoZhw4bh1VdfxRtvvIFWrVohKysLt2/fxokTJ9ClSxf5esi1QUFBAYCyr2l+4cIFDB48GL169ULTpk2RmpqKffv24c6dO3jvvfeUlpLT09NDaGgo+vTpg27dumHkyJEwNzdHeHg44uPjERISgpYtW6r9vKoTbvOas337dixevBje3t5wcHCAubk57t27hwMHDiA5ORndunXDlClT5PklEgmWLFkCf39/vPHGG+jXrx9at26Nhw8fYufOnUhNTcWHH36osNY5PZ+IqamFD5KTk9G+fXu0a9cOrq6uaNy4MVJSUnD+/HlcvHgR5ubm2Lhxo0aOrSnc5jUrNDQUJ0+eBFA4zEWWJhuCMXDgQPkQvYq0+Yooz7UkNjYWgwYNQnZ2Nry9vREWFqaUx97eXn4HRWb69OlISkoC8OK8p0+fDlNTUwDAJ598Amdn58qcRpXiONGcYcOGYfXq1YiMjISTkxMGDBgAKysrxMTE4MiRI5BIJFi2bJnCPrGxsfjyyy8BAJmZmfI0WTu0trbGN998I89f3mtDea9XRf3f//0fcnNzMWbMGJUPBqwW1NVrKemFMt7ZICIaN26cfLmv4n6VePToEY0fP57s7OzI0NCQXF1d6fvvv6dbt26VuSdPRJSUlERjxoyhevXqkZGREb3++ut06NAhlUu9ycTGxtKECRNIKpWSgYEBWVlZkaurK02aNInOnTtXllPUGHXf2ZgyZQoBoCNHjpSprNu3b9OwYcOoadOmZGBgQJaWltS9e3favn17ifudPXuW+vbtSxYWFmRkZETu7u60efPmEvepLXc2iLjNV0ZJbf78+fP03nvvkYuLC1laWpKenh7Vr1+ffHx8aPXq1cUuJXj06FHq378/2djYkK6uLpmbm1PXrl1pw4YNSnljYmIIAI0ePbpS51FcHKalpdG8efPI09OTGjVqRPr6+mRiYkIuLi40ZcoUunv3brFlVtc7G0Tc5iujtM95WVsq7hUUFKS0T3nafEn1Ku7OxmuvvUZmZmb033//lVpOREREqcufqvpFWSqVlrhPcdeK6npng4jjpDJKi5OsrCxavHgxubm5kbGxMenp6ZGdnR2NHDlS5Z280trly8cq77WhotcrIqLWrVsTAPrrr7/KdCxt3Nmodp0NVnEV6WyUpH379tShQwe1ladOtamzwSpO3W2+vL777jsSQqgcSqBt1bmzwSpO222+vJ4+fUo6Ojo0Y8YMbVdFperc2WAVp+04qenXBnV3NqrXQrys0m7fvg0hBIQQiI2NrXA5aWlpuHz5ssKycNVB165dIYTA/PnztV0VVk2oq81XxO+//44BAwbAxcWlSo9bktDQUAgh4ODgoO2qMA3RZpsvr1OnTkFfXx9Tp07VdlXk8vLy5O9feSYns5qFrw2KtHltqFZzNljlTJ48GU+ePJH/uzJLtpmamqpcBk/bxo8fj549e8r/XVeWQmSqqbPNV4SqZZ61zc3NDUFBQfJ/V/UKR0yztN3my+uNN95AVlaWtquhQEdHRyFGWO2j7Tjha4Mi7mzUIpMnT9Z2FTSuOj6shmlPXWjz5eXm5lbup5OzmoPbfOXp6Oho9AG3TPs4TpRp89rAw6gYY4wxxhhjGsGdDcYYY4wxxphGcGeDMcYYY4wxphHc2SjFhg0bIITAhg0btF0VxrSO44GxQhwLjBXiWGCl4c4GK5OMjAwsWbIEo0aNgrOzM3R0dCCEQEJCgrarxliV43hgTNGWLVvQsWNHmJiYwMrKCm+++Sb++OMPbVeLsSrHsaCMOxusTB49eoTp06cjLCwMWVlZsLKy0naVGNMajgfGXli4cCFGjx6Nhw8fIjAwEMOHD8epU6fg4eGByMhIbVePsSrDsaAadzZYmVhbW+Pw4cNITk5GQkICOnTooO0qMaY1HA+MFfrnn38QFBSEli1b4sqVK1iyZAlWr16N6Oho6Onpwd/fv1o+s4kxdeNYKF6d7mxERUVh4MCBaNiwISQSCZo2bYrBgwfj5MmTpe67c+dOjBw5Ei1atICxsTEsLCzQrVs3/PrrryrzHzlyBH369IGdnR0kEgkaNmyIbt26ITQ0VCHf+fPnMWTIEDRt2hQSiQQ2Njbo0KEDFi1apJZzrihTU1P06tUL9erV02o9mOZwPJQdx0PtxrFQduvXr0deXh4+/fRTWFhYyNNdXFwwduxY3Lx5E8ePH9diDVllcCyUHcdC8ersQ/2WL1+OKVOmwMjICIMGDUKzZs1w7949nDx5Etu3b0fXrl1L3H/27NkwMDBA165dYWtri8ePH2P37t0YPnw4li1bho8//lied8+ePfD19YWlpSV8fX3l+S9fvoyff/4Z/v7+AICLFy+ia9eu0NPTg6+vL6RSKZ48eYI///wToaGhmD17tkbfE1Z3cTwwVohjoXxOnDgBAOjTp4/Stt69e2PVqlU4ceIEevfuXdVVY5XEsVA+HAvFq5OdjZiYGEydOhW2trY4deoU7O3t5duICPfv3y+1jP3796N58+YKaWlpaejSpQvmzZuH9957D8bGxgAKe7tEhIiICLz66qsK+yQnJ8v/f/PmzcjJycG2bdvg6+tbbL6SREZGlmtcYLt27TBw4MAy52e1D8fDCxwPdRvHwgtljYW4uDiYmpqiYcOGStucnJzkeVjNwrHwAsdC5dXJzsbq1atRUFCAkJAQhQACACEE7OzsSi3j5QACCodW+Pn5Ydq0aTh//jy8vLzkZQKQB1VR9evXVzh2WfKVJDIyEvPnzy9TXgAYO3Ysf7mq4zgeXuB4qNs4Fl4oayw8ffoUDRo0ULnN3NxcnofVLBwLL3AsVF6dnLNx7tw5AKjUraxHjx5h6tSpaN26NYyNjSGEgBAC06ZNAwAkJibK844cORIA8Prrr2PixInYsWMHHj16pFTm8OHDoaOjg0GDBmH8+PHYsmUL7ty5U656BQcHg4jK/OJ1sRnHA8cDK8SxwLHACnEscCyoU53sbDx9+hRCCNja2lZo///++w8dOnTAt99+i/r162PChAmYO3cugoKC5Lf1srOz5fmHDh2KXbt2oU2bNvjxxx8xdOhQNGrUCN27d8fly5fl+Tp16oTIyEh069YNW7ZswejRoyGVSuHu7o6IiIhKnTNjxeF4YKwQx0L5WVhYFPtrbWpqqjwPq1k4FsqPY6F4dXIYlaWlpXzMYePGjcu9/9q1a3Hnzh2EhITg008/Vdj25Zdf4rffflPax9fXF76+vkhNTUV0dDTCw8Oxdu1a9O3bF7GxsbC0tAQAdOvWDQcOHEBmZibOnj2LPXv24IcffkC/fv1w7do1lbcli+Ix6qy8OB5e4Hio2zgWXihrLDg5OeH06dN48OABGjVqpLBNNj5dNl6d1RwcCy9wLFRenexsdOzYEX/88QcOHz6McePGlXv/mzdvAoDS5CQA+P3330vc19zcHH379kXfvn2Rn5+PdevW4ezZs0qrFxgZGcHb2xve3t6wtLTEvHnzcOTIEQQEBJRYPo9RZ+XF8fACx0PdxrHwQlljwcvLC6dPn8bhw4cxZswYhW2HDh2S52E1C8fCCxwLlVcnh1EFBgZCV1cXc+fOxe3btxW2lWWVBalUCqBw/emitmzZgv379yvlP3bsGLKyspTSZeMRDQ0NARQGoOxWW1EPHz5UyFcSHovIyovjgeOBFeJYKH8sjBs3Dnp6evjiiy8UhpD8+eef+L//+z84Ojqie/fuZSqLVR8cCxwL6lQn72y4urpi2bJlmDRpElxcXDBw4EBIpVI8ePAAUVFR6NevH5YtW1bs/u+++y4WL16MSZMmITIyElKpFFeuXMHRo0cxePBghIeHK+SfNm0a7ty5A29vb9jb20MIgZMnT+LcuXPo3LmzfK3qJUuW4MiRI/Dx8UHz5s1haGiIixcv4tixY3B0dMTgwYM1+baUavr06UhKSgIAXL16VZ5mamoKAPjkk0/g7OystfqxiuF4qBiOh9qHY6H8WrZsieDgYMydOxdt27bF0KFDkZ6ejrCwMOTm5mLNmjXQ06uTXzVqNI6F8uNYKEF5encVfQH4KCAgIJOqmYiICOrfvz/Vq1ePDAwMqEmTJjRkyBA6deqUPM/69esJAK1fv15h38uXL1Pv3r3JysqKzMzMyMvLi44ePaoy/y+//ELDhw8nR0dHMjY2JgsLC2rXrh199dVXlJaWJs938OBBGjNmDLVq1YrMzMzI1NSUXnnlFZo7dy4lJSVp+u0olVQqJQDFviIiIrRdRQXW1tZpAOypCtr4yy8AA3v27Pm0Sk5UTTgeyqemxYMqoaGhZGVl9Qupp823d3JyelLlJ6EBHAvlt3nzZnJ3dycjIyOysLCgvn370rlz57RdLbWwtLRMB2BHaogTa2vrU/v27avyc6gojoXyqw2x4Ozs/ARAR1LTdyJBhRcJjRJCfBQQEPDVjz/+WPr9LcbUxMbGJj0pKakNESVU9bGFEAN79uy58ciRI+ZVfWzGymrt2rWYMWPG1v/++29EZcsSQrR3cnI69s8//9TN5VZYrWVlZZXx5MkTJyJKLD13yWxsbE5t3Lixy5tvvqmOqjGmEa1bt34aGxvbm4jOqaO8OjlngzHGGGOMMaZ5VdbZqIo7KIxVJ8SNnlVzz29xq62dcpNntZE627VsWAlj1Zm622hVdTYy0tLS8qvoWIwBADIzM3UBpGvp8Bnp6do6NGNlk56ejry8POWlXSomIzMzk++Ws1onKytLD+q7lmRkZGSoqSjGNCMjI0MHgNoaalVdGBJiYmK4s8GqzIMHD5CXlwcAKVqqQsI///yjX1BQoKXDM1a6K1euZKWnp/+jpuLuJSUlSbiTzWqTf//9FwDyADxTR3mZmZmx165d4+9DrNrKyMjA48ePDQDcU1eZVdXZiLp586bu3bt3q+hwrK7bsWMHGRoaHiCiPG0cn4j+ycvLSz579qw2Ds9YqfLy8rB9+3Yiop3qKI+IUo2Njf/Yt2+fOopjrFr49ddfSSKR7CYitfxylJGRsXXTpk18a4NVW/v374eRkdFlIlLbj7VV0tkgolwDA4NfJk2alPn812bGNObff//F559/nvH06dPV2qxHdnb2j1OmTOFb5qxaCgkJyQVwnYhuqavMlJSU7+fMmZMue/4IYzVZQkICFi5cmJmamrpGjcVGP3z4MG3NmjV825tVO8nJyZg9e3ZGSkrKD+ost8rG16ampk48duzYH/369cuMjIxEfj7fRWTq9ezZM2zZsgWdOnXKePr06QIiOqTN+mRnZy/+888/93p6embs378fOTk52qwOYyAiXL58GYGBgblLliy5n5qaqu71N8Pu37+/6vXXX0/fsWMHuKPNaqLU1FRs3rwZr7/+ekZqauocIjqurrKJqCAjI8Nr8uTJKbNmzcqPjY1VV9GMVVhmZibCw8PRuXPn9MTExJ8AbFJn+VXynA35wYQw1NPTm2piYjIuLy+vScOGDXMMDQ15WQZWKUSE9PR08fDhQ4mRkdHZJ0+erCCiHdquFwAIIXSFEP+zsLAIyM7OdmrUqFG2oaEhCSG0XTVWx+Tm5iIpKUk/Nzc3LT8//+fMzMzFRPRQ3ccRhY37HSsrqw8zMzPbNWzYMNvY2JjbPKv2iAhpaWni0aNHEmNj4+iUlJTlRPSbJo4lhHAwMTGZSUQjTExM9K2srPLq7NOlmdYQETIyMmTfn2Ke39H4P3WvplmlnQ2FAwthB6AhAIlWKsBqm2cA7hKRulbWUTshhA0AOwBG2q4Lq5PyACQDSKiqZZmFEFYAmgAwqYrjMaYGzwDcISK1TAgvjRBCB0BzAFYAdKvimIy9JB3Av+qco/EyrXU2GGOMMcYYY7Ubr4nOGGOMMcYY0wjubDDGGGOMMcY0gjsbjDHGGGOMMY3gzgZjjDHGGGNMI7izwRhjjDHGGNMI7mwwxhhjjDHGNII7G4wxxhhjjDGN4M4GY4wxxhhjTCO4s8EYY4wxxhjTCO5sMMYYY4wxxjSCOxuMMcYYY4wxjeDOBmOMMcYYY0wjuLPBGGOMMcYY0wjubDDGGGOMMcY0gjsbjDHGGGOMMY3gzgZjjDHGGGNMI7izwRhjjDHGGNMI7mwwxhhjjDHGNII7G4wxxhhjjDGN4M4GY4wxxhhjTCP+H04sGAjpQeyfAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1008x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(14, 7))\n",
    "plot_tree(clf, feature_names=X_train.columns, class_names=clf.classes_.astype(str), rounded=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "477d9336",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 1])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Make Predictions\n",
    "y_pred=clf.predict(X_train)\n",
    "y_pred[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "23badb6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.68644068, 0.31355932],\n",
       "       [0.68644068, 0.31355932],\n",
       "       [0.68644068, 0.31355932],\n",
       "       [0.04255319, 0.95744681],\n",
       "       [0.04255319, 0.95744681]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Estimate Probability\n",
    "y_pred_proba=clf.predict_proba(X_train)\n",
    "y_pred_proba[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510168a9",
   "metadata": {},
   "source": [
    "### Exercise 3) <br> Evaluate your in-sample results using the model score, confusion matrix, and classification report."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63982575",
   "metadata": {},
   "source": [
    "- Evaluating the model with a Model Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "400810aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree classifier on titanic training set: 0.80\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of Decision Tree classifier on titanic training set: {:.2f}'\n",
    "      .format(clf.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab25432",
   "metadata": {},
   "source": [
    "- Evaluating the model with the Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d5fcb18b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[265,  42],\n",
       "       [ 58, 133]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's make a confusion matrix\n",
    "confusion_matrix(y_train, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "110ed417",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    307\n",
       "1    191\n",
       "Name: survived, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3ffa2890",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Not Survived 0</th>\n",
       "      <th>Survived 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Not Survived 0</th>\n",
       "      <td>265</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Survived 1</th>\n",
       "      <td>58</td>\n",
       "      <td>133</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Not Survived 0  Survived 1\n",
       "Not Survived 0             265          42\n",
       "Survived 1                  58         133"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "#creating a dataframe to see the matrix/needed to rename as variables were still 0 and 1\n",
    "labels = ('Not Survived 0', 'Survived 1')\n",
    "\n",
    "pd.DataFrame(confusion_matrix(y_train, y_pred), index=labels, columns=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1db152",
   "metadata": {},
   "source": [
    "- Evaluating with a classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8e2727b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.86      0.84       307\n",
      "           1       0.76      0.70      0.73       191\n",
      "\n",
      "    accuracy                           0.80       498\n",
      "   macro avg       0.79      0.78      0.78       498\n",
      "weighted avg       0.80      0.80      0.80       498\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03208692",
   "metadata": {},
   "source": [
    "### Exercise 4) <br> Compute: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2fd089f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "TP = 265\n",
    "FP = 58\n",
    "FN = 42\n",
    "TN = 133\n",
    "ALL = TP + FP + FN + TN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "92e5d5b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#accuracy: shows in classification report above:\n",
    "0.80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ec369a77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8204334365325078"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#True Positive rate: TP/(TP+FN)\n",
    "265/(265+58)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "afe2a078",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#False positive rate: FP/(FP+TN)\n",
    "42/(42+133)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1fa109d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#True negative rate: TN/(TN+)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7533d90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#False negative rate: FN/(FN+)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "80fe1d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Precision rate: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "77e7205b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Recall rate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "37f00ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#f1-score rate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5c4a8953",
   "metadata": {},
   "outputs": [],
   "source": [
    "#support rate:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0236d05e",
   "metadata": {},
   "source": [
    "### Exercise 5) <br> Run through steps 2-4 using a different max_depth value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f61ddd81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's create a loop for this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "21dcece7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree classifier on titanic training set: 0.84\n"
     ]
    }
   ],
   "source": [
    "clf1 = DecisionTreeClassifier(max_depth=4, random_state=123)\n",
    "clf1 = clf1.fit(X_train, y_train)\n",
    "print('Accuracy of Decision Tree classifier on titanic training set: {:.2f}'\n",
    "      .format(clf1.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "68d8d617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree classifier on titanic training set: 0.90\n"
     ]
    }
   ],
   "source": [
    "clf2 = DecisionTreeClassifier(max_depth=8, random_state=123)\n",
    "clf2 = clf2.fit(X_train, y_train)\n",
    "print('Accuracy of Decision Tree classifier on titanic training set: {:.2f}'\n",
    "      .format(clf2.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac00423",
   "metadata": {},
   "source": [
    "### Exercise 6) <br> Which model performs better on your in-sample data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cbacc2e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 Score: 0.8353413654618473\n",
      "Model 2 Score: 0.8975903614457831\n"
     ]
    }
   ],
   "source": [
    "model1_train_accuracy=clf1.score(X_train, y_train)\n",
    "model2_train_accuracy=clf2.score(X_train, y_train)\n",
    "\n",
    "print(\"Model 1 Score:\", model1_train_accuracy)\n",
    "print(\"Model 2 Score:\", model2_train_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d61fef",
   "metadata": {},
   "source": [
    "### Exercise 7) Which model performs best on your out-of-sample data, the validate set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ee2421ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree classifier on titanic training set: 0.83\n"
     ]
    }
   ],
   "source": [
    "clf1 = DecisionTreeClassifier(max_depth=3, random_state=123)\n",
    "clf1 = clf1.fit(X_validate, y_validate)\n",
    "print('Accuracy of Decision Tree classifier on titanic training set: {:.2f}'\n",
    "      .format(clf1.score(X_validate, y_validate)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1562ad6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree classifier on titanic training set: 0.95\n"
     ]
    }
   ],
   "source": [
    "clf2 = DecisionTreeClassifier(max_depth=8, random_state=123)\n",
    "clf2 = clf2.fit(X_validate, y_validate)\n",
    "print('Accuracy of Decision Tree classifier on titanic training set: {:.2f}'\n",
    "      .format(clf2.score(X_validate, y_validate)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0aaeaacc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 Score: 0.8317757009345794\n",
      "Model 2 Score: 0.9532710280373832\n"
     ]
    }
   ],
   "source": [
    "model1_validate_accuracy=clf1.score(X_validate, y_validate)\n",
    "model2_validate_accuracy=clf2.score(X_validate, y_validate)\n",
    "\n",
    "print(\"Model 1 Score:\", model1_validate_accuracy)\n",
    "print(\"Model 2 Score:\", model2_validate_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c3db6c8",
   "metadata": {},
   "source": [
    "## Telco Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b1bbf1a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "customer_id                             0\n",
       "gender                                  0\n",
       "is_senior_citizen                       0\n",
       "partner                                 0\n",
       "dependents                              0\n",
       "phone_service                           0\n",
       "internet_service                        0\n",
       "contract_type                           0\n",
       "payment_type                            0\n",
       "monthly_charges                         0\n",
       "total_charges                           8\n",
       "churn                                   0\n",
       "tenure                                  0\n",
       "gender_Male                             0\n",
       "dependents_Yes                          0\n",
       "partner_Yes                             0\n",
       "contract_type_one_year                  0\n",
       "contract_type_two_years                 0\n",
       "payment_type_Credit card (automatic)    0\n",
       "payment_type_Electronic check           0\n",
       "payment_type_Mailed check               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# applying this to Telco data:\n",
    "# read fresh telco data from acquire\n",
    "telco = acquire.google_sheets()\n",
    "# open up the t,v,t and push fresh data through prepare\n",
    "train, validate, test = prepare.prepare_telco_data(telco)\n",
    "train.isna().sum()#checking for nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a8303545",
   "metadata": {},
   "outputs": [],
   "source": [
    "#total_charges has some NaT s. Let's fill them with the mean()of total_charges:\n",
    "train['total_charges'] = train.total_charges.fillna(train.total_charges.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "df658e64",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>gender</th>\n",
       "      <th>is_senior_citizen</th>\n",
       "      <th>partner</th>\n",
       "      <th>dependents</th>\n",
       "      <th>phone_service</th>\n",
       "      <th>internet_service</th>\n",
       "      <th>contract_type</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>monthly_charges</th>\n",
       "      <th>...</th>\n",
       "      <th>churn</th>\n",
       "      <th>tenure</th>\n",
       "      <th>gender_Male</th>\n",
       "      <th>dependents_Yes</th>\n",
       "      <th>partner_Yes</th>\n",
       "      <th>contract_type_one_year</th>\n",
       "      <th>contract_type_two_years</th>\n",
       "      <th>payment_type_Credit card (automatic)</th>\n",
       "      <th>payment_type_Electronic check</th>\n",
       "      <th>payment_type_Mailed check</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5310</th>\n",
       "      <td>7503-MIOGA</td>\n",
       "      <td>Female</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>two_years</td>\n",
       "      <td>Bank transfer (automatic)</td>\n",
       "      <td>89.85</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>74.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3790</th>\n",
       "      <td>5329-KRDTM</td>\n",
       "      <td>Male</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>two_years</td>\n",
       "      <td>Credit card (automatic)</td>\n",
       "      <td>77.35</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>69.8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4398</th>\n",
       "      <td>6199-IWKGC</td>\n",
       "      <td>Female</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>one_year</td>\n",
       "      <td>Electronic check</td>\n",
       "      <td>100.25</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>47.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2635</th>\n",
       "      <td>3748-FVMZZ</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>month_to_month</td>\n",
       "      <td>Electronic check</td>\n",
       "      <td>40.05</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2986</th>\n",
       "      <td>4280-DLSHD</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>month_to_month</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>54.75</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>8.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     customer_id  gender  is_senior_citizen partner dependents  phone_service  \\\n",
       "5310  7503-MIOGA  Female                  1     Yes         No              2   \n",
       "3790  5329-KRDTM    Male                  1     Yes         No              2   \n",
       "4398  6199-IWKGC  Female                  1     Yes         No              2   \n",
       "2635  3748-FVMZZ    Male                  0      No         No              0   \n",
       "2986  4280-DLSHD    Male                  0     Yes         No              1   \n",
       "\n",
       "      internet_service   contract_type               payment_type  \\\n",
       "5310                 1       two_years  Bank transfer (automatic)   \n",
       "3790                 1       two_years    Credit card (automatic)   \n",
       "4398                 2        one_year           Electronic check   \n",
       "2635                 1  month_to_month           Electronic check   \n",
       "2986                 1  month_to_month               Mailed check   \n",
       "\n",
       "      monthly_charges  ...  churn tenure  gender_Male  dependents_Yes  \\\n",
       "5310            89.85  ...     No   74.5            0               0   \n",
       "3790            77.35  ...     No   69.8            1               0   \n",
       "4398           100.25  ...     No   47.4            0               0   \n",
       "2635            40.05  ...     No    4.1            1               0   \n",
       "2986            54.75  ...     No    8.1            1               0   \n",
       "\n",
       "      partner_Yes  contract_type_one_year  contract_type_two_years  \\\n",
       "5310            1                       0                        1   \n",
       "3790            1                       0                        1   \n",
       "4398            1                       1                        0   \n",
       "2635            0                       0                        0   \n",
       "2986            1                       0                        0   \n",
       "\n",
       "      payment_type_Credit card (automatic)  payment_type_Electronic check  \\\n",
       "5310                                     0                              0   \n",
       "3790                                     1                              0   \n",
       "4398                                     0                              1   \n",
       "2635                                     0                              1   \n",
       "2986                                     0                              0   \n",
       "\n",
       "      payment_type_Mailed check  \n",
       "5310                          0  \n",
       "3790                          0  \n",
       "4398                          0  \n",
       "2635                          0  \n",
       "2986                          1  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e0a0eade",
   "metadata": {},
   "outputs": [],
   "source": [
    "#changing any yes/no to whole of dataframe\n",
    "train = train.replace({'Yes':1, 'No':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cff29680",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hadn't added encoding yet to prepare file. \n",
    "train = train.drop(columns=['customer_id',])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7ae94b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's encode gender, partner, dependents, contract_type, payment_type, churn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2df43da2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>is_senior_citizen</th>\n",
       "      <th>partner</th>\n",
       "      <th>dependents</th>\n",
       "      <th>phone_service</th>\n",
       "      <th>internet_service</th>\n",
       "      <th>contract_type</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>monthly_charges</th>\n",
       "      <th>total_charges</th>\n",
       "      <th>churn</th>\n",
       "      <th>tenure</th>\n",
       "      <th>gender_Male</th>\n",
       "      <th>dependents_Yes</th>\n",
       "      <th>partner_Yes</th>\n",
       "      <th>contract_type_one_year</th>\n",
       "      <th>contract_type_two_years</th>\n",
       "      <th>payment_type_Credit card (automatic)</th>\n",
       "      <th>payment_type_Electronic check</th>\n",
       "      <th>payment_type_Mailed check</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5310</th>\n",
       "      <td>Female</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>two_years</td>\n",
       "      <td>Bank transfer (automatic)</td>\n",
       "      <td>89.85</td>\n",
       "      <td>6697.35</td>\n",
       "      <td>0</td>\n",
       "      <td>74.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3790</th>\n",
       "      <td>Male</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>two_years</td>\n",
       "      <td>Credit card (automatic)</td>\n",
       "      <td>77.35</td>\n",
       "      <td>5396.25</td>\n",
       "      <td>0</td>\n",
       "      <td>69.8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4398</th>\n",
       "      <td>Female</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>one_year</td>\n",
       "      <td>Electronic check</td>\n",
       "      <td>100.25</td>\n",
       "      <td>4753.85</td>\n",
       "      <td>0</td>\n",
       "      <td>47.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2635</th>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>month_to_month</td>\n",
       "      <td>Electronic check</td>\n",
       "      <td>40.05</td>\n",
       "      <td>162.45</td>\n",
       "      <td>0</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2986</th>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>month_to_month</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>54.75</td>\n",
       "      <td>445.85</td>\n",
       "      <td>0</td>\n",
       "      <td>8.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      gender  is_senior_citizen  partner  dependents  phone_service  \\\n",
       "5310  Female                  1        1           0              2   \n",
       "3790    Male                  1        1           0              2   \n",
       "4398  Female                  1        1           0              2   \n",
       "2635    Male                  0        0           0              0   \n",
       "2986    Male                  0        1           0              1   \n",
       "\n",
       "      internet_service   contract_type               payment_type  \\\n",
       "5310                 1       two_years  Bank transfer (automatic)   \n",
       "3790                 1       two_years    Credit card (automatic)   \n",
       "4398                 2        one_year           Electronic check   \n",
       "2635                 1  month_to_month           Electronic check   \n",
       "2986                 1  month_to_month               Mailed check   \n",
       "\n",
       "      monthly_charges  total_charges  churn  tenure  gender_Male  \\\n",
       "5310            89.85        6697.35      0    74.5            0   \n",
       "3790            77.35        5396.25      0    69.8            1   \n",
       "4398           100.25        4753.85      0    47.4            0   \n",
       "2635            40.05         162.45      0     4.1            1   \n",
       "2986            54.75         445.85      0     8.1            1   \n",
       "\n",
       "      dependents_Yes  partner_Yes  contract_type_one_year  \\\n",
       "5310               0            1                       0   \n",
       "3790               0            1                       0   \n",
       "4398               0            1                       1   \n",
       "2635               0            0                       0   \n",
       "2986               0            1                       0   \n",
       "\n",
       "      contract_type_two_years  payment_type_Credit card (automatic)  \\\n",
       "5310                        1                                     0   \n",
       "3790                        1                                     1   \n",
       "4398                        0                                     0   \n",
       "2635                        0                                     0   \n",
       "2986                        0                                     0   \n",
       "\n",
       "      payment_type_Electronic check  payment_type_Mailed check  \n",
       "5310                              0                          0  \n",
       "3790                              0                          0  \n",
       "4398                              1                          0  \n",
       "2635                              1                          0  \n",
       "2986                              0                          1  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d5e2af",
   "metadata": {},
   "source": [
    "# Random Forest Exercises\n",
    "\n",
    "### Exercise 1)\n",
    "Fit the Random Forest classifier to your training sample and transform (i.e. make predictions on the training sample) setting the random_state accordingly and setting min_samples_leaf = 1 and max_depth = 10."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9689d27",
   "metadata": {},
   "source": [
    "- Setting up data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ad01af4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "40b9f69c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alone</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>alone</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>embark_town_Queenstown</th>\n",
       "      <th>embark_town_Southampton</th>\n",
       "      <th>embark_town_Southhampton</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40.1250</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>20.5250</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>39.6875</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>female</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>110.8833</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     survived  pclass     sex        age  sibsp  parch      fare  embark_town  \\\n",
       "583         0       1    male  36.000000      0      0   40.1250    Cherbourg   \n",
       "165         1       3    male   9.000000      0      2   20.5250  Southampton   \n",
       "50          0       3    male   7.000000      4      1   39.6875  Southampton   \n",
       "259         1       2  female  50.000000      0      1   26.0000  Southampton   \n",
       "306         1       1  female  29.699118      0      0  110.8833    Cherbourg   \n",
       "\n",
       "     alone  pclass  sibsp  parch  alone  sex_male  embark_town_Queenstown  \\\n",
       "583      1       1      0      0      1         1                       0   \n",
       "165      0       3      0      2      0         1                       0   \n",
       "50       0       3      4      1      0         1                       0   \n",
       "259      0       2      0      1      0         0                       0   \n",
       "306      1       1      0      0      1         0                       0   \n",
       "\n",
       "     embark_town_Southampton  embark_town_Southhampton  \n",
       "583                        0                         0  \n",
       "165                        1                         0  \n",
       "50                         1                         0  \n",
       "259                        1                         0  \n",
       "306                        0                         0  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read titanic data from pydatset\n",
    "titanic = acquire.new_titanic_data()\n",
    "#split the data into train, validate, test\n",
    "train, validate, test =prepare.prepare_titanic_data(titanic)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c2322c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping categorical\n",
    "train = train.drop(columns=['sex', 'embark_town'])\n",
    "validate = validate.drop(columns=['sex', 'embark_town'])\n",
    "test = test.drop(columns=['sex', 'embark_town'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2939f08f",
   "metadata": {},
   "source": [
    "- Separating data to get apply Random Forest using 'survived' as target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2f780770",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((498, 14), (214, 14), (179, 14))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create X & y version of train, where y is a series with just the target variable and X are all the features. \n",
    "X_train = train.drop(columns=['survived'])\n",
    "y_train = train.survived\n",
    "\n",
    "X_validate = validate.drop(columns=['survived'])\n",
    "y_validate = validate.survived\n",
    "\n",
    "X_test = test.drop(columns=['survived'])\n",
    "y_test = test.survived\n",
    "\n",
    "X_train.shape, X_validate.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f47134d2",
   "metadata": {},
   "source": [
    "- Creating a Bootstrap version of data with random samples to add in data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1792753f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=10, random_state=123)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create the model and set max depth 10 with random_state general\n",
    "rf = RandomForestClassifier(bootstrap=True, \n",
    "                            class_weight=None, \n",
    "                            criterion='gini',\n",
    "                            min_samples_leaf=1,\n",
    "                            n_estimators=100,\n",
    "                            max_depth=10, \n",
    "                            random_state=123)\n",
    "rf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ffd8a33",
   "metadata": {},
   "source": [
    "- Fitting the RF bootstrap into the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3c382f63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=10, random_state=123)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fit the random forest algorithm into training data\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "298acfd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest classifier on titanic training set: 0.97\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(max_depth=10, random_state=123)\n",
    "clf = clf.fit(X_train, y_train)\n",
    "print('Accuracy of Random Forest classifier on titanic training set: {:.2f}'\n",
    "      .format(clf.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bcf1e687",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.04910359 0.20879458 0.03014638 0.01982673 0.23785936 0.01097164\n",
      " 0.05353124 0.03200334 0.02154846 0.01445995 0.28157762 0.01474419\n",
      " 0.02480507 0.00062783]\n"
     ]
    }
   ],
   "source": [
    "#finding importance of features (higher number -> the more important/has weight to the data)\n",
    "print(rf.feature_importances_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31302ac1",
   "metadata": {},
   "source": [
    "- Checking out the statistical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "eb27c8ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features:\n",
      "pclass:0.04910359\n",
      "age:0.20879458\n",
      "sibsp:0.03014638\n",
      "parch:0.01982673\n",
      "fare:0.23785936\n",
      "alone:0.01097164\n",
      "sex:0.28157762\n"
     ]
    }
   ],
   "source": [
    "print('Features:')\n",
    "print('pclass:0.04910359')\n",
    "print('age:0.20879458')\n",
    "print('sibsp:0.03014638')\n",
    "print('parch:0.01982673')\n",
    "print('fare:0.23785936')\n",
    "print('alone:0.01097164')\n",
    "print('sex:0.28157762')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c83ba83",
   "metadata": {},
   "source": [
    "#### TAKE-AWAYS:\n",
    "Age, Fare, and Sex hold the most weight when it comes to training the model to predict our baseline (who would not survive)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "047d6b35",
   "metadata": {},
   "source": [
    "- Making predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "67235e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicting classifier for each survived/not survived probability\n",
    "y_pred = rf.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "deb48ce9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.77147863, 0.22852137],\n",
       "       [0.24844444, 0.75155556],\n",
       "       [0.955     , 0.045     ],\n",
       "       [0.07509615, 0.92490385],\n",
       "       [0.02421053, 0.97578947],\n",
       "       [0.83387922, 0.16612078],\n",
       "       [0.83519934, 0.16480066],\n",
       "       [0.9358506 , 0.0641494 ],\n",
       "       [0.94987425, 0.05012575],\n",
       "       [1.        , 0.        ],\n",
       "       [0.74583263, 0.25416737],\n",
       "       [0.92039078, 0.07960922],\n",
       "       [0.04842949, 0.95157051],\n",
       "       [0.6597301 , 0.3402699 ],\n",
       "       [0.87476171, 0.12523829],\n",
       "       [0.62432049, 0.37567951],\n",
       "       [0.95483317, 0.04516683],\n",
       "       [0.05185027, 0.94814973],\n",
       "       [0.6555221 , 0.3444779 ],\n",
       "       [0.84153297, 0.15846703],\n",
       "       [0.16420238, 0.83579762],\n",
       "       [0.96362825, 0.03637175],\n",
       "       [0.03142857, 0.96857143],\n",
       "       [0.03704451, 0.96295549],\n",
       "       [0.55270856, 0.44729144],\n",
       "       [0.97499244, 0.02500756],\n",
       "       [0.04625   , 0.95375   ],\n",
       "       [0.76871053, 0.23128947],\n",
       "       [0.73525161, 0.26474839],\n",
       "       [0.93376286, 0.06623714],\n",
       "       [0.9599409 , 0.0400591 ],\n",
       "       [0.97694866, 0.02305134],\n",
       "       [0.97597836, 0.02402164],\n",
       "       [0.14149154, 0.85850846],\n",
       "       [0.04636612, 0.95363388],\n",
       "       [0.48446254, 0.51553746],\n",
       "       [0.82931216, 0.17068784],\n",
       "       [0.01      , 0.99      ],\n",
       "       [0.93556656, 0.06443344],\n",
       "       [0.1260119 , 0.8739881 ],\n",
       "       [0.90357794, 0.09642206],\n",
       "       [0.96155843, 0.03844157],\n",
       "       [0.74145833, 0.25854167],\n",
       "       [0.09309524, 0.90690476],\n",
       "       [0.58201238, 0.41798762],\n",
       "       [0.97547959, 0.02452041],\n",
       "       [0.94987425, 0.05012575],\n",
       "       [0.96663081, 0.03336919],\n",
       "       [0.03482249, 0.96517751],\n",
       "       [0.87471444, 0.12528556],\n",
       "       [0.93722356, 0.06277644],\n",
       "       [0.9400073 , 0.0599927 ],\n",
       "       [0.02142857, 0.97857143],\n",
       "       [0.02366667, 0.97633333],\n",
       "       [0.8177043 , 0.1822957 ],\n",
       "       [0.14452381, 0.85547619],\n",
       "       [0.95419308, 0.04580692],\n",
       "       [0.03979522, 0.96020478],\n",
       "       [0.30698333, 0.69301667],\n",
       "       [0.93367573, 0.06632427],\n",
       "       [0.83425   , 0.16575   ],\n",
       "       [0.98421323, 0.01578677],\n",
       "       [0.97689447, 0.02310553],\n",
       "       [0.80781216, 0.19218784],\n",
       "       [0.87224765, 0.12775235],\n",
       "       [0.94987425, 0.05012575],\n",
       "       [0.47370113, 0.52629887],\n",
       "       [0.92837115, 0.07162885],\n",
       "       [0.3175    , 0.6825    ],\n",
       "       [0.03979853, 0.96020147],\n",
       "       [0.94      , 0.06      ],\n",
       "       [0.96416249, 0.03583751],\n",
       "       [0.0364881 , 0.9635119 ],\n",
       "       [0.29228734, 0.70771266],\n",
       "       [0.94987425, 0.05012575],\n",
       "       [0.87543414, 0.12456586],\n",
       "       [0.96279888, 0.03720112],\n",
       "       [0.93454064, 0.06545936],\n",
       "       [0.96867983, 0.03132017],\n",
       "       [0.32833333, 0.67166667],\n",
       "       [0.87947508, 0.12052492],\n",
       "       [0.01421053, 0.98578947],\n",
       "       [0.94599702, 0.05400298],\n",
       "       [0.88419076, 0.11580924],\n",
       "       [0.91067983, 0.08932017],\n",
       "       [0.89285714, 0.10714286],\n",
       "       [0.01037719, 0.98962281],\n",
       "       [0.14666667, 0.85333333],\n",
       "       [0.1339697 , 0.8660303 ],\n",
       "       [0.93454064, 0.06545936],\n",
       "       [0.92823838, 0.07176162],\n",
       "       [0.94987425, 0.05012575],\n",
       "       [0.1942152 , 0.8057848 ],\n",
       "       [0.04142857, 0.95857143],\n",
       "       [0.74044121, 0.25955879],\n",
       "       [0.96325788, 0.03674212],\n",
       "       [0.00671053, 0.99328947],\n",
       "       [0.86031525, 0.13968475],\n",
       "       [0.86667379, 0.13332621],\n",
       "       [0.02      , 0.98      ],\n",
       "       [0.94237414, 0.05762586],\n",
       "       [0.81549603, 0.18450397],\n",
       "       [0.03125   , 0.96875   ],\n",
       "       [0.94723398, 0.05276602],\n",
       "       [0.61142857, 0.38857143],\n",
       "       [0.00704451, 0.99295549],\n",
       "       [0.86819444, 0.13180556],\n",
       "       [0.034     , 0.966     ],\n",
       "       [0.96435163, 0.03564837],\n",
       "       [0.98178086, 0.01821914],\n",
       "       [0.13668523, 0.86331477],\n",
       "       [0.18579238, 0.81420762],\n",
       "       [0.86879456, 0.13120544],\n",
       "       [0.9666957 , 0.0333043 ],\n",
       "       [0.64326667, 0.35673333],\n",
       "       [0.02934524, 0.97065476],\n",
       "       [1.        , 0.        ],\n",
       "       [0.94952898, 0.05047102],\n",
       "       [0.04083333, 0.95916667],\n",
       "       [0.04333333, 0.95666667],\n",
       "       [0.83958097, 0.16041903],\n",
       "       [0.97586696, 0.02413304],\n",
       "       [0.79111123, 0.20888877],\n",
       "       [0.77146359, 0.22853641],\n",
       "       [0.14608333, 0.85391667],\n",
       "       [0.12317857, 0.87682143],\n",
       "       [0.03333333, 0.96666667],\n",
       "       [0.73451082, 0.26548918],\n",
       "       [0.45241667, 0.54758333],\n",
       "       [0.89      , 0.11      ],\n",
       "       [0.05185027, 0.94814973],\n",
       "       [0.95681089, 0.04318911],\n",
       "       [0.98      , 0.02      ],\n",
       "       [0.13002289, 0.86997711],\n",
       "       [0.92534586, 0.07465414],\n",
       "       [0.9605369 , 0.0394631 ],\n",
       "       [0.8963601 , 0.1036399 ],\n",
       "       [0.95483317, 0.04516683],\n",
       "       [0.81758333, 0.18241667],\n",
       "       [0.72545239, 0.27454761],\n",
       "       [0.02559524, 0.97440476],\n",
       "       [0.90388889, 0.09611111],\n",
       "       [0.8385761 , 0.1614239 ],\n",
       "       [0.97415983, 0.02584017],\n",
       "       [0.13904762, 0.86095238],\n",
       "       [0.20303946, 0.79696054],\n",
       "       [0.00478261, 0.99521739],\n",
       "       [0.06761905, 0.93238095],\n",
       "       [0.06      , 0.94      ],\n",
       "       [0.04      , 0.96      ],\n",
       "       [0.98421323, 0.01578677],\n",
       "       [0.03386905, 0.96613095],\n",
       "       [0.22871053, 0.77128947],\n",
       "       [0.9700646 , 0.0299354 ],\n",
       "       [0.70262376, 0.29737624],\n",
       "       [0.16697219, 0.83302781],\n",
       "       [0.97317065, 0.02682935],\n",
       "       [0.97115091, 0.02884909],\n",
       "       [0.17475758, 0.82524242],\n",
       "       [0.8958213 , 0.1041787 ],\n",
       "       [0.87198744, 0.12801256],\n",
       "       [0.05158835, 0.94841165],\n",
       "       [0.91330093, 0.08669907],\n",
       "       [0.13738095, 0.86261905],\n",
       "       [0.9674249 , 0.0325751 ],\n",
       "       [0.98705351, 0.01294649],\n",
       "       [0.89      , 0.11      ],\n",
       "       [0.93952898, 0.06047102],\n",
       "       [0.90367519, 0.09632481],\n",
       "       [0.93138175, 0.06861825],\n",
       "       [0.94650442, 0.05349558],\n",
       "       [0.01671053, 0.98328947],\n",
       "       [0.17475758, 0.82524242],\n",
       "       [0.91078314, 0.08921686],\n",
       "       [0.76799474, 0.23200526],\n",
       "       [0.93716325, 0.06283675],\n",
       "       [0.01      , 0.99      ],\n",
       "       [0.88291787, 0.11708213],\n",
       "       [0.967     , 0.033     ],\n",
       "       [0.39361188, 0.60638812],\n",
       "       [0.91833211, 0.08166789],\n",
       "       [0.96416249, 0.03583751],\n",
       "       [0.97189726, 0.02810274],\n",
       "       [0.01478261, 0.98521739],\n",
       "       [0.98178086, 0.01821914],\n",
       "       [0.0224336 , 0.9775664 ],\n",
       "       [0.94696187, 0.05303813],\n",
       "       [0.04333333, 0.95666667],\n",
       "       [0.77494118, 0.22505882],\n",
       "       [0.47271414, 0.52728586],\n",
       "       [0.94707437, 0.05292563],\n",
       "       [0.02621118, 0.97378882],\n",
       "       [0.92317209, 0.07682791],\n",
       "       [0.93516564, 0.06483436],\n",
       "       [0.01142857, 0.98857143],\n",
       "       [0.26810784, 0.73189216],\n",
       "       [0.88287879, 0.11712121],\n",
       "       [0.45007678, 0.54992322],\n",
       "       [0.9086418 , 0.0913582 ],\n",
       "       [0.92401735, 0.07598265],\n",
       "       [1.        , 0.        ],\n",
       "       [0.08      , 0.92      ],\n",
       "       [0.06671053, 0.93328947],\n",
       "       [0.92131532, 0.07868468],\n",
       "       [0.89705159, 0.10294841],\n",
       "       [0.94896862, 0.05103138],\n",
       "       [0.89438795, 0.10561205],\n",
       "       [0.92859633, 0.07140367],\n",
       "       [0.95483317, 0.04516683],\n",
       "       [0.18866667, 0.81133333],\n",
       "       [0.75932342, 0.24067658],\n",
       "       [0.96416249, 0.03583751],\n",
       "       [0.83778173, 0.16221827],\n",
       "       [0.38058874, 0.61941126],\n",
       "       [0.00142857, 0.99857143],\n",
       "       [0.12668523, 0.87331477],\n",
       "       [0.97067983, 0.02932017],\n",
       "       [0.98273126, 0.01726874],\n",
       "       [0.16010806, 0.83989194],\n",
       "       [0.96454366, 0.03545634],\n",
       "       [0.76404692, 0.23595308],\n",
       "       [0.95483317, 0.04516683],\n",
       "       [0.87959249, 0.12040751],\n",
       "       [0.01142857, 0.98857143],\n",
       "       [0.97441704, 0.02558296],\n",
       "       [0.91517532, 0.08482468],\n",
       "       [0.75213194, 0.24786806],\n",
       "       [0.57563431, 0.42436569],\n",
       "       [0.96442175, 0.03557825],\n",
       "       [0.17384206, 0.82615794],\n",
       "       [0.84671138, 0.15328862],\n",
       "       [0.90723035, 0.09276965],\n",
       "       [0.98178086, 0.01821914],\n",
       "       [0.93655323, 0.06344677],\n",
       "       [0.92401735, 0.07598265],\n",
       "       [0.05985806, 0.94014194],\n",
       "       [0.15845238, 0.84154762],\n",
       "       [0.97689447, 0.02310553],\n",
       "       [0.9756352 , 0.0243648 ],\n",
       "       [0.988125  , 0.011875  ],\n",
       "       [0.92317209, 0.07682791],\n",
       "       [0.90418293, 0.09581707],\n",
       "       [0.1104881 , 0.8895119 ],\n",
       "       [0.58240395, 0.41759605],\n",
       "       [0.035     , 0.965     ],\n",
       "       [0.97334315, 0.02665685],\n",
       "       [0.01      , 0.99      ],\n",
       "       [0.94378448, 0.05621552],\n",
       "       [0.75608143, 0.24391857],\n",
       "       [0.08708333, 0.91291667],\n",
       "       [0.82475565, 0.17524435],\n",
       "       [0.84822508, 0.15177492],\n",
       "       [0.97091135, 0.02908865],\n",
       "       [0.23774609, 0.76225391],\n",
       "       [0.91808081, 0.08191919],\n",
       "       [0.26397549, 0.73602451],\n",
       "       [0.60485784, 0.39514216],\n",
       "       [0.02      , 0.98      ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.27703501, 0.72296499],\n",
       "       [0.75862865, 0.24137135],\n",
       "       [0.91257692, 0.08742308],\n",
       "       [0.03482249, 0.96517751],\n",
       "       [0.08      , 0.92      ],\n",
       "       [0.93138175, 0.06861825],\n",
       "       [0.89009128, 0.10990872],\n",
       "       [0.85563025, 0.14436975],\n",
       "       [0.34841011, 0.65158989],\n",
       "       [0.96435163, 0.03564837],\n",
       "       [0.81434454, 0.18565546],\n",
       "       [0.93211111, 0.06788889],\n",
       "       [0.76504654, 0.23495346],\n",
       "       [0.96422632, 0.03577368],\n",
       "       [0.01      , 0.99      ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.95547959, 0.04452041],\n",
       "       [0.94387023, 0.05612977],\n",
       "       [0.95483317, 0.04516683],\n",
       "       [0.95483317, 0.04516683],\n",
       "       [0.96413836, 0.03586164],\n",
       "       [0.96413836, 0.03586164],\n",
       "       [0.01366667, 0.98633333],\n",
       "       [0.6509134 , 0.3490866 ],\n",
       "       [0.03482249, 0.96517751],\n",
       "       [0.90557348, 0.09442652],\n",
       "       [0.87793414, 0.12206586],\n",
       "       [0.05715476, 0.94284524],\n",
       "       [0.40340956, 0.59659044],\n",
       "       [0.82      , 0.18      ],\n",
       "       [0.90336289, 0.09663711],\n",
       "       [0.94721414, 0.05278586],\n",
       "       [0.93862522, 0.06137478],\n",
       "       [0.95483317, 0.04516683],\n",
       "       [0.96422632, 0.03577368],\n",
       "       [0.86291452, 0.13708548],\n",
       "       [0.42044095, 0.57955905],\n",
       "       [0.77196254, 0.22803746],\n",
       "       [0.96550805, 0.03449195],\n",
       "       [0.97      , 0.03      ],\n",
       "       [0.93415778, 0.06584222],\n",
       "       [0.6738031 , 0.3261969 ],\n",
       "       [0.90357794, 0.09642206],\n",
       "       [0.96280963, 0.03719037],\n",
       "       [0.03482249, 0.96517751],\n",
       "       [0.97091135, 0.02908865],\n",
       "       [0.87039078, 0.12960922],\n",
       "       [0.04142857, 0.95857143],\n",
       "       [0.96416249, 0.03583751],\n",
       "       [0.85136345, 0.14863655],\n",
       "       [0.80607143, 0.19392857],\n",
       "       [0.93516564, 0.06483436],\n",
       "       [0.96211111, 0.03788889],\n",
       "       [0.99014009, 0.00985991],\n",
       "       [0.0599336 , 0.9400664 ],\n",
       "       [0.92      , 0.08      ],\n",
       "       [0.83979259, 0.16020741],\n",
       "       [0.96416249, 0.03583751],\n",
       "       [0.00954451, 0.99045549],\n",
       "       [0.41281996, 0.58718004],\n",
       "       [0.98695948, 0.01304052],\n",
       "       [0.92619573, 0.07380427],\n",
       "       [0.88155053, 0.11844947],\n",
       "       [0.00621118, 0.99378882],\n",
       "       [0.74967904, 0.25032096],\n",
       "       [0.86967159, 0.13032841],\n",
       "       [0.21932056, 0.78067944],\n",
       "       [0.39729844, 0.60270156],\n",
       "       [0.60998698, 0.39001302],\n",
       "       [0.2014225 , 0.7985775 ],\n",
       "       [0.0241542 , 0.9758458 ],\n",
       "       [0.95489046, 0.04510954],\n",
       "       [0.054     , 0.946     ],\n",
       "       [0.03482249, 0.96517751],\n",
       "       [0.27563488, 0.72436512],\n",
       "       [0.17634622, 0.82365378],\n",
       "       [0.05185027, 0.94814973],\n",
       "       [0.89333333, 0.10666667],\n",
       "       [0.29807143, 0.70192857],\n",
       "       [0.9400073 , 0.0599927 ],\n",
       "       [0.46249462, 0.53750538],\n",
       "       [0.87413982, 0.12586018],\n",
       "       [0.17845648, 0.82154352],\n",
       "       [0.28052451, 0.71947549],\n",
       "       [0.26417915, 0.73582085],\n",
       "       [0.84810103, 0.15189897],\n",
       "       [0.303536  , 0.696464  ],\n",
       "       [0.87793414, 0.12206586],\n",
       "       [0.7817011 , 0.2182989 ],\n",
       "       [0.72159948, 0.27840052],\n",
       "       [0.92039078, 0.07960922],\n",
       "       [0.01      , 0.99      ],\n",
       "       [0.8565632 , 0.1434368 ],\n",
       "       [0.43836937, 0.56163063],\n",
       "       [0.10875   , 0.89125   ],\n",
       "       [0.0322619 , 0.9677381 ],\n",
       "       [0.00142857, 0.99857143],\n",
       "       [0.01      , 0.99      ],\n",
       "       [0.96      , 0.04      ],\n",
       "       [0.83979259, 0.16020741],\n",
       "       [0.16204762, 0.83795238],\n",
       "       [0.89251627, 0.10748373],\n",
       "       [0.33686239, 0.66313761],\n",
       "       [0.064884  , 0.935116  ],\n",
       "       [0.83833333, 0.16166667],\n",
       "       [0.98717656, 0.01282344],\n",
       "       [0.67007932, 0.32992068],\n",
       "       [0.6555221 , 0.3444779 ],\n",
       "       [0.91100192, 0.08899808],\n",
       "       [0.93      , 0.07      ],\n",
       "       [0.74913139, 0.25086861],\n",
       "       [0.93516564, 0.06483436],\n",
       "       [0.90857763, 0.09142237],\n",
       "       [0.18005605, 0.81994395],\n",
       "       [0.86705913, 0.13294087],\n",
       "       [0.276589  , 0.723411  ],\n",
       "       [0.74320264, 0.25679736],\n",
       "       [0.04      , 0.96      ],\n",
       "       [0.6035119 , 0.3964881 ],\n",
       "       [0.01671053, 0.98328947],\n",
       "       [0.29872549, 0.70127451],\n",
       "       [0.094     , 0.906     ],\n",
       "       [0.0257619 , 0.9742381 ],\n",
       "       [0.03979853, 0.96020147],\n",
       "       [0.86414875, 0.13585125],\n",
       "       [0.82256528, 0.17743472],\n",
       "       [0.03560027, 0.96439973],\n",
       "       [0.83778173, 0.16221827],\n",
       "       [0.30176779, 0.69823221],\n",
       "       [0.76166667, 0.23833333],\n",
       "       [0.9393823 , 0.0606177 ],\n",
       "       [0.90100178, 0.09899822],\n",
       "       [0.66812431, 0.33187569],\n",
       "       [0.79469757, 0.20530243],\n",
       "       [0.51025501, 0.48974499],\n",
       "       [0.27282411, 0.72717589],\n",
       "       [0.81448965, 0.18551035],\n",
       "       [0.04      , 0.96      ],\n",
       "       [0.97454366, 0.02545634],\n",
       "       [0.88490968, 0.11509032],\n",
       "       [0.67825595, 0.32174405],\n",
       "       [0.94724481, 0.05275519],\n",
       "       [0.09053571, 0.90946429],\n",
       "       [0.94413869, 0.05586131],\n",
       "       [0.85627413, 0.14372587],\n",
       "       [0.92853767, 0.07146233],\n",
       "       [0.70478664, 0.29521336],\n",
       "       [0.91727157, 0.08272843],\n",
       "       [0.75181487, 0.24818513],\n",
       "       [0.9856352 , 0.0143648 ],\n",
       "       [0.60930991, 0.39069009],\n",
       "       [0.92039078, 0.07960922],\n",
       "       [0.97397811, 0.02602189],\n",
       "       [0.97668356, 0.02331644],\n",
       "       [0.94394737, 0.05605263],\n",
       "       [0.02      , 0.98      ],\n",
       "       [0.05874219, 0.94125781],\n",
       "       [0.01704451, 0.98295549],\n",
       "       [0.74008396, 0.25991604],\n",
       "       [0.00704451, 0.99295549],\n",
       "       [0.7092781 , 0.2907219 ],\n",
       "       [0.33769668, 0.66230332],\n",
       "       [0.94374462, 0.05625538],\n",
       "       [0.98421323, 0.01578677],\n",
       "       [0.00825   , 0.99175   ],\n",
       "       [0.93780535, 0.06219465],\n",
       "       [0.01761905, 0.98238095],\n",
       "       [0.80622923, 0.19377077],\n",
       "       [0.0160119 , 0.9839881 ],\n",
       "       [0.94502677, 0.05497323],\n",
       "       [0.74015476, 0.25984524],\n",
       "       [0.96416249, 0.03583751],\n",
       "       [0.80444444, 0.19555556],\n",
       "       [0.9766957 , 0.0233043 ],\n",
       "       [0.97694866, 0.02305134],\n",
       "       [0.18885784, 0.81114216],\n",
       "       [0.60320348, 0.39679652],\n",
       "       [0.65348916, 0.34651084],\n",
       "       [0.94723398, 0.05276602],\n",
       "       [0.04      , 0.96      ],\n",
       "       [0.9710429 , 0.0289571 ],\n",
       "       [0.96416249, 0.03583751],\n",
       "       [0.87105452, 0.12894548],\n",
       "       [0.95060971, 0.04939029],\n",
       "       [0.76308103, 0.23691897],\n",
       "       [0.96435163, 0.03564837],\n",
       "       [0.28699089, 0.71300911],\n",
       "       [0.95277778, 0.04722222],\n",
       "       [1.        , 0.        ],\n",
       "       [0.46620117, 0.53379883],\n",
       "       [0.98352206, 0.01647794],\n",
       "       [0.1142986 , 0.8857014 ],\n",
       "       [0.03037719, 0.96962281],\n",
       "       [0.94378448, 0.05621552],\n",
       "       [0.91441204, 0.08558796],\n",
       "       [0.15358333, 0.84641667],\n",
       "       [0.29923671, 0.70076329],\n",
       "       [0.93      , 0.07      ],\n",
       "       [0.85197681, 0.14802319],\n",
       "       [0.96729113, 0.03270887],\n",
       "       [0.93516564, 0.06483436],\n",
       "       [0.91486111, 0.08513889],\n",
       "       [0.95592749, 0.04407251],\n",
       "       [0.05158835, 0.94841165],\n",
       "       [0.9025    , 0.0975    ],\n",
       "       [0.85122344, 0.14877656],\n",
       "       [0.01      , 0.99      ],\n",
       "       [0.28160714, 0.71839286],\n",
       "       [0.94359819, 0.05640181],\n",
       "       [0.21      , 0.79      ],\n",
       "       [0.92587476, 0.07412524],\n",
       "       [0.03979522, 0.96020478],\n",
       "       [0.70841011, 0.29158989],\n",
       "       [0.93415778, 0.06584222],\n",
       "       [0.93222063, 0.06777937],\n",
       "       [0.95916128, 0.04083872],\n",
       "       [0.83778173, 0.16221827],\n",
       "       [0.04951783, 0.95048217],\n",
       "       [0.84      , 0.16      ],\n",
       "       [0.84819486, 0.15180514],\n",
       "       [0.94952898, 0.05047102],\n",
       "       [0.27046105, 0.72953895],\n",
       "       [0.02      , 0.98      ],\n",
       "       [0.10397809, 0.89602191],\n",
       "       [0.03285714, 0.96714286],\n",
       "       [0.94599702, 0.05400298],\n",
       "       [0.34024495, 0.65975505],\n",
       "       [0.69001254, 0.30998746],\n",
       "       [0.15304268, 0.84695732],\n",
       "       [0.95483317, 0.04516683],\n",
       "       [0.36897657, 0.63102343],\n",
       "       [0.0160119 , 0.9839881 ],\n",
       "       [0.91011724, 0.08988276],\n",
       "       [0.03285714, 0.96714286],\n",
       "       [0.96369237, 0.03630763],\n",
       "       [0.85347588, 0.14652412],\n",
       "       [0.77682049, 0.22317951],\n",
       "       [0.92619573, 0.07380427],\n",
       "       [0.70548379, 0.29451621]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#estimating the probabiliy of not survived\n",
    "y_pred_proba = rf.predict_proba(X_train)\n",
    "y_pred_proba"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a948bfd6",
   "metadata": {},
   "source": [
    "### Exercise 2) \n",
    "Evaluate your results using the model score, confusion matrix, and classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "bd3e6f95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[307   0]\n",
      " [ 14 177]]\n"
     ]
    }
   ],
   "source": [
    "#now let's try comparing this to a confusion matrix\n",
    "print(confusion_matrix(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b6841dfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98       307\n",
      "           1       1.00      0.93      0.96       191\n",
      "\n",
      "    accuracy                           0.97       498\n",
      "   macro avg       0.98      0.96      0.97       498\n",
      "weighted avg       0.97      0.97      0.97       498\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#a classification report of this RF model\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d32c831",
   "metadata": {},
   "source": [
    "### Exercise 3)\n",
    "Print and clearly label the following: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7c0751b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9718875502008032\n",
      "True Positive Rate: 0.956386292834891\n",
      "False Positive Rate: 0.0\n",
      "True Negative Rate: 1.0\n",
      "False Negative Rate: 0.04361370716510903\n",
      "Precision: 1.0\n",
      "Recall: 0.956386292834891\n",
      "F1 Score: 0.9777070063694268\n",
      "Support (0): 321\n",
      "Support (1): 177\n"
     ]
    }
   ],
   "source": [
    "TP = 307\n",
    "FP = 0\n",
    "FN = 14\n",
    "TN = 177\n",
    "ALL = TP + FP + FN + TN\n",
    "\n",
    "accuracy = (TP + TN)/ALL\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "true_positive_rate = TP/(TP+FN)\n",
    "print(f\"True Positive Rate: {true_positive_rate}\")\n",
    "\n",
    "false_positive_rate = FP/(FP+TN)\n",
    "print(f\"False Positive Rate: {false_positive_rate}\")\n",
    "\n",
    "true_negative_rate = TN/(TN+FP)\n",
    "print(f\"True Negative Rate: {true_negative_rate}\")\n",
    "\n",
    "false_negative_rate = FN/(FN+TP)\n",
    "print(f\"False Negative Rate: {false_negative_rate}\")\n",
    "\n",
    "precision = TP/(TP+FP)\n",
    "print(f\"Precision: {precision}\")\n",
    "\n",
    "recall = TP/(TP+FN)\n",
    "print(f\"Recall: {recall}\")\n",
    "\n",
    "f1_score = 2*(precision*recall)/(precision+recall)\n",
    "print(f\"F1 Score: {f1_score}\")\n",
    "\n",
    "support_pos = TP + FN\n",
    "print(f\"Support (0): {support_pos}\")\n",
    "\n",
    "support_neg = FP + TN\n",
    "print(f\"Support (1): {support_neg}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d43097b",
   "metadata": {},
   "source": [
    "### Exercise 4):\n",
    "Run through steps increasing your min_samples_leaf and decreasing your max_depth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2bdc9711",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest model with max depth of 2\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.775194    0.936937  0.811245    0.856065      0.837228\n",
      "recall       0.977199    0.544503  0.811245    0.760851      0.811245\n",
      "f1-score     0.864553    0.688742  0.811245    0.776648      0.797124\n",
      "support    307.000000  191.000000  0.811245  498.000000    498.000000\n",
      "\n",
      "Random Forest model with max depth of 3\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.817927    0.893617  0.839357    0.855772      0.846957\n",
      "recall       0.951140    0.659686  0.839357    0.805413      0.839357\n",
      "f1-score     0.879518    0.759036  0.839357    0.819277      0.833309\n",
      "support    307.000000  191.000000  0.839357  498.000000    498.000000\n",
      "\n",
      "Random Forest model with max depth of 4\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.828169    0.909091  0.851406    0.868630      0.859205\n",
      "recall       0.957655    0.680628  0.851406    0.819141      0.851406\n",
      "f1-score     0.888218    0.778443  0.851406    0.833330      0.846115\n",
      "support    307.000000  191.000000  0.851406  498.000000    498.000000\n",
      "\n",
      "Random Forest model with max depth of 5\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.838527    0.924138  0.863454    0.881332      0.871362\n",
      "recall       0.964169    0.701571  0.863454    0.832870      0.863454\n",
      "f1-score     0.896970    0.797619  0.863454    0.847294      0.858865\n",
      "support    307.000000  191.000000  0.863454  498.000000    498.000000\n",
      "\n",
      "Random Forest model with max depth of 6\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.853448    0.933333   0.87751    0.893391      0.884087\n",
      "recall       0.967427    0.732984   0.87751    0.850206      0.877510\n",
      "f1-score     0.906870    0.821114   0.87751    0.863992      0.873980\n",
      "support    307.000000  191.000000   0.87751  498.000000    498.000000\n",
      "\n",
      "Random Forest model with max depth of 7\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.879056    0.943396  0.899598    0.911226      0.903733\n",
      "recall       0.970684    0.785340  0.899598    0.878012      0.899598\n",
      "f1-score     0.922601    0.857143  0.899598    0.889872      0.897495\n",
      "support    307.000000  191.000000  0.899598  498.000000    498.000000\n",
      "\n",
      "Random Forest model with max depth of 8\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.881657    0.943750  0.901606    0.912703      0.905472\n",
      "recall       0.970684    0.790576  0.901606    0.880630      0.901606\n",
      "f1-score     0.924031    0.860399  0.901606    0.892215      0.899626\n",
      "support    307.000000  191.000000  0.901606  498.000000    498.000000\n",
      "\n",
      "Random Forest model with max depth of 9\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.887240    0.950311  0.907631    0.918775      0.911430\n",
      "recall       0.973941    0.801047  0.907631    0.887494      0.907631\n",
      "f1-score     0.928571    0.869318  0.907631    0.898945      0.905846\n",
      "support    307.000000  191.000000  0.907631  498.000000    498.000000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Create a loop so we can easily change and auto different max_depths (will add in min_samples on the next kernel)\n",
    "for i in range(2,10):\n",
    "    # Make the model\n",
    "    forest = RandomForestClassifier(bootstrap=True, \n",
    "                            class_weight=None, \n",
    "                            criterion='gini',\n",
    "                            min_samples_leaf=3,\n",
    "                            n_estimators=100,\n",
    "                            max_depth=i, \n",
    "                            random_state=123)\n",
    "\n",
    "    # Fit the model (on train and only train)\n",
    "    forest = forest.fit(X_train, y_train)\n",
    "\n",
    "    # Use the model\n",
    "    # We'll evaluate the model's performance on train, first\n",
    "    y_predictions = forest.predict(X_train)\n",
    "\n",
    "    # Produce the classification report on the actual y values and this model's predicted y values\n",
    "    report = classification_report(y_train, y_predictions, output_dict=True)\n",
    "    print(f\"Random Forest model with max depth of {i}\")\n",
    "    print(pd.DataFrame(report))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af108664",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e410fc38",
   "metadata": {},
   "source": [
    "### Exercise 5) \n",
    "What are the differences in the evaluation metrics? Which performs better on your in-sample data? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d29ed09",
   "metadata": {},
   "source": [
    "<b>My in-sample data shows that the higher max depth is the higher the  return of accuracy is </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1b5c70b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_samples_leaf</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>validate_accuracy</th>\n",
       "      <th>difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>0.915663</td>\n",
       "      <td>0.803738</td>\n",
       "      <td>0.111924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0.901606</td>\n",
       "      <td>0.813084</td>\n",
       "      <td>0.088522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>0.889558</td>\n",
       "      <td>0.813084</td>\n",
       "      <td>0.076474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0.867470</td>\n",
       "      <td>0.799065</td>\n",
       "      <td>0.068404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0.859438</td>\n",
       "      <td>0.789720</td>\n",
       "      <td>0.069718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>0.843373</td>\n",
       "      <td>0.813084</td>\n",
       "      <td>0.030289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>0.821285</td>\n",
       "      <td>0.799065</td>\n",
       "      <td>0.022220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>0.819277</td>\n",
       "      <td>0.794393</td>\n",
       "      <td>0.024885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.736948</td>\n",
       "      <td>0.724299</td>\n",
       "      <td>0.012649</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   max_depth  min_samples_leaf  train_accuracy  validate_accuracy  difference\n",
       "0          9                 2        0.915663           0.803738    0.111924\n",
       "1          8                 3        0.901606           0.813084    0.088522\n",
       "2          7                 4        0.889558           0.813084    0.076474\n",
       "3          6                 5        0.867470           0.799065    0.068404\n",
       "4          5                 6        0.859438           0.789720    0.069718\n",
       "5          4                 7        0.843373           0.813084    0.030289\n",
       "6          3                 8        0.821285           0.799065    0.022220\n",
       "7          2                 9        0.819277           0.794393    0.024885\n",
       "8          1                10        0.736948           0.724299    0.012649"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let's compare with validate (out-of-sample data)\n",
    "depth = list(range(10,0,-1))\n",
    "leaf = list(range(1,11))\n",
    "metrics = []\n",
    "\n",
    "for i in range(1,10):\n",
    "    # Make the model\n",
    "    forest = RandomForestClassifier(bootstrap=True, \n",
    "                            class_weight=None, \n",
    "                            criterion='gini',\n",
    "                            min_samples_leaf= leaf[i],\n",
    "                            n_estimators=100,\n",
    "                            max_depth= depth[i], \n",
    "                            random_state=123)\n",
    "\n",
    "    # Fit the model (on train and only train)\n",
    "    forest = forest.fit(X_train, y_train)\n",
    "\n",
    "    # Use the model\n",
    "    # We'll evaluate the model's performance on train, first\n",
    "    in_sample_accuracy = forest.score(X_train, y_train)\n",
    "    \n",
    "    out_of_sample_accuracy = forest.score(X_validate, y_validate)\n",
    "\n",
    "    output = {\n",
    "        \"max_depth\": depth[i],\n",
    "        \"min_samples_leaf\": leaf[i],\n",
    "        \"train_accuracy\": in_sample_accuracy,\n",
    "        \"validate_accuracy\": out_of_sample_accuracy\n",
    "    }\n",
    "    \n",
    "    metrics.append(output)\n",
    "    \n",
    "df = pd.DataFrame(metrics)\n",
    "df[\"difference\"] = df.train_accuracy - df.validate_accuracy\n",
    "df\n",
    "\n",
    "#we are hyperparameter tuning when we model...like 'hot-roding' our data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1734f9e",
   "metadata": {},
   "source": [
    "<b>TAKE_AWAYS: The differences of train vs validate are showing that there is some over-fitting happening. I would choose probably row 5 or 6 due to similar accuracy (between train and validation) and there is smaller rate of differece too with no overfitting.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "070cbcd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Thinking about lists: (for self reminders)\n",
    "#notes: remember, lists are functions!\n",
    "#depth = list(range(10,0,-1))\n",
    "#leaf = list(range(1,10))\n",
    "\n",
    "#another note: if error of index not \"fitting\" shows up, check the created list functions lengths\n",
    "len(depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c69e3b28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(leaf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c1b68a6",
   "metadata": {},
   "source": [
    "## KNN EXERCISES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "757e04f4",
   "metadata": {},
   "source": [
    "### Exercise 1)\n",
    "Fit a K-Nearest Neighbors classifier to your training sample and transform (i.e. make predictions on the training sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2b5c3b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92d19f8",
   "metadata": {},
   "source": [
    "- Training our Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4c87b739",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating KNN object\n",
    "#weights will be uniform and density\n",
    "knn = KNeighborsClassifier(n_neighbors=5, weights='uniform')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0962a023",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fit the K-Nearest Neighbors to train\n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5494b2ea",
   "metadata": {},
   "source": [
    "- Finding our baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c9bfd290",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6164658634538153"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['baseline_prediction'] = 0\n",
    "baseline_accuracy = (train.baseline_prediction == train.survived).mean()\n",
    "baseline_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765cb38d",
   "metadata": {},
   "source": [
    "- Predictions & Probablity Time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "578523c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's make predictions!\n",
    "#classifying each parameter by predicting if one survived Titanic or not\n",
    "y_pred = knn.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "27ed3e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now some probabilities\n",
    "y_pred_proba=knn.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a9c4329",
   "metadata": {},
   "source": [
    "### Exercise 2)\n",
    "Evaluate your results using the model score, confusion matrix, and classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "68fa0071",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of KNN classifier on training set: 0.79\n"
     ]
    }
   ],
   "source": [
    "#evaluating our model score of accuracy\n",
    "print('Accuracy of KNN classifier on training set: {:.2f}'\n",
    "     .format(knn.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4f0fdf5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[255  52]\n",
      " [ 54 137]]\n"
     ]
    }
   ],
   "source": [
    "#evaluating our model with confusion matrix\n",
    "print(confusion_matrix(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "05e1955a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.83      0.83       307\n",
      "           1       0.72      0.72      0.72       191\n",
      "\n",
      "    accuracy                           0.79       498\n",
      "   macro avg       0.78      0.77      0.77       498\n",
      "weighted avg       0.79      0.79      0.79       498\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#evaluating our model with classification report\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08972f0",
   "metadata": {},
   "source": [
    "### Exercise 3)\n",
    "Print and clearly label the following: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "0eb306e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(153, 299, 8, 38)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TN, FP, FN, TP = confusion_matrix(y_train,y_predictions).ravel()\n",
    "ALL = TP + TN + FP + FN\n",
    "\n",
    "TP, TN, FP, FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d432aad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9076305220883534\n",
      "True Positive Rate: 0.8010471204188482\n",
      "False Positive Rate: 0.026058631921824105\n",
      "True Negative Rate: 0.9739413680781759\n",
      "False Negative Rate: 0.19895287958115182\n",
      "Precision: 0.9503105590062112\n",
      "Recall: 0.8010471204188482\n",
      "F1 Score: 0.8693181818181818\n",
      "Support (0): 191\n",
      "Support (1): 307\n"
     ]
    }
   ],
   "source": [
    "accuracy = (TP + TN)/ALL\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "true_positive_rate = TP/(TP+FN)\n",
    "print(f\"True Positive Rate: {true_positive_rate}\")\n",
    "\n",
    "false_positive_rate = FP/(FP+TN)\n",
    "print(f\"False Positive Rate: {false_positive_rate}\")\n",
    "\n",
    "true_negative_rate = TN/(TN+FP)\n",
    "print(f\"True Negative Rate: {true_negative_rate}\")\n",
    "\n",
    "false_negative_rate = FN/(FN+TP)\n",
    "print(f\"False Negative Rate: {false_negative_rate}\")\n",
    "\n",
    "precision = TP/(TP+FP)\n",
    "print(f\"Precision: {precision}\")\n",
    "\n",
    "recall = TP/(TP+FN)\n",
    "print(f\"Recall: {recall}\")\n",
    "\n",
    "f1_score = 2*(precision*recall)/(precision+recall)\n",
    "print(f\"F1 Score: {f1_score}\")\n",
    "\n",
    "support_pos = TP + FN\n",
    "print(f\"Support (0): {support_pos}\")\n",
    "\n",
    "support_neg = FP + TN\n",
    "print(f\"Support (1): {support_neg}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb04a6fa",
   "metadata": {},
   "source": [
    "### Exercise 4)\n",
    "Run through steps 2-4 setting k to 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "40838ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn10 = KNeighborsClassifier(n_neighbors=10, weights='uniform')# <- setting neighbors to 10\n",
    "knn10.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_train)\n",
    "y_pred_proba=knn.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c9ae2904",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of KNN classifier on training set: 0.75\n",
      "======================================\n",
      "[[255  52]\n",
      " [ 54 137]]\n",
      "======================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.83      0.83       307\n",
      "           1       0.72      0.72      0.72       191\n",
      "\n",
      "    accuracy                           0.79       498\n",
      "   macro avg       0.78      0.77      0.77       498\n",
      "weighted avg       0.79      0.79      0.79       498\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#evaluating our model score of accuracy\n",
    "print('Accuracy of KNN classifier on training set: {:.2f}'\n",
    "     .format(knn10.score(X_train, y_train)))\n",
    "print('======================================')\n",
    "#evaluating our model with confusion matrix\n",
    "print(confusion_matrix(y_train, y_pred))\n",
    "#evaluating our model with classification report\n",
    "print('======================================')\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "defaa1b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(153, 299, 8, 38)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#evaluating our statistical features with knn10\n",
    "TN, FP, FN, TP = confusion_matrix(y_train,y_predictions).ravel()\n",
    "ALL = TP + TN + FP + FN\n",
    "\n",
    "TP, TN, FP, FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0198107b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9076305220883534\n",
      "True Positive Rate: 0.8010471204188482\n",
      "False Positive Rate: 0.026058631921824105\n",
      "True Negative Rate: 0.9739413680781759\n",
      "False Negative Rate: 0.19895287958115182\n",
      "Precision: 0.9503105590062112\n",
      "Recall: 0.8010471204188482\n",
      "F1 Score: 0.8693181818181818\n",
      "Support (0): 191\n",
      "Support (1): 307\n"
     ]
    }
   ],
   "source": [
    "accuracy = (TP + TN)/ALL\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "true_positive_rate = TP/(TP+FN)\n",
    "print(f\"True Positive Rate: {true_positive_rate}\")\n",
    "\n",
    "false_positive_rate = FP/(FP+TN)\n",
    "print(f\"False Positive Rate: {false_positive_rate}\")\n",
    "\n",
    "true_negative_rate = TN/(TN+FP)\n",
    "print(f\"True Negative Rate: {true_negative_rate}\")\n",
    "\n",
    "false_negative_rate = FN/(FN+TP)\n",
    "print(f\"False Negative Rate: {false_negative_rate}\")\n",
    "\n",
    "precision = TP/(TP+FP)\n",
    "print(f\"Precision: {precision}\")\n",
    "\n",
    "recall = TP/(TP+FN)\n",
    "print(f\"Recall: {recall}\")\n",
    "\n",
    "f1_score = 2*(precision*recall)/(precision+recall)\n",
    "print(f\"F1 Score: {f1_score}\")\n",
    "\n",
    "support_pos = TP + FN\n",
    "print(f\"Support (0): {support_pos}\")\n",
    "\n",
    "support_neg = FP + TN\n",
    "print(f\"Support (1): {support_neg}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2078e75",
   "metadata": {},
   "source": [
    "### Exercise 5)\n",
    "Run through setps 2-4 setting k to 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "34333b27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_neighbors</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>validate_accuracy</th>\n",
       "      <th>difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0.829317</td>\n",
       "      <td>0.705607</td>\n",
       "      <td>0.123710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0.841365</td>\n",
       "      <td>0.738318</td>\n",
       "      <td>0.103048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0.797189</td>\n",
       "      <td>0.710280</td>\n",
       "      <td>0.086908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>0.787149</td>\n",
       "      <td>0.724299</td>\n",
       "      <td>0.062850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>0.777108</td>\n",
       "      <td>0.733645</td>\n",
       "      <td>0.043464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7</td>\n",
       "      <td>0.777108</td>\n",
       "      <td>0.728972</td>\n",
       "      <td>0.048136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>0.753012</td>\n",
       "      <td>0.733645</td>\n",
       "      <td>0.019367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9</td>\n",
       "      <td>0.761044</td>\n",
       "      <td>0.719626</td>\n",
       "      <td>0.041418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10</td>\n",
       "      <td>0.748996</td>\n",
       "      <td>0.738318</td>\n",
       "      <td>0.010678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>11</td>\n",
       "      <td>0.751004</td>\n",
       "      <td>0.742991</td>\n",
       "      <td>0.008013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>12</td>\n",
       "      <td>0.742972</td>\n",
       "      <td>0.747664</td>\n",
       "      <td>-0.004692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>13</td>\n",
       "      <td>0.746988</td>\n",
       "      <td>0.752336</td>\n",
       "      <td>-0.005348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>14</td>\n",
       "      <td>0.730924</td>\n",
       "      <td>0.728972</td>\n",
       "      <td>0.001952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>15</td>\n",
       "      <td>0.726908</td>\n",
       "      <td>0.747664</td>\n",
       "      <td>-0.020756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>16</td>\n",
       "      <td>0.730924</td>\n",
       "      <td>0.724299</td>\n",
       "      <td>0.006625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>17</td>\n",
       "      <td>0.718876</td>\n",
       "      <td>0.714953</td>\n",
       "      <td>0.003922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>18</td>\n",
       "      <td>0.736948</td>\n",
       "      <td>0.724299</td>\n",
       "      <td>0.012649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>19</td>\n",
       "      <td>0.716867</td>\n",
       "      <td>0.724299</td>\n",
       "      <td>-0.007432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>20</td>\n",
       "      <td>0.726908</td>\n",
       "      <td>0.724299</td>\n",
       "      <td>0.002609</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    n_neighbors  train_accuracy  validate_accuracy  difference\n",
       "0             2        0.829317           0.705607    0.123710\n",
       "1             3        0.841365           0.738318    0.103048\n",
       "2             4        0.797189           0.710280    0.086908\n",
       "3             5        0.787149           0.724299    0.062850\n",
       "4             6        0.777108           0.733645    0.043464\n",
       "5             7        0.777108           0.728972    0.048136\n",
       "6             8        0.753012           0.733645    0.019367\n",
       "7             9        0.761044           0.719626    0.041418\n",
       "8            10        0.748996           0.738318    0.010678\n",
       "9            11        0.751004           0.742991    0.008013\n",
       "10           12        0.742972           0.747664   -0.004692\n",
       "11           13        0.746988           0.752336   -0.005348\n",
       "12           14        0.730924           0.728972    0.001952\n",
       "13           15        0.726908           0.747664   -0.020756\n",
       "14           16        0.730924           0.724299    0.006625\n",
       "15           17        0.718876           0.714953    0.003922\n",
       "16           18        0.736948           0.724299    0.012649\n",
       "17           19        0.716867           0.724299   -0.007432\n",
       "18           20        0.726908           0.724299    0.002609"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_range = list(range(1,21))\n",
    "listed = []\n",
    "\n",
    "for k in range(1,20):\n",
    "    # Make the model\n",
    "    knn = KNeighborsClassifier(n_neighbors = k_range[k],\n",
    "                               weights = 'uniform')\n",
    "\n",
    "    # Fit the model (on train and only train)\n",
    "    knn = knn.fit(X_train, y_train)\n",
    "\n",
    "    # Use the model\n",
    "    # We'll evaluate the model's performance on train, first\n",
    "    in_sample_accuracy = knn.score(X_train, y_train)\n",
    "    \n",
    "    out_of_sample_accuracy = knn.score(X_validate, y_validate)\n",
    "\n",
    "    output = {\n",
    "        \"n_neighbors\": k_range[k],\n",
    "        \"train_accuracy\": in_sample_accuracy,\n",
    "        \"validate_accuracy\": out_of_sample_accuracy\n",
    "    }\n",
    "    \n",
    "    listed.append(output)\n",
    "    \n",
    "df = pd.DataFrame(listed)\n",
    "df[\"difference\"] = df.train_accuracy - df.validate_accuracy\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a0a8bbc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's visualize this!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "bae8b0d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "k_range = range(1, 20)\n",
    "scores = []\n",
    "for k in k_range:\n",
    "    knn = KNeighborsClassifier(n_neighbors = k)\n",
    "    knn.fit(X_train, y_train)\n",
    "    scores.append(knn.score(X_test, y_test))\n",
    "plt.figure()\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('accuracy')\n",
    "plt.scatter(k_range, scores)\n",
    "plt.xticks([0,5,10,15,20])\n",
    "plt.show()\n",
    "#this helps be see that around 6/7 for n_neighbors has the highest accuracy..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d402fad4",
   "metadata": {},
   "source": [
    "### Exercise 6)\n",
    "What are the differences in the evaluation metrics? Which performs better on your in-sample data? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb7c0db2",
   "metadata": {},
   "source": [
    "Between the accuracy score dataframe I made and the scatterplot of accuracy, I would say that number 6 performs best.\n",
    "\n",
    "    - It has a low difference of .02(rounded), meaning the Test and Validate are fairly close\n",
    "        - (also means no overfitting)\n",
    "    - It still is over our baseline of 0.62\n",
    "    - It is still at a great training point to move forward with testing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97454ef6",
   "metadata": {},
   "source": [
    "### Exercise 7)\n",
    "Which model performs best on our out-of-sample data from validate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "556a93b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of random forest classifier on test set: 0.81\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of random forest classifier on test set: {:.2f}'\n",
    "     .format(rf.score(X_validate, y_validate)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1372e05",
   "metadata": {},
   "source": [
    "# Logistic Regression Exercises\n",
    "\n",
    "### Exercise 1)\n",
    "Create a model that includes age in addition to fare and pclass. Does this model perform better than your baseline?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "700273e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "fc6daea5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6164658634538153"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#note: Baseline reminder :::::: 0.64\n",
    "\n",
    "train['baseline_prediction'] = 0\n",
    "baseline_accuracy = (train.baseline_prediction == train.survived).mean()\n",
    "baseline_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "9c8a46fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#found a duplicated column needing to be dropped\n",
    "train = train.loc[:,~train.columns.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "42933b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, validate, test\n",
    "train, validate, test = train_validate_test_split(train, target='survived', seed=123)\n",
    "\n",
    "# create X & y version of train, where y is a series with just the target variable and X are all the features. \n",
    "\n",
    "X_train = train.drop(columns=['survived','sibsp','parch','alone','sex_male','embark_town_Queenstown','embark_town_Southampton','embark_town_Southhampton','baseline_prediction'])\n",
    "y_train = train.survived\n",
    "\n",
    "X_validate = validate.drop(columns=['survived','sibsp','parch','alone','sex_male','embark_town_Queenstown','embark_town_Southampton','embark_town_Southhampton','baseline_prediction'])\n",
    "y_validate = validate.survived\n",
    "\n",
    "X_test = test.drop(columns=['survived','sibsp','parch','alone','sex_male','embark_town_Queenstown','embark_town_Southampton','embark_town_Southhampton','baseline_prediction'])\n",
    "y_test = test.survived"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d34e13",
   "metadata": {},
   "source": [
    "### Making the Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "50e0a0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import LogisticRegression\n",
    "logit = LogisticRegression(C=1, random_state=123, intercept_scaling=1, solver='lbfgs')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec9ca08",
   "metadata": {},
   "source": [
    "- Fit the Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "8813e03b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, random_state=123)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c775c3bb",
   "metadata": {},
   "source": [
    "- Feature Importance: looking at each column to determine the important/weight of each feature using coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "1e9a0d4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient: \n",
      " [[-0.90331246 -0.01994638  0.00570021]]\n",
      "Intercept: \n",
      " [1.97375021]\n"
     ]
    }
   ],
   "source": [
    "print('Coefficient: \\n', logit.coef_)\n",
    "print('Intercept: \\n', logit.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "16825a8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['pclass', 'age', 'fare'], dtype='object')"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#to show what each column the coefficients are referring to:\n",
    "X_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41fa785",
   "metadata": {},
   "source": [
    "- Making Predictions on whether or not a passenger survived or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "3628a786",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = logit.predict(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c95e54",
   "metadata": {},
   "source": [
    "- Estimating Probability of not surviving based on each observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "1522ed94",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = logit.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1dd125",
   "metadata": {},
   "source": [
    "### Evaluating model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "14607768",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression classifier on training set: 0.71\n"
     ]
    }
   ],
   "source": [
    "#Accuracy of the models logistic classifier\n",
    "print('Accuracy of Logistic Regression classifier on training set: {:.2f}'\n",
    "     .format(logit.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "857f6125",
   "metadata": {},
   "source": [
    "### <i><p style=\"color:teal;\"> TAKE AWAY: Yes! This first model's accuracy is already higher than our baseline </i></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587142a4",
   "metadata": {},
   "source": [
    "- Classification Report:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "b08a66af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.86      0.79       171\n",
      "           1       0.68      0.48      0.56       107\n",
      "\n",
      "    accuracy                           0.71       278\n",
      "   macro avg       0.70      0.67      0.67       278\n",
      "weighted avg       0.71      0.71      0.70       278\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2711078b",
   "metadata": {},
   "source": [
    "### <i><p style=\"color:teal;\"> TAKE AWAY: these are pretty good numbers. let's look at a new model with another C strength (remember, smaller values with C specify stronger regularization)\n",
    "</i></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79af5765",
   "metadata": {},
   "source": [
    "### Exercise 2)\n",
    "Include sex in your model as well. Note that you'll need to encode or create a dummy variable of this feature before including it in a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "693f8476",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename X_train and y_train to the drop any columnsn not wanted (this time keep sex_male!)\n",
    "\n",
    "X_train = train.drop(columns=['survived','sibsp','parch','alone','embark_town_Queenstown','embark_town_Southampton','embark_town_Southhampton','baseline_prediction'])\n",
    "y_train = train.survived\n",
    "\n",
    "X_validate = validate.drop(columns=['survived','sibsp','parch','alone','embark_town_Queenstown','embark_town_Southampton','embark_town_Southhampton','baseline_prediction'])\n",
    "y_validate = validate.survived\n",
    "\n",
    "X_test = test.drop(columns=['survived','sibsp','parch','alone','embark_town_Queenstown','embark_town_Southampton','embark_town_Southhampton','baseline_prediction'])\n",
    "y_test = test.survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "f16d3799",
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "float division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/d3/11nygz6126ndxvtrp12687680000gn/T/ipykernel_2226/3703896047.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m# Fit the model (on train and only train)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mlogit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m# Use the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1404\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1405\u001b[0m             \u001b[0mprefer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'processes'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1406\u001b[0;31m         fold_coefs_ = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n\u001b[0m\u001b[1;32m   1407\u001b[0m                                \u001b[0;34m**\u001b[0m\u001b[0m_joblib_parallel_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprefer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1408\u001b[0m             path_func(X, y, pos_class=class_, Cs=[C_],\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1041\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1043\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1044\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    859\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 861\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    862\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    777\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/utils/fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36m_logistic_regression_path\u001b[0;34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight, l1_ratio)\u001b[0m\n\u001b[1;32m    758\u001b[0m             opt_res = optimize.minimize(\n\u001b[1;32m    759\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"L-BFGS-B\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjac\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 760\u001b[0;31m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    761\u001b[0m                 \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"iprint\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0miprint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"gtol\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"maxiter\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    762\u001b[0m             )\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: float division by zero"
     ]
    }
   ],
   "source": [
    "#creating a 'for-loop' that can change the C value\n",
    "\n",
    "for i in range(0,1):\n",
    "    # Make the model\n",
    "    logit = LogisticRegression(C=i, \n",
    "                               random_state=123, \n",
    "                               intercept_scaling=1, \n",
    "                               solver='lbfgs')\n",
    "\n",
    "    # Fit the model (on train and only train)\n",
    "    logit.fit(X_train, y_train)\n",
    "\n",
    "    # Use the model\n",
    "    # We'll evaluate the model's performance on train, first\n",
    "    y_pred = logit.predict(X_train)\n",
    "\n",
    "    # Produce the classification report on the actual y values and this model's predicted y values\n",
    "    report = classification_report(y_train, y_predictions, output_dict=True)\n",
    "    print(f\"Random Forest model with max depth of {i}\")\n",
    "    print(pd.DataFrame(report))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126f013f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
